"""
Customer Service Agent Runner - ê³µí†µ ëª¨ë“ˆ ì‚¬ìš© ë²„ì „
"""

import sys
import os
import logging
import pathlib

# ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from shared_modules import (
    get_llm,
    get_vectorstore
)

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain
from langchain_core.output_parsers import StrOutputParser

# ë¡œê¹… ì„¤ì •
from shared_modules.logging_utils import setup_logging
logger = setup_logging("customer_agent_runner")

# í˜„ì¬ íŒŒì¼ ë””ë ‰í† ë¦¬
BASE_DIR = pathlib.Path(__file__).parent.resolve()

# ê¸°ì¡´ ì„í¬íŠ¸ë“¤
from customer_agent.prompts_config import PROMPT_META
from shared_modules.queries import get_templates_by_type

# ê´€ë ¨ í† í”½ ì¶”ë¡ 
TOPIC_CLASSIFY_SYSTEM_PROMPT = """
ë„ˆëŠ” ê³ ê° ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ê´€ë ¨ëœ ê³ ê°ê´€ë¦¬ í† í”½ì„ ê³¨ë¼ì£¼ëŠ” ì—­í• ì´ì•¼.

ì•„ë˜ì˜ í† í”½ ì¤‘ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œë¥¼ **ê°€ì¥ ë°€ì ‘í•œ í‚¤ì›Œë“œ 1ê°œë§Œ** ê³¨ë¼ì¤˜.
í‚¤ë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª…ì€ í•˜ì§€ë§ˆ. (ì˜ˆ: customer_service)
í† í”½ì´ ì—†ì„ ì‹œ customer_etc ì¶œë ¥í•´.

ê°€ëŠ¥í•œ í† í”½:
- customer_service â€“ ì‘ëŒ€, í´ë ˆì„
- customer_retention â€“ ì¬ë°©ë¬¸, ë‹¨ê³¨ ì „ëµ
- customer_satisfaction â€“ ë§Œì¡±ë„, ì—¬ì •
- customer_feedback â€“ ê³ ê°ì˜ ì˜ê²¬ ìˆ˜ì§‘ ë° ê°œì„ 
- customer_segmentation â€“ íƒ€ê²Ÿ ë¶„ë¥˜, í˜ë¥´ì†Œë‚˜
- community_building â€“ íŒ¬, íŒ¬ë¤, ì»¤ë®¤ë‹ˆí‹°
- customer_data â€“ ê³ ê°DB, CRM
- privacy_compliance â€“ ê°œì¸ì •ë³´, ë™ì˜ ê´€ë¦¬
- customer_message â€“ ê³ ê°ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€,ë¬¸êµ¬,ì•Œë¦¼,í…œí”Œë¦¿ ì¶”ì²œ ë° ì‘ì„±
- customer_etc - ê·¸ ì™¸ì˜ í† í”½
"""

# í…œí”Œë¦¿ ì£¼ì œ ì¶”ë¡ 
TEMPLATE_TYPE_EXTRACT_PROMPT = """
ë‹¤ìŒì€ ê³ ê° ë©”ì‹œì§€ í…œí”Œë¦¿ ìœ í˜• ëª©ë¡ì´ì•¼.
- ìƒì¼/ê¸°ë…ì¼
- êµ¬ë§¤ í›„ ì•ˆë‚´ (ì¶œê³  ì™„ë£Œ, ë°°ì†¡ ì‹œì‘, ë°°ì†¡ ì•ˆë‚´ ë“± í¬í•¨)
- ì¬êµ¬ë§¤ ìœ ë„
- ê³ ê° ë§ì¶¤ ë©”ì‹œì§€ (VIP, ê°€ì… ê³ ê° ë“± í¬í•¨)
- ë¦¬ë·° ìš”ì²­
- ì„¤ë¬¸ ìš”ì²­
- ì´ë²¤íŠ¸ ì•ˆë‚´
- ì˜ˆì•½
- ì¬ë°©ë¬¸
- í•´ë‹¹ì‚¬í•­ ì—†ìŒ

ì•„ë˜ ì§ˆë¬¸ì—ì„œ ê°€ì¥ ì˜ ë§ëŠ” í…œí”Œë¦¿ ìœ í˜•ì„ í•œê¸€ë¡œ ì •í™•íˆ 1ê°œë§Œ ê³¨ë¼ì¤˜.
ì„¤ëª… ì—†ì´ í‚¤ì›Œë“œë§Œ ì¶œë ¥í•´. (ì˜ˆ: ìƒì¼/ê¸°ë…ì¼)
ì§ˆë¬¸: {input}
"""

# def classify_topics(user_input: str) -> list:
#     """í† í”½ ë¶„ë¥˜"""
#     classify_prompt = ChatPromptTemplate.from_messages([
#         ("system", TOPIC_CLASSIFY_SYSTEM_PROMPT),
#         ("human", "ì‚¬ìš©ì ì§ˆë¬¸: {input}")
#     ])
    
#     # ê³µí†µ ëª¨ë“ˆì˜ LLM ì‚¬ìš©
#     llm = get_llm()
#     if not llm:
#         logger.error("LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
#         return []
    
#     chain = classify_prompt | llm | StrOutputParser()
#     result = chain.invoke({"input": user_input}).strip()
    
#     return [result.strip()] if result.strip() in PROMPT_META else []

def classify_topics(user_input: str) -> list:
    from shared_modules import get_llm_manager
    manager = get_llm_manager()

    try:
        llm = manager.get_llm()
        prompt = ChatPromptTemplate.from_messages([
            ("system", TOPIC_CLASSIFY_SYSTEM_PROMPT),
            ("human", "ì‚¬ìš©ì ì§ˆë¬¸: {input}")
        ])
        chain = prompt | llm | StrOutputParser()
        result = chain.invoke({"input": user_input}).strip()

        topic = result.strip()
        if topic not in PROMPT_META:
            logger.warning(f"Unknown topic classified: {topic}")
            return []
        return [topic]

    except Exception as e:
        logger.warning(f"[classify_topics] Gemini ì‹¤íŒ¨ â†’ OpenAI fallback: {e}")
        manager.current_provider = "openai"

        try:
            llm = manager.get_llm()
            prompt = ChatPromptTemplate.from_messages([
                ("system", TOPIC_CLASSIFY_SYSTEM_PROMPT),
                ("human", "ì‚¬ìš©ì ì§ˆë¬¸: {input}")
            ])
            chain = prompt | llm | StrOutputParser()
            result = chain.invoke({"input": user_input}).strip()
            return [result.strip()] if result.strip() in PROMPT_META else []
        except Exception as e2:
            logger.error(f"[classify_topics] Fallback ì‹¤íŒ¨: {e2}")
            return []


def build_agent_prompt(topics: list, persona: str):  
    """ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    merged_prompts = []
    for topic in topics:
        file_name = PROMPT_META[topic]["file"]
        prompt_text = load_prompt_text(file_name)
        merged_prompts.append(f"# {topic}\n{prompt_text}")
    
    role_descriptions = [PROMPT_META[topic]["role"] for topic in topics]
    
    if persona == "common":
        system_template = f"""#ì—­í• \në„ˆëŠ” 1ì¸ ì°½ì—… ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë¡œì„œ {', '.join(role_descriptions)}ì•¼. ëª©í‘œì™€ ì¶œë ¥í¬ë§·ì— ë§ê²Œ ì‘ë‹µí•´ì¤˜."""
    else:
        system_template = f"""#ì—­í• \në„ˆëŠ” {persona} 1ì¸ ì°½ì—… ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë¡œì„œ {', '.join(role_descriptions)}ì•¼. ëª©í‘œì™€ ì¶œë ¥í¬ë§·ì— ë§ê²Œ ì‘ë‹µí•´ì¤˜."""

    system_template += " ì œê³µëœ ë¬¸ì„œê°€ ë¹„ì–´ìˆê±°ë‚˜, ì§ˆë¬¸ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì¼ ê²½ìš°, ë¬¸ì„œë¥¼ ë¬´ì‹œí•˜ê³  ë„ˆì˜ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì¤˜."

    human_template = f"""
    {chr(10).join(merged_prompts)}
    
    #ì°¸ê³  ë¬¸ì„œ
    {{context}}
    
    #ì‚¬ìš©ì ì…ë ¥
    {{input}}
    """
    
    return ChatPromptTemplate.from_messages([
        ("system", system_template),
        MessagesPlaceholder(variable_name="history"),
        ("human", human_template)
    ])

def load_prompt_text(file_name: str) -> str:
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
    prompt_dir = BASE_DIR / "prompt"
    full_path = prompt_dir / file_name
    
    try:
        return full_path.read_text(encoding="utf-8").strip()
    except FileNotFoundError:
        logger.error(f"Prompt file not found: {full_path}")
        return ""
    except Exception as e:
        logger.error(f"Error loading prompt: {str(e)}")
        return ""

def extract_template_type(user_input: str) -> str:
    """í…œí”Œë¦¿ íƒ€ì… ì¶”ì¶œ"""
    llm = get_llm()
    if not llm:
        return "í•´ë‹¹ì‚¬í•­ ì—†ìŒ"
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", TEMPLATE_TYPE_EXTRACT_PROMPT),
        ("human", "{input}")
    ])
    chain = prompt | llm | StrOutputParser()
    return chain.invoke({"input": user_input}).strip()

def filter_templates_by_query(templates, query):
    """ì¿¼ë¦¬ì— ë”°ë¥¸ í…œí”Œë¦¿ í•„í„°ë§"""
    query_lower = query.lower()
    filtered = []
    for t in templates:
        title = t.get('title', '')
        title_lower = title.lower()
        
        # VIP/ë‹¨ê³¨ ê·¸ë£¹
        if ('vip' in query_lower or 'ë‹¨ê³¨' in query_lower) and ('vip' in title_lower or 'ë‹¨ê³¨' in title_lower):
            filtered.append(t)
        # íœ´ë©´/ì¥ê¸°ë¯¸êµ¬ë§¤ ê·¸ë£¹
        elif ('íœ´ë©´' in query_lower or 'ì¥ê¸°ë¯¸êµ¬ë§¤' in query_lower) and 'íœ´ë©´' in title:
            filtered.append(t)
        # ê°€ì…, íšŒì›ê°€ì… ê·¸ë£¹
        elif ('ê°€ì…' in query_lower or 'íšŒì›ê°€ì…' in query_lower) and ('ê°€ì…' in title_lower or 'íšŒì›ê°€ì…' in title_lower):
            filtered.append(t)
        # ìµœê·¼ êµ¬ë§¤, ìµœê·¼êµ¬ë§¤ ê·¸ë£¹
        elif ('ìµœê·¼ êµ¬ë§¤' in query_lower or 'ìµœê·¼êµ¬ë§¤' in query_lower) and ('ìµœê·¼ êµ¬ë§¤' in title_lower or 'ìµœê·¼êµ¬ë§¤' in title_lower):
            filtered.append(t)
    return filtered

def run_rag_chain(user_input, topics, persona, chat_history):
    """RAG ì²´ì¸ ì‹¤í–‰"""
    prompt = build_agent_prompt(topics, persona)

    llm = get_llm()
    if not llm:
        logger.error("LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", ""

    try:
        vectorstore = get_vectorstore("global-documents")
        if not vectorstore:
            raise ValueError("Vectorstore ì—°ê²° ì‹¤íŒ¨")

        retriever = vectorstore.as_retriever(search_kwargs={
            "k": 5,
            "filter": {"category": "customer_management", "topic": {"$in": topics}} if topics != ["customer_etc"] else {"category": "customer_management"}
        })

        document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)
        retrieval_chain = create_retrieval_chain(
            retriever=retriever,
            combine_docs_chain=document_chain
        )

        result = retrieval_chain.invoke({
            "input": user_input,
            "history": chat_history or []
        })

        sources = "\n\n".join(
            [f"# ë¬¸ì„œ\n{doc.page_content}\n" for doc in result["context"]]
        )

        return result["answer"], sources

    except Exception as e:
        logger.warning(f"ğŸ” ë²¡í„°ìŠ¤í† ì–´ ì˜¤ë¥˜ë¡œ RAG ì‹¤íŒ¨. ë¬¸ì„œ ì—†ì´ ê¸°ë³¸ LLM ì‘ë‹µ ìˆ˜í–‰: {e}")
        # ë²¡í„°ìŠ¤í† ì–´ ì—†ì´ë„ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ë‹µë³€ ìƒì„±
        chain = prompt | llm | StrOutputParser()
        answer = chain.invoke({
            "input": user_input,
            "history": chat_history or [],
            "context": "ë¬¸ì„œ ì—†ìŒ"
        })
        return answer, ""


def run_customer_service_with_rag(
    user_input: str,
    customer_id: str = None,
    conversation_id: int = None,
    persona: str = "common",
    chat_history: list = None
):
    """ê³ ê° ì„œë¹„ìŠ¤ RAG ì‹¤í–‰ (ë©”ì¸ í•¨ìˆ˜)"""
    try:
        topics = classify_topics(user_input)
        logger.info(f"Classified topics: {topics}")

        if "customer_message" in topics:
            template_type = extract_template_type(user_input)
            logger.info(f"Extracted template_type: {template_type}")
            templates = get_templates_by_type(template_type)

            if template_type == "ê³ ê° ë§ì¶¤ ë©”ì‹œì§€" and templates:
                filtered_templates = filter_templates_by_query(templates, user_input)
            else:
                filtered_templates = templates

            if filtered_templates:
                answer_blocks = []
                for t in filtered_templates:
                    if t.get("content_type") == "html":
                        preview_url = f"http://localhost:8001/preview/{t['template_id']}"
                        answer_blocks.append(f"ì œëª©: {t['title']}\n\n[HTML ë¯¸ë¦¬ë³´ê¸°]({preview_url})")
                    else:
                        answer_blocks.append(f"ì œëª©: {t['title']}\n\n{t['content']}")
                
                answer = "\n\n---\n\n".join(answer_blocks)
                answer += f"\n\nìœ„ì™€ ê°™ì€ ë©”ì‹œì§€ í…œí”Œë¦¿ì„ í™œìš©í•´ë³´ì„¸ìš”."
                sources = ""
            else:
                answer, sources = run_rag_chain(user_input, topics, persona, chat_history)
            
            return {
                "topics": topics,
                "answer": answer,
                "sources": sources
            }

        # customer_messageê°€ ì•„ë‹Œ ê²½ìš° ê³µí†µ RAG ì‹¤í–‰
        answer, sources = run_rag_chain(user_input, topics, persona, chat_history)
        return {
            "topics": topics,
            "answer": answer,
            "sources": sources
        }
        
    except Exception as e:
        logger.error(f"ê³ ê° ì„œë¹„ìŠ¤ RAG ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {
            "topics": [],
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "sources": ""
        }

# ê¸°ì¡´ í•¨ìˆ˜ëª…ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
run_customer_agent_with_rag = run_customer_service_with_rag
