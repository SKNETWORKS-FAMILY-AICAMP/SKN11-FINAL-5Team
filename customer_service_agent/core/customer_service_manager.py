"""
í†µí•© ê³ ê° ì„œë¹„ìŠ¤ ì—ì´ì „íŠ¸ ë§¤ë‹ˆì € - ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ
ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ì˜ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì—¬ ë¦¬íŒ©í† ë§
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from enum import Enum
import json
from datetime import datetime

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
from shared_modules import (
    get_config,
    get_llm_manager,
    get_vector_manager,
    get_or_create_conversation_session,
    create_message,
    get_recent_messages,
    insert_message_raw,
    get_session_context,
    create_success_response,
    create_error_response,
    get_current_timestamp,
    format_conversation_history,
    load_prompt_from_file,
    PromptTemplate,
    get_templates_by_type
)

from customer_service_agent.config.persona_config import PERSONA_CONFIG, get_persona_by_topic
from customer_service_agent.config.prompts_config import PROMPT_META
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)

class ConversationStage(Enum):
    """ëŒ€í™” ë‹¨ê³„ ì •ì˜"""
    INITIAL = "initial"                    # ì´ˆê¸° ì ‘ì´‰
    PROBLEM_IDENTIFICATION = "problem_identification"  # ë¬¸ì œ íŒŒì•…
    INFORMATION_GATHERING = "info_gathering"  # ì •ë³´ ìˆ˜ì§‘
    ANALYSIS = "analysis"                  # ë¶„ì„
    SOLUTION_PROPOSAL = "solution_proposal"  # í•´ê²°ì±… ì œì•ˆ
    FEEDBACK = "feedback"                  # í”¼ë“œë°± ìˆ˜ì§‘
    REFINEMENT = "refinement"              # ìˆ˜ì •
    FINAL_RESULT = "final_result"          # ìµœì¢… ê²°ê³¼
    COMPLETED = "completed"                # ì™„ë£Œ

class ConversationState:
    """ëŒ€í™” ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, conversation_id: int, user_id: int):
        self.conversation_id = conversation_id
        self.user_id = user_id
        self.stage = ConversationStage.INITIAL
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        
        # ìˆ˜ì§‘ëœ ì •ë³´
        self.collected_info = {
            "business_type": None,           # ì‚¬ì—… ìœ í˜•
            "customer_issue": None,          # ê³ ê° ë¬¸ì œ/ë¶ˆë§Œ
            "customer_segment": None,        # ê³ ê° ì„¸ê·¸ë¨¼íŠ¸
            "current_situation": None,       # í˜„ì¬ ìƒí™©
            "desired_outcome": None,         # ì›í•˜ëŠ” ê²°ê³¼
            "urgency_level": None,           # ê¸´ê¸‰ë„
            "available_resources": None,     # ê°€ìš© ìì›
            "previous_attempts": None,       # ì´ì „ ì‹œë„
            "customer_data": None,          # ê³ ê° ë°ì´í„°
            "communication_channel": None,   # ì†Œí†µ ì±„ë„
            "timeline": None,               # í•´ê²° ê¸°í•œ
            "budget": None,                 # ì˜ˆì‚°
            "additional_context": {}
        }
        
        # ë¶„ì„ ê²°ê³¼
        self.analysis_results = {
            "primary_topics": [],
            "intent_analysis": {},
            "customer_sentiment": "neutral",
            "problem_category": None,
            "recommendations": []
        }
        
        # í•´ê²°ì±… ë° ì œì•ˆ
        self.solutions = []
        self.feedback_history = []
        self.refinements = []
        
        # ìµœì¢… ê²°ê³¼
        self.final_solution = None
        self.action_plan = None
        
        # ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ê¸°ë¡
        self.stage_prompts = {}
        
    def update_stage(self, new_stage: ConversationStage):
        """ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
        self.stage = new_stage
        self.updated_at = datetime.now()
        
    def add_collected_info(self, key: str, value: Any):
        """ìˆ˜ì§‘ëœ ì •ë³´ ì¶”ê°€"""
        self.collected_info[key] = value
        self.updated_at = datetime.now()
        
    def add_feedback(self, feedback: Dict[str, Any]):
        """í”¼ë“œë°± ì¶”ê°€"""
        feedback["timestamp"] = datetime.now()
        self.feedback_history.append(feedback)
        self.updated_at = datetime.now()
        
    def is_information_complete(self) -> bool:
        """ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
        required_fields = ["business_type", "customer_issue", "desired_outcome"]
        return all(self.collected_info.get(field) for field in required_fields)
        
    def get_completion_rate(self) -> float:
        """ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œìœ¨"""
        total_fields = len(self.collected_info)
        completed_fields = len([v for v in self.collected_info.values() if v])
        return completed_fields / total_fields if total_fields > 0 else 0.0

class CustomerServiceAgentManager:
    """í†µí•© ê³ ê° ì„œë¹„ìŠ¤ ì—ì´ì „íŠ¸ ê´€ë¦¬ì - ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ê³ ê° ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        self.config = get_config()
        self.llm_manager = get_llm_manager()
        self.vector_manager = get_vector_manager()
        
        # í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.prompts_dir = Path(__file__).parent.parent / 'prompts'
        
        # ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
        self.knowledge_collection = 'customer-service-knowledge'
        
        # ê³ ê° ì„œë¹„ìŠ¤ í† í”½ ì •ì˜
        self.customer_topics = {
            "customer_service": "ê³ ê° ì‘ëŒ€ ë° í´ë ˆì„ ì²˜ë¦¬",
            "customer_retention": "ì¬ë°©ë¬¸ ìœ ë„ ë° ê³ ê° ìœ ì§€",
            "customer_satisfaction": "ê³ ê° ë§Œì¡±ë„ ê°œì„ ",
            "customer_feedback": "ê³ ê° í”¼ë“œë°± ë¶„ì„",
            "customer_segmentation": "ê³ ê° íƒ€ê²ŸíŒ… ë° ì„¸ë¶„í™”",
            "community_building": "ì»¤ë®¤ë‹ˆí‹° êµ¬ì¶•",
            "customer_data": "ê³ ê° ë°ì´í„° í™œìš©",
            "privacy_compliance": "ê°œì¸ì •ë³´ ë³´í˜¸",
            "customer_message": "ê³ ê° ë©”ì‹œì§€ í…œí”Œë¦¿",
            "customer_etc": "ê¸°íƒ€ ê³ ê° ê´€ë¦¬"
        }
        
        # ëŒ€í™” ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self.conversation_states: Dict[int, ConversationState] = {}
        
        # ë‹¨ê³„ë³„ ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸ í…œí”Œë¦¿
        self.info_gathering_questions = {
            "business_type": "ì–´ë–¤ ì—…ì¢…/ì‚¬ì—…ì„ ìš´ì˜í•˜ê³  ê³„ì‹ ê°€ìš”?",
            "customer_issue": "í˜„ì¬ ì–´ë–¤ ê³ ê° ê´€ë ¨ ë¬¸ì œë‚˜ ì´ìŠˆê°€ ìˆìœ¼ì‹ ê°€ìš”?",
            "customer_segment": "ì£¼ìš” ê³ ê°ì¸µì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "current_situation": "í˜„ì¬ ìƒí™©ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
            "desired_outcome": "ì–´ë–¤ ê²°ê³¼ë¥¼ ì›í•˜ì‹œë‚˜ìš”?",
            "urgency_level": "ì´ ë¬¸ì œì˜ ê¸´ê¸‰ë„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
            "available_resources": "í˜„ì¬ í™œìš© ê°€ëŠ¥í•œ ìì›(ì¸ë ¥, ì‹œìŠ¤í…œ ë“±)ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "previous_attempts": "ì´ì „ì— ì‹œë„í•´ë³¸ í•´ê²° ë°©ë²•ì´ ìˆë‚˜ìš”?",
            "customer_data": "ê³ ê° ë°ì´í„°ë‚˜ í”¼ë“œë°±ì´ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”",
            "communication_channel": "ì£¼ë¡œ ì–´ë–¤ ì±„ë„ë¡œ ê³ ê°ê³¼ ì†Œí†µí•˜ì‹œë‚˜ìš”?",
            "timeline": "ì–¸ì œê¹Œì§€ í•´ê²°í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
            "budget": "ì˜ˆì‚° ë²”ìœ„ê°€ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”"
        }
        
        # ì§€ì‹ ê¸°ë°˜ ì´ˆê¸°í™”
        self._initialize_knowledge_base()
    
    def call_llm_api(self, model: str, prompt: str) -> str:
        """LLM API í˜¸ì¶œ í•¨ìˆ˜"""
        try:
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
                HumanMessage(content=prompt)
            ]
            
            llm = ChatOpenAI(model_name=model, temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            return response
            
        except Exception as e:
            logger.error(f"LLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def is_follow_up(self, user_input: str, last_message: str, model="gpt-4o-mini") -> bool:
        """ì´ì „ ë©”ì‹œì§€ì™€ ì—°ê²°ë˜ëŠ” í›„ì† ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        try:
            prompt = f"""ì•„ë˜ ì‚¬ìš©ì ë°œí™”ê°€ ì´ì „ ë©”ì‹œì§€ "{last_message}"ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” í›„ì† ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•´.
í›„ì† ì§ˆë¬¸ì´ë©´ true, ì•„ë‹ˆë©´ falseë§Œ ì¶œë ¥í•´.

ì‚¬ìš©ì ë°œí™”: "{user_input}"""
            
            response = self.call_llm_api(model=model, prompt=prompt)
            return "true" in response.lower()
            
        except Exception as e:
            logger.error(f"is_follow_up íŒë‹¨ ì‹¤íŒ¨: {e}")
            return False
    
    def _initialize_knowledge_base(self):
        """ê³ ê° ì„œë¹„ìŠ¤ ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            vectorstore = self.vector_manager.get_vectorstore(
                collection_name=self.knowledge_collection,
                create_if_not_exists=True
            )
            
            if not vectorstore:
                logger.warning("ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return
            
            logger.info("âœ… ê³ ê° ì„œë¹„ìŠ¤ ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def get_or_create_conversation_state(self, conversation_id: int, user_id: int) -> ConversationState:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ ë˜ëŠ” ìƒì„±"""
        if conversation_id not in self.conversation_states:
            self.conversation_states[conversation_id] = ConversationState(conversation_id, user_id)
        return self.conversation_states[conversation_id]
    
    def load_topic_prompt(self, topic: str) -> str:
        """í† í”½ë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì§ì ‘ ë¡œë“œ"""
        try:
            prompt_file = self.prompts_dir / f"{topic}.txt"
            if prompt_file.exists():
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                logger.warning(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {topic}")
                return ""
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({topic}): {e}")
            return ""
    
    def classify_customer_topic_with_llm(self, user_input: str, context: str = "") -> List[str]:
        """LLMì„ í™œìš©í•œ ê³ ê° ì„œë¹„ìŠ¤ í† í”½ ë¶„ë¥˜"""
        try:
            topic_classification_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ëœ ê³ ê° ì„œë¹„ìŠ¤ í† í”½ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ ê³ ê° ì„œë¹„ìŠ¤ í† í”½:
{chr(10).join([f"- {key}: {value}" for key, value in self.customer_topics.items()])}

{f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸: {context}" if context else ""}

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ìœ„ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ í† í”½ì„ ìµœëŒ€ 2ê°œê¹Œì§€ ì„ íƒí•˜ì—¬ í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì˜ˆì‹œ: customer_service, customer_retention

ë‹µë³€:"""

            # SystemMessage, HumanMessageë¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ ê³ ê° ì„œë¹„ìŠ¤ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì •í™•í•œ ê³ ê° ê´€ë¦¬ í† í”½ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."),
                HumanMessage(content=topic_classification_prompt)
            ]
            
            # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            if response:
                topics = [topic.strip() for topic in response.split(',')]
                valid_topics = [topic for topic in topics if topic in self.customer_topics]
                return valid_topics[:2] if valid_topics else ["customer_service"]
            
            return ["customer_service"]
            
        except Exception as e:
            logger.error(f"LLM í† í”½ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return ["customer_service", "customer_etc"]
    
    def analyze_user_intent_and_stage(self, user_input: str, state: ConversationState) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ë° ëŒ€í™” ë‹¨ê³„ ë¶„ì„"""
        try:
            context_info = {
                "current_stage": state.stage.value,
                "collected_info": state.collected_info,
                "completion_rate": state.get_completion_rate()
            }
            
            intent_analysis_prompt = f"""ì‚¬ìš©ìì˜ ê³ ê° ì„œë¹„ìŠ¤ ìƒë‹´ ì˜ë„ì™€ ëŒ€í™” ì§„í–‰ ë°©í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

í˜„ì¬ ëŒ€í™” ìƒíƒœ:
- ë‹¨ê³„: {state.stage.value}
- ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œìœ¨: {state.get_completion_rate():.1%}
- ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(state.collected_info, ensure_ascii=False, indent=2)}

ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë‹¤ìŒ JSON í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "intent_type": "problem_report|info_provide|solution_request|feedback_give|template_request|general_inquiry",
    "confidence": 0.9,
    "extracted_info": {{
        "field_name": "ì¶”ì¶œëœ ì •ë³´ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)"
    }},
    "next_stage_recommendation": "problem_identification|info_gathering|analysis|solution_proposal|feedback|refinement|final_result",
    "customer_sentiment": "positive|neutral|negative|frustrated|urgent",
    "urgency_level": "high|medium|low",
    "suggested_questions": ["ì¶”ê°€ë¡œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ë“¤"]
}}

ë¶„ì„ ê²°ê³¼:"""

            # SystemMessage, HumanMessageë¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ ê³ ê° ì„œë¹„ìŠ¤ ìƒë‹´ ì „ë¬¸ê°€ë¡œì„œ ëŒ€í™” íë¦„ê³¼ ì‚¬ìš©ì ì˜ë„ë¥¼ ì •í™•íˆ ë¶„ì„í•©ë‹ˆë‹¤."),
                HumanMessage(content=intent_analysis_prompt)
            ]
            
            # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            if isinstance(response, dict):
                return response
            elif isinstance(response, str):
                try:
                    return json.loads(response)
                except json.JSONDecodeError:
                    pass
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "intent_type": "general_inquiry",
                "confidence": 0.7,
                "extracted_info": {},
                "next_stage_recommendation": "problem_identification",
                "customer_sentiment": "neutral",
                "urgency_level": "medium",
                "suggested_questions": []
            }
            
        except Exception as e:
            logger.error(f"ì˜ë„ ë° ë‹¨ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "intent_type": "general_inquiry",
                "confidence": 0.5,
                "extracted_info": {},
                "next_stage_recommendation": "problem_identification",
                "customer_sentiment": "neutral",
                "urgency_level": "medium",
                "suggested_questions": []
            }
    
    def handle_template_request(self, user_input: str, state: ConversationState) -> str:
        """ê³ ê° ë©”ì‹œì§€ í…œí”Œë¦¿ ìš”ì²­ ì²˜ë¦¬"""
        try:
            # í…œí”Œë¦¿ íƒ€ì… ì¶”ì¶œ
            template_type = self.extract_template_type(user_input)
            logger.info(f"ì¶”ì¶œëœ í…œí”Œë¦¿ íƒ€ì…: {template_type}")
            
            # í…œí”Œë¦¿ ì¡°íšŒ
            templates = get_templates_by_type(template_type)
            
            if template_type == "ê³ ê° ë§ì¶¤ ë©”ì‹œì§€" and templates:
                # ë§ì¶¤í˜• ë©”ì‹œì§€ì˜ ê²½ìš° ì¶”ê°€ í•„í„°ë§
                filtered_templates = self.filter_templates_by_query(templates, user_input)
            else:
                filtered_templates = templates
            
            if filtered_templates:
                answer_blocks = []
                for t in filtered_templates:
                    if t.get("content_type") == "html":
                        preview_url = f"http://localhost:8001/preview/{t['template_id']}"
                        answer_blocks.append(f"ğŸ“‹ **{t['title']}**\n\n[HTML ë¯¸ë¦¬ë³´ê¸°]({preview_url})")
                    else:
                        answer_blocks.append(f"ğŸ“‹ **{t['title']}**\n\n{t['content']}")
                
                answer = "\n\n---\n\n".join(answer_blocks)
                answer += f"\n\nâœ… ìœ„ í…œí”Œë¦¿ë“¤ì„ ì°¸ê³ í•˜ì—¬ ê³ ê°ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”!"
                return answer
            else:
                return f"'{template_type}' ê´€ë ¨ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
            
        except Exception as e:
            logger.error(f"í…œí”Œë¦¿ ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "í…œí”Œë¦¿ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def extract_template_type(self, user_input: str) -> str:
        """í…œí”Œë¦¿ íƒ€ì… ì¶”ì¶œ"""
        template_extract_prompt = f"""ë‹¤ìŒì€ ê³ ê° ë©”ì‹œì§€ í…œí”Œë¦¿ ìœ í˜• ëª©ë¡ì…ë‹ˆë‹¤.
- ìƒì¼/ê¸°ë…ì¼
- êµ¬ë§¤ í›„ ì•ˆë‚´ (ì¶œê³  ì™„ë£Œ, ë°°ì†¡ ì‹œì‘, ë°°ì†¡ ì•ˆë‚´ ë“± í¬í•¨)
- ì¬êµ¬ë§¤ ìœ ë„
- ê³ ê° ë§ì¶¤ ë©”ì‹œì§€ (VIP, ê°€ì… ê³ ê° ë“± í¬í•¨)
- ë¦¬ë·° ìš”ì²­
- ì„¤ë¬¸ ìš”ì²­
- ì´ë²¤íŠ¸ ì•ˆë‚´
- ì˜ˆì•½
- ì¬ë°©ë¬¸
- í•´ë‹¹ì‚¬í•­ ì—†ìŒ

ì•„ë˜ ì§ˆë¬¸ì—ì„œ ê°€ì¥ ì˜ ë§ëŠ” í…œí”Œë¦¿ ìœ í˜•ì„ í•œê¸€ë¡œ ì •í™•íˆ 1ê°œë§Œ ê³¨ë¼ì£¼ì„¸ìš”.
ì„¤ëª… ì—†ì´ í‚¤ì›Œë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ì§ˆë¬¸: {user_input}
"""

        try:
            # SystemMessage, HumanMessageë¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                SystemMessage(content=template_extract_prompt),
                HumanMessage(content=user_input)
            ]
            
            # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            result = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            return result.strip() if result else "í•´ë‹¹ì‚¬í•­ ì—†ìŒ"
            
        except Exception as e:
            logger.error(f"í…œí”Œë¦¿ íƒ€ì… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "í•´ë‹¹ì‚¬í•­ ì—†ìŒ"
    
    def filter_templates_by_query(self, templates: List[Dict], query: str) -> List[Dict]:
        """ì¿¼ë¦¬ì— ë”°ë¥¸ í…œí”Œë¦¿ í•„í„°ë§"""
        query_lower = query.lower()
        filtered = []
        
        for t in templates:
            title = t.get('title', '')
            title_lower = title.lower()
            
            # VIP/ë‹¨ê³¨ ê·¸ë£¹
            if ('vip' in query_lower or 'ë‹¨ê³¨' in query_lower) and ('vip' in title_lower or 'ë‹¨ê³¨' in title_lower):
                filtered.append(t)
            # íœ´ë©´/ì¥ê¸°ë¯¸êµ¬ë§¤ ê·¸ë£¹
            elif ('íœ´ë©´' in query_lower or 'ì¥ê¸°ë¯¸êµ¬ë§¤' in query_lower) and 'íœ´ë©´' in title:
                filtered.append(t)
            # ê°€ì…, íšŒì›ê°€ì… ê·¸ë£¹
            elif ('ê°€ì…' in query_lower or 'íšŒì›ê°€ì…' in query_lower) and ('ê°€ì…' in title_lower or 'íšŒì›ê°€ì…' in title_lower):
                filtered.append(t)
            # ìµœê·¼ êµ¬ë§¤, ìµœê·¼êµ¬ë§¤ ê·¸ë£¹
            elif ('ìµœê·¼ êµ¬ë§¤' in query_lower or 'ìµœê·¼êµ¬ë§¤' in query_lower) and ('ìµœê·¼ êµ¬ë§¤' in title_lower or 'ìµœê·¼êµ¬ë§¤' in title_lower):
                filtered.append(t)
        
        return filtered if filtered else templates
    
    def _determine_conversation_mode_with_history(self, user_input: str, user_id: int, conversation_id: Optional[int] = None) -> bool:
        """íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•œ ì‹±ê¸€í„´/ë©€í‹°í„´ ëª¨ë“œ ìë™ íŒë‹¨
        
        Returns:
            bool: Trueë©´ ì‹±ê¸€í„´, Falseë©´ ë©€í‹°í„´
        """
        try:
            # 1. ì²« ëŒ€í™”ì¸ì§€ í™•ì¸
            if conversation_id is None:
                logger.info("ì²« ëŒ€í™” ê°ì§€ - ì‹±ê¸€í„´ ëª¨ë“œë¡œ ì‹œì‘")
                return True  # ì²« ëŒ€í™”ëŠ” ë¬´ì¡°ê±´ ì‹±ê¸€í„´
            
            # 2. ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
            with get_session_context() as db:
                recent_messages = get_recent_messages(db, conversation_id, limit=2)
            
                if not recent_messages or len(recent_messages) < 2:
                    logger.info("íˆìŠ¤í† ë¦¬ ë¶€ì¡± - ì‹±ê¸€í„´ ëª¨ë“œ")
                    return True  # íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ì‹±ê¸€í„´
                
                # 3. ë§ˆì§€ë§‰ ë©”ì‹œì§€ í™•ì¸
                # last_message = recent_messages[-1] if recent_messages else ""
                last_message = recent_messages[-1].content if recent_messages else ""

            
                # 4. í›„ì† ì§ˆë¬¸ì¸ì§€ LLMìœ¼ë¡œ íŒë‹¨
            is_followup = self.is_follow_up(user_input, last_message)
            
            if is_followup:
                logger.info("í›„ì† ì§ˆë¬¸ ê°ì§€ - ë©€í‹°í„´ ëª¨ë“œ ìœ ì§€")
                return False  # í›„ì† ì§ˆë¬¸ì´ë©´ ë©€í‹°í„´ ìœ ì§€
            
            # 5. ìƒˆë¡œìš´ ì£¼ì œì¸ ê²½ìš° í‚¤ì›Œë“œ ê¸°ë°˜ íŒë‹¨
            return self._determine_conversation_mode_by_keywords(user_input)
            
        except Exception as e:
            logger.error(f"íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ëŒ€í™” ëª¨ë“œ íŒë‹¨ ì‹¤íŒ¨: {e}")
            return True  # ì˜¤ë¥˜ ì‹œ ì‹±ê¸€í„´ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì •
    
    def _determine_conversation_mode_by_keywords(self, user_input: str) -> bool:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ì‹±ê¸€í„´/ë©€í‹°í„´ ëª¨ë“œ íŒë‹¨
        
        Returns:
            bool: Trueë©´ ì‹±ê¸€í„´, Falseë©´ ë©€í‹°í„´
        """
        try:
            # 1. ëª…ì‹œì  ì‹±ê¸€í„´ ìš”ì²­ í‚¤ì›Œë“œ
            single_turn_keywords = [
                "í…œí”Œë¦¿", "ë©”ì‹œì§€", "ë¬¸êµ¬", "ì•Œë¦¼",
                "ë¹ ë¥¸ ë‹µë³€", "ê°„ë‹¨í•œ ì§ˆë¬¸", "ì¦‰ì‹œ", "ë‹¹ì¥",
                "ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ", "ì–´ë””ì„œ"
            ]
            
            # 2. ë©€í‹°í„´ í•„ìš” í‚¤ì›Œë“œ
            multi_turn_keywords = [
                "ìƒë‹´", "ë„ì›€", "í•´ê²°", "ë¶„ì„", "ê³„íš",
                "ë‹¨ê³„ë³„", "ìì„¸íˆ", "ì²´ê³„ì ", "ì „ëµ",
                "ê¸´ê¸‰", "ë¬¸ì œ", "ê°œì„ ", "ì „ë¬¸ì "
            ]
            
            user_lower = user_input.lower()
            
            # 3. ëª…ì‹œì  ì‹±ê¸€í„´ ì²´í¬
            single_score = sum(1 for keyword in single_turn_keywords if keyword in user_lower)
            
            # 4. ë©€í‹°í„´ ìš”ì²­ ì²´í¬
            multi_score = sum(1 for keyword in multi_turn_keywords if keyword in user_lower)
            
            # 5. ë¬¸ì¥ ê¸¸ì´ ë° ë³µì¡ë„
            is_short = len(user_input) < 50
            is_simple_question = user_input.count('?') <= 1
            
            # 6. íŒë‹¨ ë¡œì§
            if single_score > 0 and multi_score == 0:
                return True  # ëª…ì‹œì  ì‹±ê¸€í„´ ìš”ì²­
            
            if multi_score > single_score:
                return False  # ë©€í‹°í„´ ìƒë‹´ ìš”ì²­
            
            if is_short and is_simple_question:
                return True  # ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ì‹±ê¸€í„´
            
            # 7. ê¸°ë³¸ê°’: ë©€í‹°í„´ (ìƒë‹´ ì„œë¹„ìŠ¤ì´ë¯€ë¡œ)
            return False
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ê¸°ë°˜ ëŒ€í™” ëª¨ë“œ íŒë‹¨ ì‹¤íŒ¨: {e}")
            return False  # ì˜¤ë¥˜ ì‹œ ë©€í‹°í„´ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì •
    
    def _process_single_turn_query(self, user_input: str, user_id: int) -> Dict[str, Any]:
        """ì‹±ê¸€í„´ ëŒ€í™” ì²˜ë¦¬"""
        try:
            # í…œí”Œë¦¿ ìš”ì²­ ì²´í¬
            if any(keyword in user_input for keyword in ["í…œí”Œë¦¿", "ë©”ì‹œì§€", "ë¬¸êµ¬", "ì•Œë¦¼"]):
                response_content = self._handle_single_turn_template_request(user_input)
            else:
                # ì¼ë°˜ ê³ ê° ì„œë¹„ìŠ¤ ì§ˆë¬¸ ì²˜ë¦¬
                response_content = self._handle_single_turn_general_query(user_input)
            
            return create_success_response({
                "answer": response_content,
                "agent_type": "customer_service",
                "mode": "single_turn",
                "timestamp": get_current_timestamp()
            })
            
        except Exception as e:
            logger.error(f"ì‹±ê¸€í„´ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return create_error_response(
                error_message=f"ì‹±ê¸€í„´ ìƒë‹´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                error_code="SINGLE_TURN_ERROR"
            )
    
    def _handle_single_turn_template_request(self, user_input: str) -> str:
        """ì‹±ê¸€í„´ í…œí”Œë¦¿ ìš”ì²­ ì²˜ë¦¬"""
        try:
            template_type = self.extract_template_type(user_input)
            templates = get_templates_by_type(template_type)
            
            if template_type == "ê³ ê° ë§ì¶¤ ë©”ì‹œì§€" and templates:
                filtered_templates = self.filter_templates_by_query(templates, user_input)
            else:
                filtered_templates = templates
            
            if filtered_templates:
                answer_blocks = []
                for t in filtered_templates:
                    if t.get("content_type") == "html":
                        preview_url = f"http://localhost:8001/preview/{t['template_id']}"
                        answer_blocks.append(f"ğŸ“‹ **{t['title']}**\n\n[HTML ë¯¸ë¦¬ë³´ê¸°]({preview_url})")
                    else:
                        answer_blocks.append(f"ğŸ“‹ **{t['title']}**\n\n{t['content']}")
                
                answer = "\n\n---\n\n".join(answer_blocks)
                answer += f"\n\nâœ… ìœ„ í…œí”Œë¦¿ë“¤ì„ ì°¸ê³ í•˜ì—¬ ê³ ê°ì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”!"
                return answer
            else:
                return f"'{template_type}' ê´€ë ¨ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
            
        except Exception as e:
            logger.error(f"ì‹±ê¸€í„´ í…œí”Œë¦¿ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return "í…œí”Œë¦¿ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _handle_single_turn_general_query(self, user_input: str, conversation_id: Optional[int] = None) -> str:
        """íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì¼ë°˜ ì¿¼ë¦¬ ì²˜ë¦¬ (ì‹±ê¸€í„´ â†’ ë©€í‹°í„´ ìŠ¤íƒ€ì¼)"""
        try:
            # 1. í† í”½ ë¶„ë¥˜
            topics = self.classify_customer_topic_with_llm(user_input)
            primary_topic = topics[0] if topics else "customer_service"

            # 2. ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
            knowledge_texts = self.get_relevant_knowledge(user_input, topics)

            # 3. íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° ì„œë¹„ìŠ¤ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ë¡œì„œ ì‹¤ìš©ì ì´ê³  ì „ë¬¸ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."}
            ]

            if conversation_id:
                with get_session_context() as db:
                    history = get_recent_messages(db, conversation_id, limit=10)
                    messages += [
                        {
                            "role": "user" if m.sender_type == "user" else "assistant",
                            "content": m.content
                        }
                        for m in history
                    ]

            # 4. ë§ˆì§€ë§‰ ì‚¬ìš©ì ë°œí™” ì¶”ê°€
            context = f"""
    ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"
    ì£¼ìš” í† í”½: {primary_topic}

    { "ê´€ë ¨ ì „ë¬¸ ì§€ì‹:\n\n" + "\n\n".join(knowledge_texts) if knowledge_texts else "" }

    ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    1. ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
    2. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²°ì±… ì œì‹œ
    3. ì¹œì ˆí•˜ê³  ê³µê°ì ì¸ ì–´ì¡° ìœ ì§€
    4. í•„ìš”ì‹œ ë‹¨ê³„ë³„ ì•ˆë‚´ ì œê³µ
    """
            messages.append({"role": "user", "content": context})

            # 5. GPT í˜¸ì¶œ
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.7)
            raw_response = llm.invoke([HumanMessage(**m) if m["role"] == "user" else SystemMessage(**m) if m["role"] == "system" else AIMessage(**m) for m in messages])
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)

            return response if response else "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."

        except Exception as e:
            logger.error(f"ì¼ë°˜ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    
    def _process_multi_turn_query(self, user_input: str, user_id: int, conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """ë©€í‹°í„´ ëŒ€í™” ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)"""
        # ëŒ€í™” ì„¸ì…˜ ì²˜ë¦¬
        session_info = get_or_create_conversation_session(user_id, conversation_id)
        conversation_id = session_info["conversation_id"]
        
        # ëŒ€í™” ìƒíƒœ ì¡°íšŒ/ìƒì„±
        state = self.get_or_create_conversation_state(conversation_id, user_id)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        with get_session_context() as db:
            create_message(db, conversation_id, "user", "customer_service", user_input)
        
        # í…œí”Œë¦¿ ìš”ì²­ ì²´í¬
        if any(keyword in user_input for keyword in ["í…œí”Œë¦¿", "ë©”ì‹œì§€", "ë¬¸êµ¬", "ì•Œë¦¼"]):
            response_content = self.handle_template_request(user_input, state)
        else:
            # ì˜ë„ ë° ë‹¨ê³„ ë¶„ì„
            intent_analysis = self.analyze_user_intent_and_stage(user_input, state)
            
            # í˜„ì¬ ë‹¨ê³„ì— ë”°ë¥¸ ì²˜ë¦¬
            if state.stage == ConversationStage.INITIAL:
                # ì´ˆê¸° ì ‘ì´‰ ì‹œ ë¬¸ì œ íŒŒì•… ë‹¨ê³„ë¡œ ì „í™˜
                state.update_stage(ConversationStage.PROBLEM_IDENTIFICATION)
                response_content = f"""ì•ˆë…•í•˜ì„¸ìš”! ê³ ê° ì„œë¹„ìŠ¤ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ğŸ¯

ê³ ê° ê´€ë¦¬ì™€ ì„œë¹„ìŠ¤ ê°œì„ ì„ ìœ„í•´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²« ë²ˆì§¸ ì§ˆë¬¸**: {list(self.info_gathering_questions.values())[0]}

ì •í™•í•œ ë¶„ì„ê³¼ í•´ê²°ì±… ì œì‹œë¥¼ ìœ„í•´ ì°¨ê·¼ì°¨ê·¼ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!"""
                
            elif state.stage == ConversationStage.PROBLEM_IDENTIFICATION:
                # ë¬¸ì œ íŒŒì•… í›„ ì •ë³´ ìˆ˜ì§‘ìœ¼ë¡œ ì „í™˜
                state.update_stage(ConversationStage.INFORMATION_GATHERING)
                response_content = self.handle_information_gathering(user_input, state, intent_analysis)
                
            elif state.stage == ConversationStage.INFORMATION_GATHERING:
                response_content = self.handle_information_gathering(user_input, state, intent_analysis)
                
            # ì¶”ê°€ ë‹¨ê³„ë“¤ì€ í•„ìš”ì‹œ êµ¬í˜„
            else:
                response_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ ë‹¨ê³„ì…ë‹ˆë‹¤."
        
        # ì‘ë‹µ ë©”ì‹œì§€ ì €ì¥
        insert_message_raw(
            conversation_id=conversation_id,
            sender_type="agent",
            agent_type="customer_service",
            content=response_content
        )
        
        # í‘œì¤€ ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        try:
            from shared_modules.standard_responses import create_customer_response
            return create_customer_response(
                conversation_id=conversation_id,
                answer=response_content,
                topics=getattr(state.analysis_results, 'primary_topics', []),
                sources=f"ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ (ë‹¨ê³„: {state.stage.value})",
                conversation_stage=state.stage.value,
                completion_rate=state.get_completion_rate(),
                collected_info=state.collected_info,
                multiturn_flow=True
            )
        except ImportError:
            # ë°±ì—…ìš© í‘œì¤€ ì‘ë‹µ
            return create_success_response({
                "conversation_id": conversation_id,
                "answer": response_content,
                "agent_type": "customer_service",
                "stage": state.stage.value,
                "completion_rate": state.get_completion_rate(),
                "timestamp": get_current_timestamp()
            })
    
    def process_user_query(
        self, 
        user_input: str, 
        user_id: int, 
        conversation_id: Optional[int] = None,
        single_turn: Optional[bool] = None
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ - ìë™ ë©€í‹°í„´/ì‹±ê¸€í„´ ëŒ€í™” ì§€ì›"""
        
        try:
            # 1. ëŒ€í™” ëª¨ë“œ ìë™ íŒë‹¨ (single_turnì´ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°)
            if single_turn is None:
                single_turn = self._determine_conversation_mode_with_history(user_input, user_id, conversation_id)
                
            logger.info(f"{'ì‹±ê¸€í„´' if single_turn else 'ë©€í‹°í„´'} ëª¨ë“œë¡œ ê³ ê° ì„œë¹„ìŠ¤ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: {user_input[:50]}...")
            
            # 2. ì‹±ê¸€í„´ ëª¨ë“œ ì²˜ë¦¬
            if single_turn:
                return self._process_single_turn_query(user_input, user_id)
            
            # 3. ë©€í‹°í„´ ëª¨ë“œ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
            return self._process_multi_turn_query(user_input, user_id, conversation_id)
            
        except Exception as e:
            logger.error(f"{'ì‹±ê¸€í„´' if single_turn else 'ë©€í‹°í„´'} ê³ ê° ì„œë¹„ìŠ¤ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return create_error_response(
                error_message=f"ê³ ê° ì„œë¹„ìŠ¤ ìƒë‹´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                error_code="CUSTOMER_SERVICE_ERROR"
            )
    
    def handle_information_gathering(self, user_input: str, state: ConversationState, intent_analysis: Dict[str, Any]) -> str:
        """ì •ë³´ ìˆ˜ì§‘ ë‹¨ê³„ ì²˜ë¦¬"""
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì •ë³´ ì¶”ì¶œ
        extracted_info = intent_analysis.get("extracted_info", {})
        
        # ìˆ˜ì§‘ëœ ì •ë³´ ì—…ë°ì´íŠ¸
        for field, value in extracted_info.items():
            if field in state.collected_info and value:
                state.add_collected_info(field, value)
        
        # ë‹¤ìŒ ì§ˆë¬¸ ê²°ì •
        missing_info = []
        for field, question in self.info_gathering_questions.items():
            if not state.collected_info.get(field):
                missing_info.append((field, question))
        
        # ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ í™•ì¸
        if state.is_information_complete() or len(missing_info) <= 2:
            # ë¶„ì„ ë‹¨ê³„ë¡œ ì „í™˜
            state.update_stage(ConversationStage.ANALYSIS)
            return self._generate_transition_to_analysis_response(state)
        
        # ë‹¤ìŒ ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸
        next_field, next_question = missing_info[0]
        
        collected_summary = []
        for field, value in state.collected_info.items():
            if value:
                collected_summary.append(f"- {self.info_gathering_questions.get(field, field)}: {value}")
        
        response = f"""ê°ì‚¬í•©ë‹ˆë‹¤! ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤:

{chr(10).join(collected_summary) if collected_summary else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

ğŸ’¡ **ë‹¤ìŒ ì§ˆë¬¸**: {next_question}

ë” ì •í™•í•œ ë§ì¶¤ í•´ê²°ì±…ì„ ìœ„í•´ ìœ„ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"""
        
        return response
    
    def _generate_transition_to_analysis_response(self, state: ConversationState) -> str:
        """ë¶„ì„ ë‹¨ê³„ë¡œ ì „í™˜ ì‹œ ì‘ë‹µ ìƒì„±"""
        collected_info_summary = []
        for field, value in state.collected_info.items():
            if value:
                field_name = self.info_gathering_questions.get(field, field)
                collected_info_summary.append(f"- {field_name}: {value}")
        
        return f"""ğŸ¯ **ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!** 

ìˆ˜ì§‘ëœ ì •ë³´:
{chr(10).join(collected_info_summary)}

ì´ì œ ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¬ì¸µ ë¶„ì„**ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. 
ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”... ğŸ“Š"""
    
    def get_agent_status(self) -> Dict[str, Any]:
        """ê³ ê° ì„œë¹„ìŠ¤ ì—ì´ì „íŠ¸ ìƒíƒœ ë°˜í™˜"""
        return {
            "agent_type": "customer_service",
            "version": "3.0.0",
            "conversation_system": "multiturn_and_singleturn",
            "stages": [stage.value for stage in ConversationStage],
            "active_conversations": len(self.conversation_states),
            "conversation_stages": {
                conv_id: state.stage.value 
                for conv_id, state in self.conversation_states.items()
            },
            "llm_status": self.llm_manager.get_status(),
            "vector_store_status": self.vector_manager.get_status(),
            "supported_features": [
                "ê³ ê° ë©”ì‹œì§€ í…œí”Œë¦¿",
                "ë©€í‹°í„´ ëŒ€í™”",
                "ì‹±ê¸€í„´ ëŒ€í™”",
                "ë¬¸ì œ íŒŒì•… ë° í•´ê²°",
                "ê³ ê° ì„¸ë¶„í™”",
                "ë§Œì¡±ë„ ë¶„ì„"
            ]
        }

    def get_relevant_knowledge(self, query: str, topics: List[str] = None) -> List[str]:
        """ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰ (ë²¡í„°DB - í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì œì™¸)"""
        try:
            # âœ… ì‹¤ì œ ì „ë¬¸ ì§€ì‹ë§Œ ê²€ìƒ‰ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ì€ ì œì™¸)
            search_results = self.vector_manager.search_documents(
                query=query,
                collection_name=self.knowledge_collection,
                k=5
            )
            
            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì€ í•„í„°ë§ ì œì™¸
            filtered_results = []
            for doc in search_results:
                # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì•„ë‹Œ ì‹¤ì œ ì§€ì‹ ì½˜í…ì¸ ë§Œ
                if doc.metadata.get('type') != 'prompt_template':
                    filtered_results.append(doc)
            
            # ì „ë¬¸ ì§€ì‹ ë‚´ìš© ì¶”ì¶œ
            knowledge_texts = []
            for doc in filtered_results[:3]:
                knowledge_area = doc.metadata.get('knowledge_area', 'ì¼ë°˜')
                content = doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content
                knowledge_texts.append(f"[{knowledge_area}]\n{content}")
            
            return knowledge_texts
            
        except Exception as e:
            logger.error(f"ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []