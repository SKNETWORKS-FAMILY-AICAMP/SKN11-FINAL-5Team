"""
ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ - ê°œì„ ëœ ë²„ì „
âœ… ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ë§¥ë½ ì´í•´ ê°œì„ , ì¹œë°€ê° ê°•í™”, ì‚¬ìš©ì í”¼ë¡œë„ ê°ì†Œ
âœ… ëª¨ë“  ì‘ë‹µ LLM ìƒì„±, í•˜ë“œì½”ë”© ì™„ì „ ì œê±°
âœ… ì‹±ê¸€í„´ ì™„ë£Œ ì§€ì›, ì œì•ˆ ëª¨ë“œ ì§€ì›
"""

import logging
from typing import Dict, Any, Optional, Tuple, List
from datetime import datetime
import asyncio

from conversation_manager import ConversationManager, MarketingStage, ConversationMode
from general_marketing_tools import MarketingTools
from mcp_marketing_tools import MarketingAnalysisTools
from config import config, create_response

logger = logging.getLogger(__name__)

# ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤
class ContentSelectionRequiredException(Exception):
    """ì½˜í…ì¸  ì„ íƒì´ í•„ìš”í•  ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸"""
    def __init__(self, message: str, tool_type_options: List[str], content_type_options: List[str]):
        self.message = message
        self.tool_type_options = tool_type_options
        self.content_type_options = content_type_options
        super().__init__(self.message)

class MarketingAgent:
    """ğŸ†• ê°œì„ ëœ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ - ì¹œë°€ê° ê°•í™”, ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ì™„ì „ LLM ê¸°ë°˜"""
    
    def __init__(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        self.conversation_manager = ConversationManager()
        self.general_marketing_tools = MarketingTools()
        self.mcp_marketing_tools = MarketingAnalysisTools()
        self.version = config.VERSION
        
        # ğŸ†• LLM ì‘ë‹µ ìƒì„± ê´€ë ¨ ì„¤ì •
        from config import config as cfg
        self.client = self.conversation_manager.client
        self.model = cfg.OPENAI_MODEL
        self.temperature = cfg.TEMPERATURE
        
        logger.info(f"ğŸ†• ê°œì„ ëœ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (v{self.version})")
    
    async def _generate_llm_response(self, prompt: str, context: str = "") -> str:
        """LLM ê¸°ë°˜ ì‘ë‹µ ìƒì„± í—¬í¼ ë©”ì„œë“œ"""
        try:
            full_prompt = f"{prompt}\n\nì»¨í…ìŠ¤íŠ¸: {context}" if context else prompt
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": full_prompt}
                ],
                temperature=self.temperature,
                max_tokens=800
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


    async def process_message(self, user_input: str, user_id: int, 
                    conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """ğŸ†• ê°œì„ ëœ ë©”ì‹œì§€ ì²˜ë¦¬ - ì¹œë°€ê° ê°•í™”, ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ì‹±ê¸€í„´ ì§€ì›"""
        start_time = datetime.now()
        
        try:
            logger.info(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘ - user_id: {user_id}, input: {user_input[:50]}...")
            
            # 1. ëŒ€í™” ìƒíƒœ ê´€ë¦¬
            conversation, is_new = self.conversation_manager.get_or_create_conversation(user_id, conversation_id)
            conversation_id = conversation.conversation_id
            
            # 3. ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì¤‘ì¸ì§€ í™•ì¸
            tool_results = None
            if conversation.is_in_content_creation():
                response_text = await self._handle_content_session(user_input, conversation)
                print(response_text)
                # âœ… ì»¨í…ì¸  ìƒì„± ì‹œê·¸ë„ í™•ì¸ ë° ì²˜ë¦¬
                if response_text.startswith("TRIGGER_"):
                    trigger_parts = response_text.split(":", 1)
                    if len(trigger_parts) == 2:
                        trigger_type, display_text = trigger_parts
                        response_text = display_text
                        
                        # âœ… ìë™í™” ì‘ì—… ìƒì„± ì²˜ë¦¬
                        if trigger_type == "TRIGGER_AUTOMATION_TASK":
                            automation_result = await self._handle_automation_task_creation(display_text, conversation)
                            if automation_result.get("success"):
                                response_text = automation_result["message"]
                            else:
                                error_context = f"ìë™í™” ì˜ˆì•½ ì‹¤íŒ¨: {automation_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                                response_text = await self._generate_llm_response(
                                    "ìë™í™” ì˜ˆì•½ì´ ì‹¤íŒ¨í–ˆì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                                    error_context
                                )
                        
                        # ì‹¤ì œ ì»¨í…ì¸  ìƒì„± ìˆ˜í–‰
                        elif trigger_type in ["TRIGGER_CONTENT_GENERATION", "TRIGGER_CONTENT_MODIFICATION", "TRIGGER_CONTENT_REGENERATION", "TRIGGER_NEW_CONTENT"]:
                            content_result = await self._handle_content_generation_with_llm(user_input, conversation)
                            if content_result and content_result.get("success"):
                                tool_results = content_result
                                formatted_content = await self._format_tool_results(content_result)
                                response_text += f"\n\n{formatted_content}"
                                
                                # ğŸ†• ì»¨í…ì¸  ì„¸ì…˜ ì—…ë°ì´íŠ¸ ë° í¬ìŠ¤íŒ… ë°ì´í„° ì„¤ì •
                                conversation.update_content_session(formatted_content, user_input)
                                conversation.current_content_for_posting = content_result
                            else:
                                error_message = await self._generate_llm_response(
                                    "ì»¨í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                                )
                                response_text += f"\n\n{error_message}"
            else:
                # 4. ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ (ê°œì„ ëœ ì‘ë‹µ ë¶„ì„ í¬í•¨)
                response_text = await self.conversation_manager.generate_response_with_context(user_input, conversation)
                
                # ğŸ†• êµ¬ì¡°í™”ëœ ì‘ë‹µ ì²˜ë¦¬ ì²´í¬
                if response_text.startswith("STRUCTURED_RESPONSE:"):
                    response_text = response_text.split(":", 1)[1]
                
                # âœ… ì»¨í…ì¸  ìƒì„± ì‹œê·¸ë„ í™•ì¸ ë° ì²˜ë¦¬
                if response_text.startswith("TRIGGER_CONTENT_GENERATION"):
                    response_text=""
                    # ì‹¤ì œ ì»¨í…ì¸  ìƒì„± ìˆ˜í–‰
                    content_result = await self._handle_content_generation_with_llm(user_input, conversation)
                    if content_result and content_result.get("success"):
                        tool_results = content_result
                        formatted_content = await self._format_tool_results(content_result)
                        response_text += f"\n\n{formatted_content}"
                        
                        # ğŸ†• ì»¨í…ì¸  ì„¸ì…˜ ì—…ë°ì´íŠ¸ ë° í¬ìŠ¤íŒ… ë°ì´í„° ì„¤ì •
                        conversation.update_content_session(formatted_content, user_input)
                        conversation.current_content_for_posting = content_result
                    else:
                        error_message = await self._generate_llm_response(
                            "ì»¨í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                        )
                        response_text += f"\n\n{error_message}"
            
            # 5. ì„±ëŠ¥ ì •ë³´
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # 6. ì‘ë‹µ ìƒì„±
            response_data = {
                "conversation_id": conversation_id,
                "user_id": user_id,
                "answer": response_text,
                "current_stage": conversation.current_stage.value,
                "current_mode": conversation.current_mode.value,
                "completion_rate": conversation.get_completion_rate(),
                "collected_info": dict(conversation.collected_info),
                "tool_results": tool_results,
                "processing_time": processing_time,
                "is_new_conversation": is_new,
                "in_content_creation": conversation.is_in_content_creation(),
                "content_session": conversation.current_content_session,
                "user_engagement_level": conversation.user_engagement_level,
                "negative_response_count": conversation.negative_response_count,
                # "features": ["improved_context", "negative_response_handling", "suggestion_mode", "singleton_completion", "no_hardcoding", "structured_responses"]
                "features": ["improved_context", "negative_response_handling", "suggestion_mode", "no_hardcoding", "structured_responses"]
            }
            
            return create_response(success=True, data=response_data)
            
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ğŸ†• ì—ëŸ¬ ë©”ì‹œì§€ë„ LLMìœ¼ë¡œ ìƒì„±
            error_message = await self._generate_llm_response(
                f"ë§ˆì¼€íŒ… ìƒë‹´ ì¤‘ ê¸°ìˆ ì  ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë„ì›€ì„ ê³„ì† ì œê³µí•˜ê² ë‹¤ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                f"ë°œìƒí•œ ì˜¤ë¥˜: {str(e)}"
            )
            
            return create_response(
                success=False,
                error=error_message,
                data={
                    "follow_up_questions": [
                        "ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì‹œê±°ë‚˜ ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
                        "ì–´ë–¤ ë§ˆì¼€íŒ… ì˜ì—­ì— ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”?",
                        "í˜„ì¬ ê°€ì¥ í° ë§ˆì¼€íŒ… ê³ ë¯¼ì´ ë¬´ì—‡ì¸ê°€ìš”?"
                    ],
                    "suggested_actions": [
                        "ë§ˆì¼€íŒ… ìƒë‹´ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°",
                        "ê¸°ë³¸ ë§ˆì¼€íŒ… ì „ëµ ìƒë‹´ë°›ê¸°"
                    ],
                    "has_follow_up_questions": True
                }
            )
   
    async def _handle_content_session(self, user_input: str, conversation, is_initial: bool = False) -> str:
        """ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì²˜ë¦¬ - ë©€í‹°í„´ ëŒ€í™” ì§€ì›"""
        try:
            # conversation_managerì˜ ì»¨í…ì¸  ì„¸ì…˜ ì²˜ë¦¬ í˜¸ì¶œ
            response_text = await self.conversation_manager._handle_content_creation_session(
                user_input, conversation, is_initial
            )
            
            # ì‹œê·¸ë„ í™•ì¸ - conversation_managerì—ì„œ ì‹œê·¸ë„ì„ ë°˜í™˜í•˜ë©´ ì—¬ê¸°ì„œ ì²˜ë¦¬
            if response_text.startswith("TRIGGER_"):
                # ì‹œê·¸ë„ì€ process_messageì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return response_text
            
            # ì¼ë°˜ ì‘ë‹µì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
            return response_text
            
        except Exception as e:
            logger.error(f"ì»¨í…ì¸  ì„¸ì…˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ğŸ†• ì—ëŸ¬ ë©”ì‹œì§€ë„ LLMìœ¼ë¡œ ìƒì„±
            return await self._generate_llm_response(
                "ì»¨í…ì¸  ì œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}"
            )
    
    def _is_greeting(self, user_input: str) -> bool:
        """ì¸ì‚¬ë§ í™•ì¸"""
        greetings = ["ì•ˆë…•", "hello", "hi", "ì²˜ìŒ", "ì‹œì‘", "ìƒë‹´", "ë„ì›€", "help"]
        return any(greeting in user_input.lower() for greeting in greetings)
    
    async def _should_generate_content_with_llm(self, user_input: str, conversation) -> bool:
        """LLM ê¸°ë°˜ ì½˜í…ì¸  ìƒì„± í•„ìš”ì„± íŒë‹¨"""
        has_enough_info = conversation.get_completion_rate() > 0.2
        is_execution_stage = conversation.current_stage in [MarketingStage.EXECUTION, MarketingStage.COMPLETED]
        
        # ì‹¤í–‰ ë‹¨ê³„ì´ê±°ë‚˜ ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ì„œ ì½˜í…ì¸  ìš”ì²­ì´ ìˆëŠ” ê²½ìš°
        return is_execution_stage or has_enough_info
    
    async def _handle_automation_task_creation(self, display_text: str, conversation) -> Dict[str, Any]:
        """ìë™í™” ì‘ì—… ìƒì„± ì²˜ë¦¬"""
        try:
            # display_textì—ì„œ scheduled_at ì¶”ì¶œ ("scheduled_at|message" í˜•ì‹)
            if "|" in display_text:
                scheduled_at_str, message = display_text.split("|", 1)
            else:
                return {
                    "success": False,
                    "error": "ìŠ¤ì¼€ì¤„ ì‹œê°„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ë‚ ì§œ íŒŒì‹±
            try:
                from datetime import datetime
                scheduled_at = datetime.fromisoformat(scheduled_at_str)
            except ValueError:
                return {
                    "success": False,
                    "error": f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {scheduled_at_str}"
                }
            
            # create_automation_task í˜¸ì¶œ
            try:
                from shared_modules.database import SessionLocal
                from shared_modules.queries import create_automation_task
                
                with SessionLocal() as db:
                    # ì»¨í…ì¸  ë°ì´í„° ì¤€ë¹„
                    content_data = conversation.current_content_for_posting or {}
                    task_data = {
                        "content_type": content_data.get("type", "general"),
                        "content": content_data.get("full_content", ""),
                        "platform": "social_media",  # ê¸°ë³¸ê°’
                        "user_id": conversation.user_id,
                        "conversation_id": conversation.conversation_id
                    }
                    
                    # ìë™í™” ì‘ì—… ìƒì„±
                    automation_task = create_automation_task(
                        db=db,
                        user_id=conversation.user_id,
                        task_type="social_posting",
                        title=f"ë§ˆì¼€íŒ… ì»¨í…ì¸  ìë™ í¬ìŠ¤íŒ…",
                        template_id=None,  # í•„ìš”ì‹œ í…œí”Œë¦¿ ID ì¶”ê°€
                        task_data=task_data,
                        conversation_id=conversation.conversation_id,
                        scheduled_at=scheduled_at
                    )
                    
                    if automation_task:
                        # í¬ìŠ¤íŒ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ
                        conversation.complete_posting_process()
                        conversation.end_content_session()
                        conversation.current_stage = MarketingStage.COMPLETED
                        
                        # ğŸ†• ì„±ê³µ ë©”ì‹œì§€ë„ LLMìœ¼ë¡œ ìƒì„±
                        success_message = await self._generate_llm_response(
                            f"ìë™í™” ì˜ˆì•½ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ê¸°ì˜ê²Œ ì•Œë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                            f"ì˜ˆì•½ ì‹œê°„: {scheduled_at.strftime('%Yë…„ %mì›” %dì¼ %H:%M')}, ì‘ì—… ID: {automation_task.task_id}"
                        )
                        
                        return {
                            "success": True,
                            "message": success_message,
                            "task_id": automation_task.task_id,
                            "scheduled_at": scheduled_at.isoformat()
                        }
                    else:
                        return {
                            "success": False,
                            "error": "ë°ì´í„°ë² ì´ìŠ¤ì— ì‘ì—… ì €ì¥ ì‹¤íŒ¨"
                        }
                        
            except Exception as db_error:
                logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {db_error}")
                return {
                    "success": False,
                    "error": f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {str(db_error)}"
                }
                
        except Exception as e:
            logger.error(f"ìë™í™” ì‘ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _handle_content_generation_with_llm(self, user_input: str, conversation) -> Optional[Dict[str, Any]]:
        """LLM ê¸°ë°˜ ì½˜í…ì¸  ìƒì„± ì²˜ë¦¬"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context = self._prepare_context_for_tools(conversation)
            
            # í•„ìˆ˜ ì •ë³´ ì²´í¬: ì§ì¢…ê³¼ íŒë§¤ ì œí’ˆ ì •ë³´
            missing_info = await self._check_required_info(context)
            if missing_info:
                return {
                    "success": False,
                    "error": missing_info,
                    "type": "missing_required_info"
                }
            
            # ì‚¬ìš©ìê°€ ì„ íƒ ì˜µì…˜ì„ ì œê³µí–ˆëŠ”ì§€ í™•ì¸
            parsed_selection = self._parse_user_selection(user_input, conversation)
            if parsed_selection:
                tool_type, content_type = parsed_selection
            else:
                # LLMì„ í†µí•œ tool_typeê³¼ content_type ë¶„ì„
                try:
                    tool_type, content_type = await self._analyze_content_type_with_llm(user_input, context)
                except ContentSelectionRequiredException as e:
                    # ì„ íƒì´ í•„ìš”í•œ ê²½ìš° ë©”ì‹œì§€ ë°˜í™˜
                    return {
                        "success": False,
                        "error": e.message,
                        "type": "selection_required",
                        "tool_options": e.tool_type_options,
                        "content_options": e.content_type_options
                    }
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (List[str] ë°˜í™˜)
            target_keywords = await self._extract_keyword_with_llm(user_input, conversation)
            
            # íˆ´ íƒ€ì…ë³„ ì‹¤í–‰
            if tool_type == "trend_analysis":
                # analyze_naver_trendsëŠ” List[str]ì„ ë°›ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬
                result = await self.general_marketing_tools.analyze_naver_trends(target_keywords)
                
            elif tool_type == "hashtag_analysis":
                # user_hashtagsëŠ” List[str]ì„ ë°›ìœ¼ë¯€ë¡œ target_keywords ê·¸ëŒ€ë¡œ ì „ë‹¬
                result = await self.general_marketing_tools.analyze_instagram_hashtags(
                    question=user_input,
                    user_hashtags=target_keywords
                )
                
            elif tool_type == "content_generation":
                # ì´ë¯¸ ìœ„ì—ì„œ ë‹¨ê³„ ì²´í¬ë¥¼ í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë°”ë¡œ ì‹¤í–‰
                if content_type == "blog":
                    # create_blog_postëŠ” strì„ ë°›ìœ¼ë¯€ë¡œ main_keyword ì „ë‹¬
                    result = await self.general_marketing_tools.create_blog_post(target_keywords, context)
                elif content_type == "instagram":
                    # create_instagram_postëŠ” strì„ ë°›ìœ¼ë¯€ë¡œ main_keyword ì „ë‹¬
                    result = await self.general_marketing_tools.create_instagram_post(target_keywords, context)
                elif content_type == "strategy":
                    result = await self.general_marketing_tools.create_strategy_content(context)
                elif content_type == "campaign":
                    result = await self.general_marketing_tools.create_campaign_content(context)
                else:
                    # ì¼ë°˜ì ì¸ ì½˜í…ì¸  ìƒì„±
                    result = "ì–´ë–¤ ì»¨í…ì¸ ë¥¼ ìƒì„±í•˜ê³  ì‹¶ìœ¼ì‹ ì§€ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”."
                    
            elif tool_type == "keyword_research":
                # analyze_naver_trendsëŠ” List[str]ì„ ë°›ìœ¼ë¯€ë¡œ target_keywords ì „ë‹¬
                trend_result = await self.mcp_marketing_tools.analyze_naver_trends(target_keywords)
                result = {
                    "success": True,
                    "keywords": target_keywords,  # List[str] ê·¸ëŒ€ë¡œ ì €ì¥
                    "trend_data": trend_result
                }
                
            else:
                return {
                    "success": False,
                    "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íˆ´ íƒ€ì…: {tool_type}",
                    "tool_type": tool_type
                }
            
            return result
                
        except Exception as e:
            logger.error(f"ì½˜í…ì¸  ìƒì„± ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "type": "content_generation"
            }
    
    async def _analyze_content_type_with_llm(self, user_input: str, context: Dict[str, Any]) -> Tuple[str, str]:
        """LLM ê¸°ë°˜ tool_typeê³¼ content_type ë¶„ì„"""
        try:
            # ì‚¬ìš©ì ì§ì¢…ê³¼ ì œí’ˆ ì •ë³´ ì¶”ì¶œ
            user_job = context.get('business_type') or context.get('job') or context.get('occupation')
            product_info = (context.get('product') or context.get('service') or 
                           context.get('target_product') or context.get('selling_product'))
            
            analysis_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… ë„êµ¬ íƒ€ì…ê³¼ ì½˜í…ì¸  íƒ€ì…ì„ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ìš”ì²­: "{user_input}"
ì‚¬ìš©ì ì§ì¢…: {user_job}
íŒë§¤ ì œí’ˆ/ì„œë¹„ìŠ¤: {product_info}
ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸: {context}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
tool_type: [trend_analysis/hashtag_analysis/content_generation/keyword_research ì¤‘ í•˜ë‚˜ë§Œ]
content_type: [instagram/blog/strategy/campaign ì¤‘ í•˜ë‚˜ë§Œ]

ë¶„ë¥˜ ê¸°ì¤€:
- trend_analysis: íŠ¸ë Œë“œ ë¶„ì„, ê²€ìƒ‰ëŸ‰ ì¡°ì‚¬
- hashtag_analysis: í•´ì‹œíƒœê·¸ ë¶„ì„, SNS ë¶„ì„
- content_generation: ì½˜í…ì¸  ìƒì„±, ê¸€ ì‘ì„±
- keyword_research: í‚¤ì›Œë“œ ì—°êµ¬, ê´€ë ¨ í‚¤ì›Œë“œ ì°¾ê¸°

- instagram: ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸, SNS ì½˜í…ì¸ 
- blog: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸, ê¸´ ê¸€ ì½˜í…ì¸ 
- strategy: ë§ˆì¼€íŒ… ì „ëµ, ì „ë°˜ì  ê³„íš
- campaign: ìº í˜ì¸, ì´ë²¤íŠ¸ ê¸°íš

ì‚¬ìš©ìì˜ ì§ì¢…ê³¼ íŒë§¤ ì œí’ˆì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë§ˆì¼€íŒ… ë„êµ¬ì™€ ì½˜í…ì¸  ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ê° í•­ëª©ì—ì„œ í•˜ë‚˜ì”©ë§Œ ì„ íƒí•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
            
            content = await self.general_marketing_tools.generate_content_with_llm(analysis_prompt)
            
            # ì‘ë‹µì—ì„œ tool_typeê³¼ content_type ì¶”ì¶œ
            content_lower = content.lower()
            
            # ì—¬ëŸ¬ ì˜µì…˜ì´ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸
            tool_type_options = self._extract_multiple_options(content, "tool_type")
            content_type_options = self._extract_multiple_options(content, "content_type")
            
            # ì—¬ëŸ¬ ì˜µì…˜ì´ ìˆìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì„ íƒ ìš”ì²­
            if len(tool_type_options) > 1 or len(content_type_options) > 1:
                await self._request_user_selection(tool_type_options, content_type_options)
            
            # ë‹¨ì¼ ì˜µì…˜ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§)
            tool_type = "content_generation"  # ê¸°ë³¸ê°’
            if "trend_analysis" in content_lower:
                tool_type = "trend_analysis"
            elif "hashtag_analysis" in content_lower:
                tool_type = "hashtag_analysis"
            elif "keyword_research" in content_lower:
                tool_type = "keyword_research"
            elif "content_generation" in content_lower:
                tool_type = "content_generation"
            
            # content_type ì¶”ì¶œ
            content_type = "instagram"  # ê¸°ë³¸ê°’
            if "blog" in content_lower:
                content_type = "blog"
            elif "strategy" in content_lower:
                content_type = "strategy"
            elif "campaign" in content_lower:
                content_type = "campaign"
            elif "instagram" in content_lower:
                content_type = "instagram"
            
            return tool_type, content_type
                
        except Exception as e:
            logger.warning(f"ì½˜í…ì¸  íƒ€ì… ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "content_generation", "instagram"
    
    def _extract_multiple_options(self, content: str, option_type: str) -> List[str]:
        """ì‘ë‹µì—ì„œ ì—¬ëŸ¬ ì˜µì…˜ì´ ì„ íƒë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        try:
            lines = content.split('\n')
            for line in lines:
                if option_type in line.lower():
                    # [option1/option2/option3] í˜•íƒœ ì°¾ê¸°
                    if '[' in line and ']' in line:
                        options_text = line[line.find('[')+1:line.find(']')]
                        if '/' in options_text:
                            options = [opt.strip() for opt in options_text.split('/')]
                            # ìœ íš¨í•œ ì˜µì…˜ë“¤ë§Œ í•„í„°ë§
                            valid_options = []
                            if option_type == "tool_type":
                                valid_types = ["trend_analysis", "hashtag_analysis", "content_generation", "keyword_research"]
                                valid_options = [opt for opt in options if opt in valid_types]
                            elif option_type == "content_type":
                                valid_types = ["instagram", "blog", "strategy", "campaign"]
                                valid_options = [opt for opt in options if opt in valid_types]
                            
                            return valid_options if len(valid_options) > 1 else []
            return []
        except Exception as e:
            logger.warning(f"ì˜µì…˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def _request_user_selection(self, tool_type_options: List[str], content_type_options: List[str]):
        """ì‚¬ìš©ìì—ê²Œ ì„ íƒì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ ìƒì„± - LLM ê¸°ë°˜"""
        
        # ğŸ†• LLMìœ¼ë¡œ ì„ íƒ ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
        selection_context = f"""
        ë§ˆì¼€íŒ… ë„êµ¬ ì˜µì…˜: {tool_type_options}
        ì½˜í…ì¸  ìœ í˜• ì˜µì…˜: {content_type_options}
        """
        
        selection_message = await self._generate_llm_response(
            "ì‚¬ìš©ìì—ê²Œ ë§ˆì¼€íŒ… ë„êµ¬ ìœ í˜•ê³¼ ì½˜í…ì¸  ìœ í˜•ì„ ì„ íƒí•˜ë„ë¡ ì¹œê·¼í•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ê° ì˜µì…˜ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…ë„ í¬í•¨í•´ì£¼ì„¸ìš”.",
            selection_context
        )
        
        # ì„ íƒ ìš”ì²­ ì˜ˆì™¸ ë°œìƒ (ì´ë¥¼ í†µí•´ ìƒìœ„ì—ì„œ ì²˜ë¦¬)
        raise ContentSelectionRequiredException(selection_message, tool_type_options, content_type_options)
    
    async def _extract_keyword_with_llm(self, user_input: str, conversation) -> List[str]:
        """LLM ê¸°ë°˜ í‚¤ì›Œë“œ 10ê°œ ì¶”ì¶œ"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì œí’ˆ ì •ë³´ ì¶”ì¶œ
            context = self._prepare_context_for_tools(conversation)
            product_info = (
                context.get('product') or context.get('service') or
                context.get('target_product') or context.get('selling_product')
            )
            
            keyword_prompt = f"""
            ë‹¤ìŒ ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬ ë§ˆì¼€íŒ… ì½˜í…ì¸  ìƒì„±ì— ìœ ìš©í•œ í•µì‹¬ í‚¤ì›Œë“œ 10ê°œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.

            ì‚¬ìš©ì ìš”ì²­: "{user_input}"
            ì§ì¢…/ì—…ì¢…: {conversation.business_type}
            íŒë§¤ ì œí’ˆ/ì„œë¹„ìŠ¤: {product_info}
            ìˆ˜ì§‘ëœ ì •ë³´: {conversation.collected_info}

            ì¡°ê±´:
            1. ë§ˆì¼€íŒ… íš¨ê³¼ê°€ ë†’ì€ í•µì‹¬ í‚¤ì›Œë“œ 10ê°œë¥¼ í•œ ì¤„ì— í•˜ë‚˜ì”© ì¶œë ¥í•˜ì„¸ìš”.
            2. ì¤‘ë³µë˜ëŠ” ë‹¨ì–´ ì—†ì´ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
            3. ë¶ˆí•„ìš”í•œ ë¬¸ì¥ ì—†ì´ í‚¤ì›Œë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
            """

            content = await self.general_marketing_tools.generate_content_with_llm(keyword_prompt)
            
            # ê° ì¤„ì„ í‚¤ì›Œë“œë¡œ ë¶„ë¦¬í•˜ê³  ê³µë°± ì œê±°
            keywords = [kw.strip() for kw in content.splitlines() if kw.strip()]
            
            # 10ê°œë¡œ ì œí•œ (í˜¹ì‹œ ëª¨ë¸ì´ ë” ë§ì´ ì‘ë‹µí•  ê²½ìš° ëŒ€ë¹„)
            return keywords[:10] if keywords else ["ë§ˆì¼€íŒ…"]

        except Exception as e:
            logger.warning(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ["ë§ˆì¼€íŒ…"]

            
        except Exception as e:
            logger.warning(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # í´ë°±: ì—…ì¢… ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
            return conversation.business_type if conversation.business_type != "ì¼ë°˜" else "ë§ˆì¼€íŒ…"
    
    def _parse_user_selection(self, user_input: str, conversation) -> Optional[Tuple[str, str]]:
        """ì‚¬ìš©ìì˜ ì„ íƒ ì…ë ¥ì„ íŒŒì‹±"""
        user_input_lower = user_input.lower()
        
        # ìˆ«ì ì„ íƒ ë˜ëŠ” ì§ì ‘ ëª…ì‹œí•œ ì„ íƒ ì²˜ë¦¬
        tool_type = None
        content_type = None
        
        # Tool type íŒŒì‹±
        if any(word in user_input_lower for word in ["íŠ¸ë Œë“œ", "trend", "ê²€ìƒ‰ëŸ‰", "ë¶„ì„"]):
            tool_type = "trend_analysis"
        elif any(word in user_input_lower for word in ["í•´ì‹œíƒœê·¸", "hashtag", "sns"]):
            tool_type = "hashtag_analysis"
        elif any(word in user_input_lower for word in ["ì½˜í…ì¸ ", "content", "ìƒì„±", "ì‘ì„±"]):
            tool_type = "content_generation"
        elif any(word in user_input_lower for word in ["í‚¤ì›Œë“œ", "keyword", "ì—°êµ¬"]):
            tool_type = "keyword_research"
        
        # Content type íŒŒì‹±
        if any(word in user_input_lower for word in ["ì¸ìŠ¤íƒ€", "instagram", "ì¸ìŠ¤íƒ€ê·¸ë¨"]):
            content_type = "instagram"
        elif any(word in user_input_lower for word in ["ë¸”ë¡œê·¸", "blog"]):
            content_type = "blog"
        elif any(word in user_input_lower for word in ["ì „ëµ", "strategy"]):
            content_type = "strategy"
        elif any(word in user_input_lower for word in ["ìº í˜ì¸", "campaign"]):
            content_type = "campaign"
        
        # ìˆ«ì ì„ íƒ ì²˜ë¦¬ (1, 2, 3, 4)
        if tool_type is None:
            if "1" in user_input or "ì²«" in user_input:
                tool_type = "trend_analysis"
            elif "2" in user_input or "ë‘" in user_input:
                tool_type = "hashtag_analysis"
            elif "3" in user_input or "ì„¸" in user_input:
                tool_type = "content_generation"
            elif "4" in user_input or "ë„¤" in user_input:
                tool_type = "keyword_research"
        
        if content_type is None:
            if "1" in user_input or "ì²«" in user_input:
                content_type = "instagram"
            elif "2" in user_input or "ë‘" in user_input:
                content_type = "blog"
            elif "3" in user_input or "ì„¸" in user_input:
                content_type = "strategy"
            elif "4" in user_input or "ë„¤" in user_input:
                content_type = "campaign"
        
        # ë‘˜ ë‹¤ ì„ íƒë˜ì—ˆìœ¼ë©´ ë°˜í™˜
        if tool_type and content_type:
            return tool_type, content_type
        
        return None
    
    async def _check_required_info(self, context: Dict[str, Any]) -> Optional[str]:
        """ì»¨í…ì¸  ìƒì„±ì— í•„ìš”í•œ í•„ìˆ˜ ì •ë³´ ì²´í¬ - LLM ê¸°ë°˜"""
        missing_items = []
        
        # 1. ì§ì¢… ì •ë³´ ì²´í¬
        user_job = context.get("business_type") or context.get("job") or context.get("occupation")
        if not user_job or user_job == "ì¼ë°˜":
            missing_items.append("ì§ì¢…/ì—…ì¢…")
        
        # 2. íŒë§¤ ì œí’ˆ ì •ë³´ ì²´í¬
        product_info = (context.get("product") or context.get("service") or 
                       context.get("target_product") or context.get("selling_product"))
        if not product_info:
            missing_items.append("íŒë§¤ ì œí’ˆ/ì„œë¹„ìŠ¤")
        
        if missing_items:
            # ğŸ†• LLMìœ¼ë¡œ í•„ìˆ˜ ì •ë³´ ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
            missing_info_message = await self._generate_llm_response(
                f"ì»¨í…ì¸  ìƒì„±ì„ ìœ„í•´ ë‹¤ìŒ í•„ìˆ˜ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì¹œê·¼í•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”: {', '.join(missing_items)}"
            )
            return missing_info_message
        
        return None
    
    def _prepare_context_for_tools(self, conversation) -> Dict[str, Any]:
        """ë„êµ¬ìš© ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        context = {}
        
        # ìˆ˜ì§‘ëœ ì •ë³´ì—ì„œ ê°’ ì¶”ì¶œ
        for key, info in conversation.collected_info.items():
            context[key] = info["value"]
        
        # ê¸°ë³¸ ê°’ ì„¤ì •
        context.setdefault("business_type", conversation.business_type)
        context.setdefault("current_stage", conversation.current_stage.value)
        
        return context
    
    async def _format_tool_results(self, tool_results: Dict[str, Any]) -> str:
        """ë„êµ¬ ê²°ê³¼ í¬ë§·íŒ… - LLM ê¸°ë°˜"""
        if not tool_results.get("success"):
            error_type = tool_results.get("type", "general_error")
            
            if error_type == "selection_required":
                # ì‚¬ìš©ì ì„ íƒ ìš”ì²­ ë©”ì‹œì§€
                return tool_results.get("error", "ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
            elif error_type == "missing_required_info":
                # í•„ìˆ˜ ì •ë³´ ë¶€ì¡± ë©”ì‹œì§€
                return tool_results.get("error", "í•„ìˆ˜ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                # ğŸ†• ì¼ë°˜ ì˜¤ë¥˜ë„ LLMìœ¼ë¡œ ì²˜ë¦¬
                error_message = await self._generate_llm_response(
                    "ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                    f"ì˜¤ë¥˜ ë‚´ìš©: {tool_results.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                )
                return error_message
        
        # í‚¤ì›Œë“œ ë¦¬ì„œì¹˜ ê²°ê³¼ì¸ì§€ í™•ì¸ (keywordsì™€ trend_dataê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°)
        if 'keywords' in tool_results and 'trend_data' in tool_results:
            return await self._format_keyword_research_result(tool_results)
        
        content_type = tool_results.get("type", "content")
        
        if content_type == "instagram_post":
            return await self._format_instagram_result(tool_results)
        elif content_type == "blog_post":
            return await self._format_blog_result(tool_results)
        elif content_type == "marketing_strategy":
            # ğŸ†• LLMìœ¼ë¡œ ì „ëµ ê²°ê³¼ í¬ë§·íŒ…
            strategy_message = await self._generate_llm_response(
                "ë§ˆì¼€íŒ… ì „ëµì´ ì™„ì„±ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë°ì€í†¤ìœ¼ë¡œ ì•Œë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                f"ì „ëµ ë‚´ìš©: {tool_results.get('strategy', '')}"
            )
            return strategy_message
        else:
            # ğŸ†• ê¸°íƒ€ ì½˜í…ì¸ ë„ LLMìœ¼ë¡œ í¬ë§·íŒ…
            content_message = await self._generate_llm_response(
                f"{content_type} ìƒì„±ì´ ì™„ë£Œë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë°ì€í†¤ìœ¼ë¡œ ì•Œë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                f"ìƒì„±ëœ ë‚´ìš©: {tool_results.get('full_content', str(tool_results))}"
            )
            return content_message
    
    async def _format_instagram_result(self, result: Dict[str, Any]) -> str:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ê²°ê³¼ í¬ë§·íŒ… - LLM ê¸°ë°˜"""
        instagram_context = f"""
        ìº¡ì…˜: {result.get('caption', '')}
        í•´ì‹œíƒœê·¸: {result.get('hashtags', '')}
        CTA: {result.get('cta', '')}
        """
        
        formatted_message = await self._generate_llm_response(
            "ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ê°€ ì™„ì„±ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë°ì€í†¤ìœ¼ë¡œ ì•Œë¦¬ê³ , ìº¡ì…˜, í•´ì‹œíƒœê·¸, CTAë¥¼ ì˜ˆì˜ê²Œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
            instagram_context
        )
        return formatted_message
    
    async def _format_blog_result(self, result: Dict[str, Any]) -> str:
        """ë¸”ë¡œê·¸ ê²°ê³¼ í¬ë§·íŒ… - LLM ê¸°ë°˜"""
        blog_context = f"""
        ì œëª©: {result.get('title', '')}
        ëª©ì°¨: {result.get('outline', '')}
        ë³¸ë¬¸: {result.get('body', '')[:500]}{'...' if len(result.get('body', '')) > 500 else ''}
        í‚¤ì›Œë“œ: {result.get('keywords', '')}
        """
        
        formatted_message = await self._generate_llm_response(
            "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ê°€ ì™„ì„±ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë°ì€í†¤ìœ¼ë¡œ ì•Œë¦¬ê³ , ì œëª©, ëª©ì°¨, ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°, SEO í‚¤ì›Œë“œë¥¼ ì˜ˆì˜ê²Œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
            blog_context
        )
        return formatted_message
    
    async def _format_keyword_research_result(self, result: Dict[str, Any]) -> str:
        """í‚¤ì›Œë“œ ë¦¬ì„œì¹˜ ê²°ê³¼ í¬ë§·íŒ… - LLM ê¸°ë°˜"""
        keyword_context = f"""
        ì¶”ì²œ í‚¤ì›Œë“œ: {result.get('keywords', [])}
        íŠ¸ë Œë“œ ë°ì´í„°: {result.get('trend_data', {})}
        """
        
        formatted_message = await self._generate_llm_response(
            "ë°ì€í†¤ìœ¼ë¡œ ì¶”ì²œ í‚¤ì›Œë“œì™€ íŠ¸ë Œë“œ ë¶„ì„ì„ ì˜ˆì˜ê²Œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë§ˆì¼€íŒ… í™œìš© íŒë„ í¬í•¨í•´ì£¼ì„¸ìš”.",
            keyword_context
        )
        return formatted_message
    
    def get_conversation_status(self, conversation_id: int) -> Dict[str, Any]:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ"""
        return self.conversation_manager.get_conversation_summary(conversation_id)
    
    def get_agent_status(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ"""
        # ë§Œë£Œëœ ëŒ€í™” ì •ë¦¬
        cleaned_count = self.conversation_manager.cleanup_expired_conversations()
        
        return {
            "version": self.version,
            "service_name": config.SERVICE_NAME,
            "status": "healthy",
            "intelligence_type": "improved_llm_based",
            "active_conversations": len(self.conversation_manager.conversations),
            "cleaned_conversations": cleaned_count,
            "available_tools": len(self.general_marketing_tools.get_available_tools()),
            "llm_capabilities": [
                "ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€",
                "ë¶€ì •ì  ì‘ë‹µ ê°ì§€ ë° ì²˜ë¦¬",
                "ì œì•ˆ ëª¨ë“œ ìë™ ì „í™˜",
                "ì¹œë°€ê° ê°•í™”ëœ ëŒ€í™”",
                "ì‹±ê¸€í„´ ì™„ë£Œ ì§€ì›",
                "ì™„ì „ LLM ê¸°ë°˜ ì‘ë‹µ (í•˜ë“œì½”ë”© ì œê±°)"
            ],
            "features": [
                "ê°œì„ ëœ ë§¥ë½ ì´í•´",
                "ì§ˆë¬¸ í”¼ë¡œë„ ë°©ì§€",
                "ë§ì¶¤í˜• ì¦‰ì‹œ ì œì•ˆ",
                "ë‹¤ì–‘í•œ í†¤ ë³€í™”",
                "ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„",
                "ë‹¨ë°©í–¥ ëª¨ë“œ ì „í™˜",
                "ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ìƒì„±",
                "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„±",
                "ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½",
                "í‚¤ì›Œë“œ ë¶„ì„",
                "êµ¬ì¡°í™”ëœ ì‘ë‹µ ì‹œìŠ¤í…œ",
                "ì§€ëŠ¥í˜• í›„ì† ì§ˆë¬¸ ìƒì„±",
                "ë‹¨ê³„ë³„ ë§ì¶¤ ì•¡ì…˜ ì œì•ˆ"
            ],
            "supported_business_types": [
                "ë·°í‹°/ë¯¸ìš©", "ìŒì‹ì /ì¹´í˜", "ì˜¨ë¼ì¸ì‡¼í•‘ëª°", 
                "ì„œë¹„ìŠ¤ì—…", "êµìœ¡", "í—¬ìŠ¤ì¼€ì–´", "ì œì¡°ì—…", "í¬ë¦¬ì—ì´í„°"
            ],
            "conversation_improvements": {
                "negative_response_handling": "ë¶€ì •ì  ì‘ë‹µ ìë™ ê°ì§€ ë° ì œì•ˆ ëª¨ë“œ ì „í™˜",
                "question_fatigue_prevention": "ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€ ë° ì§ì ‘ ì œì•ˆ",
                "personalized_suggestions": "ìˆ˜ì§‘ ì •ë³´ ê¸°ë°˜ ë§ì¶¤í˜• ì¶”ì²œ",
                "natural_tone_variation": "ë‹¤ì–‘í•œ í†¤ê³¼ ì¹œë°€í•œ í‘œí˜„",
                # "singleton_completion": "ì¦‰ì‹œ ë‹µë³€ ê°€ëŠ¥í•œ ìš”ì²­ ë‹¨ì¼í„´ ì™„ë£Œ",
                "no_hardcoding": "ëª¨ë“  ì‘ë‹µ LLM ìƒì„±",
                "structured_responses": "ë©”ì¸ ì‘ë‹µ + í›„ì† ì§ˆë¬¸ êµ¬ì¡°í™”ëœ ì‘ë‹µ ì‹œìŠ¤í…œ",
                "intelligent_follow_ups": "ë‹¨ê³„ë³„ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§€ëŠ¥í˜• í›„ì† ì§ˆë¬¸",
                "dynamic_action_suggestions": "ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ë™ì  ì•¡ì…˜ ì œì•ˆ"
            }
        }
    
    async def reset_conversation(self, conversation_id: int) -> bool:
        """ëŒ€í™” ì´ˆê¸°í™”"""
        if conversation_id in self.conversation_manager.conversations:
            del self.conversation_manager.conversations[conversation_id]
            logger.info(f"ëŒ€í™” ì´ˆê¸°í™” ì™„ë£Œ: {conversation_id}")
            return True
        return False
    
    async def batch_process(self, messages: list) -> Dict[str, Any]:
        """ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            results = []
            
            for message_data in messages:
                result = await self.process_message(
                    user_input=message_data.get("message", ""),
                    user_id=message_data.get("user_id", 0),
                    conversation_id=message_data.get("conversation_id")
                )
                results.append(result)
                
                # ê³¼ë¶€í•˜ ë°©ì§€
                await asyncio.sleep(0.1)
            
            return create_response(
                success=True,
                data={
                    "batch_results": results,
                    "processed_count": len(results),
                    "success_count": len([r for r in results if r.get("success")])
                }
            )
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            # ğŸ†• ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ë©”ì‹œì§€ë„ LLMìœ¼ë¡œ ìƒì„±
            error_message = await self._generate_llm_response(
                "ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ê°œë³„ ë©”ì‹œì§€ë¡œ ë‹¤ì‹œ ì‹œë„ë¥¼ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.",
                f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}"
            )
            
            return create_response(
                success=False,
                error=error_message
            )
