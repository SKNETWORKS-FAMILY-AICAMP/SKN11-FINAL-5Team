"""
LangGraph ê¸°ë°˜ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ - ë©”ì¸ í´ë˜ìŠ¤
ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜ì„± ìœ ì§€í•˜ë©´ì„œ LangGraph ì›Œí¬í”Œë¡œìš° í™œìš©
"""

import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import asyncio

from marketing_workflow import marketing_workflow
from config import config, create_response

logger = logging.getLogger(__name__)

class MarketingAgent:
    """LangGraph ê¸°ë°˜ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜"""
    
    def __init__(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        self.workflow = marketing_workflow
        self.version = config.VERSION
        
        logger.info(f"ğŸš€ LangGraph ê¸°ë°˜ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (v{self.version})")
    
    async def process_message(self, user_input: str, user_id: int, 
                             conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ì²˜ë¦¬ - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
        start_time = datetime.now()
        
        try:
            logger.info(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘ - user_id: {user_id}, input: {user_input[:50]}...")
            
            # conversation_idê°€ ì—†ìœ¼ë©´ ìƒì„±
            if conversation_id is None:
                conversation_id = self._generate_conversation_id(user_id)
            
            # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await self.workflow.process_message(user_id, conversation_id, user_input)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # ê¸°ì¡´ í˜•ì‹ì— ë§ê²Œ ì‘ë‹µ ì¡°ì •
            if result.get("success"):
                data = result["data"]
                data.update({
                    "processing_time": processing_time,
                    "is_new_conversation": conversation_id != conversation_id,  # ìƒˆ ëŒ€í™” ì—¬ë¶€ëŠ” ë³„ë„ ë¡œì§ í•„ìš”
                    "workflow_engine": "langraph",
                    "features": [
                        "langraph_workflow",
                        "state_management", 
                        "conditional_routing",
                        "memory_persistence",
                        "error_recovery"
                    ]
                })
            else:
                # ì—ëŸ¬ ì‘ë‹µë„ ê¸°ì¡´ í˜•ì‹ ìœ ì§€
                data = result.get("data", {})
                data.update({
                    "processing_time": processing_time,
                    "workflow_engine": "langraph"
                })
            
            return result
            
        except Exception as e:
            logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return create_response(
                success=False,
                error=f"ë§ˆì¼€íŒ… ìƒë‹´ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                data={
                    "conversation_id": conversation_id,
                    "user_id": user_id,
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "processing_time": processing_time,
                    "workflow_engine": "langraph",
                    "error_type": "system_error"
                }
            )
    
    def get_conversation_status(self, conversation_id: int) -> Dict[str, Any]:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
        try:
            status = self.workflow.get_conversation_status(conversation_id)
            return status
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": f"ëŒ€í™” ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "conversation_id": conversation_id,
                "workflow_engine": "langraph"
            }
    
    async def reset_conversation(self, conversation_id: int) -> bool:
        """ëŒ€í™” ì´ˆê¸°í™” - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
        try:
            success = await self.workflow.reset_conversation(conversation_id)
            if success:
                logger.info(f"ëŒ€í™” ì´ˆê¸°í™” ì™„ë£Œ: {conversation_id}")
            return success
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def get_agent_status(self) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
        try:
            workflow_info = self.workflow.get_workflow_info()
            
            return {
                "version": self.version,
                "service_name": config.SERVICE_NAME,
                "status": "healthy",
                "workflow_engine": "langraph",
                "workflow_info": workflow_info,
                "capabilities": [
                    "multi_stage_consultation",
                    "adaptive_conversation_flow",
                    "content_generation",
                    "business_analysis",
                    "strategy_planning",
                    "execution_guidance"
                ],
                "langraph_features": [
                    "stateful_workflow",
                    "conditional_routing", 
                    "memory_persistence",
                    "error_recovery",
                    "checkpoint_support",
                    "async_processing"
                ],
                "improvements_over_previous": [
                    "ë” ëª…í™•í•œ ìƒíƒœ ê´€ë¦¬",
                    "ì¡°ê±´ë¶€ ë¼ìš°íŒ…ìœ¼ë¡œ ìœ ì—°í•œ ëŒ€í™” íë¦„",
                    "ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¸ì…˜ ì§€ì†ì„±",
                    "ì²´ê³„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬",
                    "ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜",
                    "í™•ì¥ ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°"
                ]
            }
            
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "version": self.version,
                "service_name": config.SERVICE_NAME,
                "status": "error",
                "error": str(e),
                "workflow_engine": "langraph"
            }
    
    async def batch_process(self, messages: list) -> Dict[str, Any]:
        """ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬ - ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ í˜¸í™˜"""
        try:
            results = []
            
            for message_data in messages:
                result = await self.process_message(
                    user_input=message_data.get("message", ""),
                    user_id=message_data.get("user_id", 0),
                    conversation_id=message_data.get("conversation_id")
                )
                results.append(result)
                
                # ë°°ì¹˜ ì²˜ë¦¬ ê°„ ë”œë ˆì´
                await asyncio.sleep(0.1)
            
            success_count = len([r for r in results if r.get("success")])
            
            return create_response(
                success=True,
                data={
                    "batch_results": results,
                    "processed_count": len(results),
                    "success_count": success_count,
                    "workflow_engine": "langraph"
                }
            )
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
            return create_response(
                success=False,
                error=f"ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                data={
                    "workflow_engine": "langraph"
                }
            )
    
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    
    def _generate_conversation_id(self, user_id: int) -> int:
        """ëŒ€í™” ID ìƒì„±"""
        import time
        return int(f"{user_id}{int(time.time())}")
    
    # ì¶”ê°€ LangGraph íŠ¹í™” ë©”ì„œë“œë“¤
    
    def get_workflow_diagram(self) -> Dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ì •ë³´ (LangGraph ì „ìš©)"""
        try:
            # LangGraphì˜ ì›Œí¬í”Œë¡œìš° êµ¬ì¡°ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„
            workflow_structure = {
                "nodes": [
                    {
                        "id": "initial_consultation",
                        "label": "ì´ˆê¸° ìƒë‹´",
                        "description": "ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ ë° ìƒë‹´ ì‹œì‘"
                    },
                    {
                        "id": "goal_setting", 
                        "label": "ëª©í‘œ ì„¤ì •",
                        "description": "ë§ˆì¼€íŒ… ëª©í‘œ ë° ì›í•˜ëŠ” ê²°ê³¼ ì„¤ì •"
                    },
                    {
                        "id": "target_analysis",
                        "label": "íƒ€ê²Ÿ ë¶„ì„", 
                        "description": "ê³ ê°ì¸µ ë° ì‹œì¥ ë¶„ì„"
                    },
                    {
                        "id": "strategy_planning",
                        "label": "ì „ëµ ê¸°íš",
                        "description": "êµ¬ì²´ì  ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½"
                    },
                    {
                        "id": "content_creation",
                        "label": "ì½˜í…ì¸  ìƒì„±",
                        "description": "ì‹¤ì œ ë§ˆì¼€íŒ… ì½˜í…ì¸  ì œì‘"
                    },
                    {
                        "id": "content_feedback",
                        "label": "í”¼ë“œë°± ì²˜ë¦¬",
                        "description": "ì½˜í…ì¸ ì— ëŒ€í•œ í”¼ë“œë°± ìˆ˜ì§‘ ë° ë°˜ì˜"
                    },
                    {
                        "id": "execution_guidance",
                        "label": "ì‹¤í–‰ ê°€ì´ë“œ",
                        "description": "ë§ˆì¼€íŒ… ì‹¤í–‰ ë°©ë²• ì•ˆë‚´"
                    },
                    {
                        "id": "error_handler",
                        "label": "ì—ëŸ¬ ì²˜ë¦¬",
                        "description": "ì˜¤ë¥˜ ìƒí™© ì²˜ë¦¬ ë° ë³µêµ¬"
                    }
                ],
                "edges": [
                    {"from": "START", "to": "initial_consultation"},
                    {"from": "initial_consultation", "to": "goal_setting", "condition": "ì •ë³´ ì¶©ì¡±"},
                    {"from": "goal_setting", "to": "target_analysis", "condition": "ëª©í‘œ ì„¤ì • ì™„ë£Œ"},
                    {"from": "target_analysis", "to": "strategy_planning", "condition": "íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ"},
                    {"from": "strategy_planning", "to": "content_creation", "condition": "ì½˜í…ì¸  ìš”ì²­"},
                    {"from": "content_creation", "to": "content_feedback", "condition": "ì½˜í…ì¸  ìƒì„± ì™„ë£Œ"},
                    {"from": "content_feedback", "to": "execution_guidance", "condition": "ìŠ¹ì¸"},
                    {"from": "content_feedback", "to": "content_creation", "condition": "ìˆ˜ì • ìš”ì²­"},
                    {"from": "execution_guidance", "to": "END"},
                    {"from": "*", "to": "error_handler", "condition": "ì˜¤ë¥˜ ë°œìƒ"}
                ],
                "workflow_type": "langraph_stateful"
            }
            
            return {
                "success": True,
                "workflow_structure": workflow_structure,
                "visualization_url": "/workflow/diagram",  # ì‹¤ì œ ì‹œê°í™” ì—”ë“œí¬ì¸íŠ¸
                "mermaid_diagram": self._generate_mermaid_diagram()
            }
            
        except Exception as e:
            logger.error(f"ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _generate_mermaid_diagram(self) -> str:
        """Mermaid ë‹¤ì´ì–´ê·¸ë¨ ì½”ë“œ ìƒì„±"""
        return """
graph TD
    START([ì‹œì‘]) --> IC[ì´ˆê¸° ìƒë‹´]
    IC --> GS[ëª©í‘œ ì„¤ì •]
    IC --> IC
    GS --> TA[íƒ€ê²Ÿ ë¶„ì„]
    GS --> GS
    TA --> SP[ì „ëµ ê¸°íš]
    TA --> TA
    SP --> CC[ì½˜í…ì¸  ìƒì„±]
    SP --> SP
    CC --> CF[í”¼ë“œë°± ì²˜ë¦¬]
    CF --> CC
    CF --> EG[ì‹¤í–‰ ê°€ì´ë“œ]
    EG --> END([ì™„ë£Œ])
    IC --> EH[ì—ëŸ¬ ì²˜ë¦¬]
    GS --> EH
    TA --> EH
    SP --> EH
    CC --> EH
    CF --> EH
    EG --> EH
    EH --> IC
    EH --> END
    
    classDef startEnd fill:#e1f5fe
    classDef process fill:#f3e5f5
    classDef decision fill:#fff3e0
    classDef error fill:#ffebee
    
    class START,END startEnd
    class IC,GS,TA,SP,CC,CF,EG process
    class EH error
"""
    
    def get_conversation_flow_analysis(self, conversation_id: int) -> Dict[str, Any]:
        """ëŒ€í™” íë¦„ ë¶„ì„ (LangGraph ì „ìš©)"""
        try:
            status = self.get_conversation_status(conversation_id)
            
            if status.get("status") == "not_found":
                return {
                    "success": False,
                    "error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                }
            
            # ëŒ€í™” íë¦„ ë¶„ì„
            analysis = {
                "conversation_id": conversation_id,
                "current_stage": status.get("current_stage"),
                "progression": self._analyze_stage_progression(status),
                "efficiency_score": self._calculate_efficiency_score(status),
                "recommendations": self._get_flow_recommendations(status),
                "workflow_performance": {
                    "stages_completed": self._count_completed_stages(status),
                    "completion_rate": status.get("completion_rate", 0),
                    "estimated_remaining_time": self._estimate_remaining_time(status)
                }
            }
            
            return {
                "success": True,
                "flow_analysis": analysis
            }
            
        except Exception as e:
            logger.error(f"ëŒ€í™” íë¦„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _analyze_stage_progression(self, status: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ë‹¨ê³„ ì§„í–‰ ë¶„ì„"""
        # êµ¬í˜„ ì˜ˆì •
        return []
    
    def _calculate_efficiency_score(self, status: Dict[str, Any]) -> float:
        """íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        completion_rate = status.get("completion_rate", 0)
        message_count = status.get("message_count", 1)
        
        # ê°„ë‹¨í•œ íš¨ìœ¨ì„± ê³„ì‚° (ë©”ì‹œì§€ ìˆ˜ ëŒ€ë¹„ ì™„ë£Œìœ¨)
        efficiency = completion_rate * 100 / max(message_count, 1)
        return min(efficiency, 100.0)
    
    def _get_flow_recommendations(self, status: Dict[str, Any]) -> List[str]:
        """íë¦„ ê°œì„  ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        completion_rate = status.get("completion_rate", 0)
        current_stage = status.get("current_stage", "")
        
        if completion_rate < 0.3:
            recommendations.append("ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ì„ ì™„ë£Œí•˜ë©´ ë” ì •í™•í•œ ì¡°ì–¸ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        if current_stage == "strategy_planning" and completion_rate > 0.6:
            recommendations.append("ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë‹ˆ ì½˜í…ì¸  ìƒì„±ì„ ì‹œì‘í•´ë³´ì„¸ìš”")
        
        return recommendations
    
    def _count_completed_stages(self, status: Dict[str, Any]) -> int:
        """ì™„ë£Œëœ ë‹¨ê³„ ìˆ˜ ê³„ì‚°"""
        # êµ¬í˜„ ì˜ˆì •
        return 0
    
    def _estimate_remaining_time(self, status: Dict[str, Any]) -> str:
        """ë‚¨ì€ ì˜ˆìƒ ì‹œê°„"""
        completion_rate = status.get("completion_rate", 0)
        
        if completion_rate < 0.3:
            return "5-10ë¶„"
        elif completion_rate < 0.7:
            return "3-5ë¶„"
        else:
            return "1-3ë¶„"

# ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
marketing_agent = MarketingAgent()
