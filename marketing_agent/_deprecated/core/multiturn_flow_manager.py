"""
4ë‹¨ê³„ ì²´ê³„ì  ë©€í‹°í„´ ì§„í–‰ ê´€ë¦¬ ëª¨ë“ˆ
"""

import json
import logging
from typing import Dict, Any, Optional, Tuple
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from .enums import MarketingStage
from .conversation_state import FlexibleConversationState
from .utils import clean_json_response

logger = logging.getLogger(__name__)


class MultiTurnFlowManager:
    """4ë‹¨ê³„ ì²´ê³„ì  ë©€í‹°í„´ ì§„í–‰ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.flow_analysis_system_prompt = self._create_flow_analysis_prompt()
        
    def _create_flow_analysis_prompt(self) -> str:
        """ë©€í‹°í„´ í”Œë¡œìš° ë¶„ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ìƒë‹´ì˜ 4ë‹¨ê³„ ì²´ê³„ì  ì§„í–‰ì„ ê´€ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**4ë‹¨ê³„ ë§ˆì¼€íŒ… í”„ë¡œì„¸ìŠ¤:**
1ë‹¨ê³„(ëª©í‘œ ì •ì˜): ë§ˆì¼€íŒ… ëª©í‘œ, ì›í•˜ëŠ” ê²°ê³¼, ì„±ê³µ ì§€í‘œ
2ë‹¨ê³„(íƒ€ê²Ÿ ë¶„ì„): ê³ ê° ë¶„ì„, í˜ë¥´ì†Œë‚˜, ê³ ê° ì—¬ì •
3ë‹¨ê³„(ì „ëµ ê¸°íš): ì±„ë„ ì„ íƒ, ì˜ˆì‚° ë°°ë¶„, ì½˜í…ì¸  ì „ëµ
4ë‹¨ê³„(ì‹¤í–‰ ê³„íš): êµ¬ì²´ì  ì½˜í…ì¸  ì œì‘, ìº í˜ì¸ ì‹¤í–‰

**ì§„í–‰ ë°©ì‹ ê²°ì •:**
- **structured_start**: ì‚¬ìš©ìê°€ ì²´ê³„ì  ì§„í–‰ì„ ì›í•  ë•Œ
- **continue_current**: í˜„ì¬ ë‹¨ê³„ ê³„ì† ì§„í–‰
- **auto_next**: í˜„ì¬ ë‹¨ê³„ ì™„ë£Œ í›„ ìë™ ë‹¤ìŒ ë‹¨ê³„
- **jump_stage**: íŠ¹ì • ë‹¨ê³„ë¡œ ì í”„
- **immediate_only**: ì¦‰ì‹œ ì‘ë‹µë§Œ (ë‹¨ê³„ ì§„í–‰ ì—†ìŒ)

**ë‹¨ê³„ ì™„ë£Œ ê¸°ì¤€:**
1ë‹¨ê³„: ëª…í™•í•œ ë§ˆì¼€íŒ… ëª©í‘œ + ì„±ê³µ ì§€í‘œ í™•ì¸
2ë‹¨ê³„: íƒ€ê²Ÿ ê³ ê° íŠ¹ì„± + í˜ë¥´ì†Œë‚˜ ì •ì˜
3ë‹¨ê³„: ë§ˆì¼€íŒ… ì±„ë„ + ì˜ˆì‚°/ì¼ì • ê²°ì •  
4ë‹¨ê³„: êµ¬ì²´ì  ì½˜í…ì¸  ë˜ëŠ” ì‹¤í–‰ ê³„íš ìˆ˜ë¦½

JSONìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”."""

    async def analyze_multiturn_flow(self, user_input: str, intent_analysis: Dict[str, Any], 
                                   context: Dict[str, Any], state: FlexibleConversationState) -> Dict[str, Any]:
        """ë©€í‹°í„´ í”Œë¡œìš° ë¶„ì„ ë° ì§„í–‰ ë°©í–¥ ê²°ì •"""
        
        logger.info(f"[ë©€í‹°í„´] í”Œë¡œìš° ë¶„ì„ ì‹œì‘ - í˜„ì¬ ë‹¨ê³„: {state.current_stage.value}")
        
        # í˜„ì¬ ìƒí™© ìš”ì•½
        completion_rates = self._calculate_stage_completion_rates(state)
        
        flow_prompt = f"""í˜„ì¬ ë§ˆì¼€íŒ… ìƒë‹´ ìƒí™©ì„ ë¶„ì„í•˜ê³  ìµœì ì˜ ì§„í–‰ ë°©í–¥ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

**í˜„ì¬ ìƒí™©:**
- ì‚¬ìš©ì ì…ë ¥: "{user_input}"
- í˜„ì¬ ë‹¨ê³„: {state.current_stage.value}
- ì—…ì¢…: {context.get('business_type', 'ì¼ë°˜')}
- ìˆ˜ì§‘ëœ ì •ë³´: {len(state.collected_info)}ê°œ

**ë‹¨ê³„ë³„ ì™„ë£Œìœ¨:**
- 1ë‹¨ê³„(ëª©í‘œ): {completion_rates.get('stage_1', 0):.0%}
- 2ë‹¨ê³„(íƒ€ê²Ÿ): {completion_rates.get('stage_2', 0):.0%}  
- 3ë‹¨ê³„(ì „ëµ): {completion_rates.get('stage_3', 0):.0%}
- 4ë‹¨ê³„(ì‹¤í–‰): {completion_rates.get('stage_4', 0):.0%}

**ìˆ˜ì§‘ëœ í•µì‹¬ ì •ë³´:**
{json.dumps(self._extract_key_info(state), ensure_ascii=False, indent=2)}

**ì˜ë„ ë¶„ì„:**
{json.dumps(intent_analysis, ensure_ascii=False, indent=2)}

**ë¶„ì„ ìš”ì²­:**
JSON í˜•íƒœë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
{{
    "flow_decision": "structured_start|continue_current|auto_next|jump_stage|immediate_only",
    "reasoning": "ê²°ì • ì´ìœ ",
    "current_stage_analysis": {{
        "completion_level": 0.0-1.0,
        "missing_info": ["ë¶€ì¡±í•œ ì •ë³´ë“¤"],
        "is_ready_for_next": true/false
    }},
    "next_action": {{
        "action_type": "ask_question|provide_summary|generate_content|move_to_next",
        "target_stage": "1|2|3|4|none",
        "requires_structured_flow": true/false
    }},
    "user_engagement": {{
        "wants_structured": true/false,
        "prefers_immediate": true/false,
        "engagement_level": "high|medium|low"
    }},
    "recommendations": ["ì§„í–‰ ë°©í–¥ ì œì•ˆë“¤"]
}}"""

        try:
            messages = [
                SystemMessage(content=self.flow_analysis_system_prompt),
                HumanMessage(content=flow_prompt)
            ]
            
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            # JSON íŒŒì‹±
            if isinstance(response, str):
                cleaned = clean_json_response(response)
                try:
                    result = json.loads(cleaned)
                    logger.info(f"[ë©€í‹°í„´] í”Œë¡œìš° ê²°ì •: {result.get('flow_decision')}")
                    return result
                except json.JSONDecodeError:
                    logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {cleaned[:100]}")
                    return self._create_default_flow_analysis()
            
            return response
            
        except Exception as e:
            logger.error(f"ë©€í‹°í„´ í”Œë¡œìš° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_flow_analysis()

    def _calculate_stage_completion_rates(self, state: FlexibleConversationState) -> Dict[str, float]:
        """ë‹¨ê³„ë³„ ì™„ë£Œìœ¨ ê³„ì‚°"""
        
        # 1ë‹¨ê³„: ëª©í‘œ ì •ì˜ ê´€ë ¨ ì •ë³´
        stage_1_keys = ['goals_main_goal', 'goals_target_metrics', 'goals_timeline', 'business_info_business_type']
        stage_1_score = sum(1 for key in stage_1_keys if key in state.collected_info) / len(stage_1_keys)
        
        # 2ë‹¨ê³„: íƒ€ê²Ÿ ë¶„ì„ ê´€ë ¨ ì •ë³´  
        stage_2_keys = ['target_audience_age_group', 'target_audience_gender', 'target_audience_interests', 'target_audience_behavior']
        stage_2_score = sum(1 for key in stage_2_keys if key in state.collected_info) / len(stage_2_keys)
        
        # 3ë‹¨ê³„: ì „ëµ ê¸°íš ê´€ë ¨ ì •ë³´
        stage_3_keys = ['marketing_info_channels', 'marketing_info_budget', 'marketing_info_tools', 'additional_preferences']
        stage_3_score = sum(1 for key in stage_3_keys if key in state.collected_info) / len(stage_3_keys)
        
        # 4ë‹¨ê³„: ì‹¤í–‰ ê´€ë ¨ ì •ë³´
        stage_4_keys = ['execution_content_type', 'execution_timeline', 'execution_resources']
        stage_4_score = sum(1 for key in stage_4_keys if key in state.collected_info) / len(stage_4_keys)
        
        return {
            'stage_1': stage_1_score,
            'stage_2': stage_2_score,  
            'stage_3': stage_3_score,
            'stage_4': stage_4_score
        }

    def _extract_key_info(self, state: FlexibleConversationState) -> Dict[str, Any]:
        """í•µì‹¬ ì •ë³´ ì¶”ì¶œ"""
        key_info = {}
        
        # ì¤‘ìš”í•œ ì •ë³´ë“¤ë§Œ ì¶”ì¶œ
        important_keys = [
            'business_info_business_type', 'goals_main_goal', 'target_audience_age_group',
            'marketing_info_budget', 'marketing_info_channels', 'additional_pain_points'
        ]
        
        for key in important_keys:
            if key in state.collected_info:
                key_info[key] = state.collected_info[key]['value']
        
        return key_info

    def _create_default_flow_analysis(self) -> Dict[str, Any]:
        """ê¸°ë³¸ í”Œë¡œìš° ë¶„ì„ ê²°ê³¼"""
        return {
            "flow_decision": "continue_current",
            "reasoning": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì§„í–‰",
            "current_stage_analysis": {
                "completion_level": 0.3,
                "missing_info": ["ê¸°ë³¸ ì •ë³´"],
                "is_ready_for_next": False
            },
            "next_action": {
                "action_type": "ask_question",
                "target_stage": "none",
                "requires_structured_flow": False
            },
            "user_engagement": {
                "wants_structured": False,
                "prefers_immediate": True,
                "engagement_level": "medium"
            },
            "recommendations": ["ì¼ë°˜ì ì¸ ë§ˆì¼€íŒ… ì¡°ì–¸ ì œê³µ"]
        }

    async def execute_flow_decision(self, flow_analysis: Dict[str, Any], user_input: str,
                                  context: Dict[str, Any], state: FlexibleConversationState) -> Tuple[str, Dict[str, Any]]:
        """í”Œë¡œìš° ê²°ì • ì‹¤í–‰"""
        
        flow_decision = flow_analysis.get("flow_decision", "continue_current")
        next_action = flow_analysis.get("next_action", {})
        
        logger.info(f"[ë©€í‹°í„´] í”Œë¡œìš° ì‹¤í–‰: {flow_decision}")
        
        if flow_decision == "structured_start":
            return await self._start_structured_flow(state, context)
            
        elif flow_decision == "auto_next":
            return await self._auto_progress_to_next_stage(state, context)
            
        elif flow_decision == "jump_stage":
            target_stage = next_action.get("target_stage", "1")
            return await self._jump_to_target_stage(target_stage, state, context)
            
        elif flow_decision == "continue_current":
            return await self._continue_current_stage(state, context, flow_analysis)
            
        else:  # immediate_only
            return "", {"requires_general_response": True}

    async def _start_structured_flow(self, state: FlexibleConversationState, 
                                   context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """ì²´ê³„ì  4ë‹¨ê³„ í”Œë¡œìš° ì‹œì‘"""
        
        state.current_stage = MarketingStage.STAGE_1_GOAL
        state.user_preferences["prefers_structured"] = True
        
        response = f"""ğŸš€ **ë§ˆì¼€íŒ… 4ë‹¨ê³„ ì²´ê³„ì  ìƒë‹´ì„ ì‹œì‘í•©ë‹ˆë‹¤!**

**ì§„í–‰ ê³¼ì •:**
1ï¸âƒ£ **ëª©í‘œ ì •ì˜** â† í˜„ì¬ ë‹¨ê³„
2ï¸âƒ£ **íƒ€ê²Ÿ ë¶„ì„** 
3ï¸âƒ£ **ì „ëµ ê¸°íš**
4ï¸âƒ£ **ì‹¤í–‰ ê³„íš**

---

### ğŸ“‹ **1ë‹¨ê³„: ë§ˆì¼€íŒ… ëª©í‘œ ì •ì˜**

ì„±ê³µì ì¸ ë§ˆì¼€íŒ…ì„ ìœ„í•´ì„œëŠ” ëª…í™•í•œ ëª©í‘œê°€ í•„ìš”í•©ë‹ˆë‹¤."""
        
        # ì—…ì¢…ë³„ ë§ì¶¤ ì§ˆë¬¸ ìš”ì²­
        from .stage_question_generator import StageQuestionGenerator
        question_generator = StageQuestionGenerator()
        stage_question = await question_generator.generate_stage_question(
            MarketingStage.STAGE_1_GOAL, context, state
        )
        
        response += f"\n\n{stage_question}"
        
        return response, {"stage_changed": True, "new_stage": "stage_1_goal"}

    async def _auto_progress_to_next_stage(self, state: FlexibleConversationState, 
                                         context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """ìë™ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰"""
        
        next_stage = state.get_next_stage()
        if not next_stage:
            return "ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰", {"flow_completed": True}
        
        state.current_stage = next_stage
        
        # ë‹¨ê³„ ì™„ë£Œ ì¶•í•˜ ë©”ì‹œì§€
        stage_names = {
            MarketingStage.STAGE_2_TARGET: "2ë‹¨ê³„: íƒ€ê²Ÿ ë¶„ì„",
            MarketingStage.STAGE_3_STRATEGY: "3ë‹¨ê³„: ì „ëµ ê¸°íš", 
            MarketingStage.STAGE_4_EXECUTION: "4ë‹¨ê³„: ì‹¤í–‰ ê³„íš"
        }
        
        response = f"""âœ… **ì´ì „ ë‹¨ê³„ ì™„ë£Œ!** 

ğŸ¯ **{stage_names.get(next_stage, 'ë‹¤ìŒ ë‹¨ê³„')}**ë¡œ ì´ë™í•©ë‹ˆë‹¤.

---
"""
        
        # ìƒˆ ë‹¨ê³„ ì§ˆë¬¸ ìƒì„±
        from .stage_question_generator import StageQuestionGenerator
        question_generator = StageQuestionGenerator()
        stage_question = await question_generator.generate_stage_question(
            next_stage, context, state
        )
        
        response += stage_question
        
        return response, {"stage_changed": True, "new_stage": next_stage.value}

    async def _jump_to_target_stage(self, target_stage: str, state: FlexibleConversationState,
                                  context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """íŠ¹ì • ë‹¨ê³„ë¡œ ì í”„"""
        
        stage_mapping = {
            "1": MarketingStage.STAGE_1_GOAL,
            "2": MarketingStage.STAGE_2_TARGET,
            "3": MarketingStage.STAGE_3_STRATEGY,
            "4": MarketingStage.STAGE_4_EXECUTION
        }
        
        if target_stage not in stage_mapping:
            return f"'{target_stage}' ë‹¨ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", {"error": True}
        
        target_stage_enum = stage_mapping[target_stage]
        state.current_stage = target_stage_enum
        
        response = f"ğŸš€ **{target_stage}ë‹¨ê³„ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤!**\n\n"
        
        # í•´ë‹¹ ë‹¨ê³„ ì§ˆë¬¸ ìƒì„±
        from .stage_question_generator import StageQuestionGenerator
        question_generator = StageQuestionGenerator()
        stage_question = await question_generator.generate_stage_question(
            target_stage_enum, context, state
        )
        
        response += stage_question
        
        return response, {"stage_changed": True, "new_stage": target_stage_enum.value}

    async def _continue_current_stage(self, state: FlexibleConversationState, context: Dict[str, Any],
                                    flow_analysis: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """í˜„ì¬ ë‹¨ê³„ ê³„ì† ì§„í–‰"""
        
        current_analysis = flow_analysis.get("current_stage_analysis", {})
        missing_info = current_analysis.get("missing_info", [])
        
        if missing_info:
            # ë¶€ì¡±í•œ ì •ë³´ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ ìƒì„±
            from .stage_question_generator import StageQuestionGenerator  
            question_generator = StageQuestionGenerator()
            
            follow_up_question = await question_generator.generate_follow_up_question(
                state.current_stage, missing_info, context, state
            )
            
            return follow_up_question, {"continue_stage": True}
        else:
            # í˜„ì¬ ë‹¨ê³„ ì™„ë£Œ, ë‹¤ìŒ ë‹¨ê³„ë¡œ ìë™ ì§„í–‰
            return await self._auto_progress_to_next_stage(state, context)

    async def should_use_structured_flow(self, user_input: str, intent_analysis: Dict[str, Any],
                                      state: FlexibleConversationState) -> bool:
        """LLM ê¸°ë°˜ ì²´ê³„ì  í”Œë¡œìš° ì‚¬ìš© ì—¬ë¶€ ê²°ì • (í•˜ë“œì½”ë”© ì—†ëŠ” ê°œì„  ë²„ì „)"""
        try:
            messages = [
                SystemMessage(content="""ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ìƒë‹´ì—ì„œ ì²´ê³„ì  ë‹¨ê³„ë³„ ì§„í–‰ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

                **ë‹¤ìŒ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´ ë¬´ì¡°ê±´ requires_structured = trueë¡œ í•˜ì„¸ìš”:**
                1. ì‚¬ìš©ìê°€ ë§ˆì¼€íŒ…ì„ ì²˜ìŒ ì‹œì‘í•˜ê±°ë‚˜ "ì•„ë¬´ê²ƒë„ ëª¨ë¥¸ë‹¤", "ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜", "ì²˜ìŒì´ë¼ ëª°ë¼" ë“± ë¶ˆí™•ì‹¤í•¨ì„ í‘œí˜„.
                2. ì‚¬ìš©ìê°€ "í™ë³´í•˜ê³  ì‹¶ë‹¤", "ë§ˆì¼€íŒ… í•˜ê³  ì‹¶ë‹¤", "í”„ë¡œëª¨ì…˜ í•˜ê³  ì‹¶ë‹¤" ë“± ë§‰ì—°í•œ ì˜ì§€ë§Œ í‘œí˜„ (ì„¸ë¶€ ê³„íš ì—†ìŒ).
                3. ìƒˆë¡œìš´ ì œí’ˆ/ì„œë¹„ìŠ¤ë¥¼ ì–´ë–»ê²Œ ë§ˆì¼€íŒ…í• ì§€ ì§ˆë¬¸í•˜ëŠ” ê²½ìš°.
                4. ë§ˆì¼€íŒ… ì „ëµ, ë¸Œëœë”©, ì‹¤í–‰ê³„íš, íƒ€ê²Ÿ ì„¤ì • ë“± ë‹¨ê³„ì  ê°€ì´ë“œê°€ í•„ìš”í•œ ê²½ìš°.
                5. í˜„ì¬ state.current_stageê°€ ANY_QUESTIONì´ ì•„ë‹ˆê±°ë‚˜ intent_analysisì—ì„œ ë³µì¡í•œ ë§ˆì¼€íŒ… ì£¼ì œê°€ ê°ì§€ë˜ëŠ” ê²½ìš°.

                **ì¦‰ì‹œ ì‘ë‹µì´ ì í•©í•œ ê²½ìš° (requires_structured = false):**
                - ë‹¨ìˆœ ì§ˆì˜(ì˜ˆ: "í˜ì´ìŠ¤ë¶ ê´‘ê³  ì˜ˆì‚°ì€ ì–¼ë§ˆ?").
                - íŠ¹ì • ì±„ë„ ì‚¬ìš©ë²•, íŠ¹ì • ê¸°ëŠ¥ì— ëŒ€í•œ ì§ˆë¬¸ (ë‹¨ê³„ì  ìƒë‹´ì´ ë¶ˆí•„ìš”).
                
                JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
                {"requires_structured": true/false, "confidence": 0.0-1.0, "reasoning": "íŒë‹¨ ê·¼ê±°"}
                """),
                HumanMessage(content=f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì  ì§„í–‰ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”.

                **ì‚¬ìš©ì ì…ë ¥:**
                "{user_input}"

                **í˜„ì¬ ìƒíƒœ:**
                - í˜„ì¬ ë‹¨ê³„: {state.current_stage.value}
                - ì„ í˜¸ë„: {json.dumps(state.user_preferences, ensure_ascii=False)}

                **ì˜ë„ ë¶„ì„:**
                {json.dumps(intent_analysis, ensure_ascii=False, indent=2)}""")
            ]

            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            response = await llm.ainvoke(messages)
            response_content = str(response.content) if hasattr(response, 'content') else str(response)

            logger.debug(f"[ë©€í‹°í„´] LLM ì‘ë‹µ ì›ë¬¸: {response_content}")

            # JSON í¬ë§· ë³´ì •
            cleaned = response_content.replace("```json", "").replace("```", "").strip()
            try:
                result = json.loads(cleaned)
                logger.info(f"[ë©€í‹°í„´] ì²´ê³„ì  ì§„í–‰ ê²°ì •: {result}")
                return result.get('requires_structured', False)
            except json.JSONDecodeError:
                logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {cleaned[:100]}")
                return self._default_structured_flow_decision(user_input, intent_analysis, state)

        except Exception as e:
            logger.error(f"ì²´ê³„ì  ì§„í–‰ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._default_structured_flow_decision(user_input, intent_analysis, state)
    
    def _default_structured_flow_decision(self, user_input: str, intent_analysis: Dict[str, Any],
                                        state: FlexibleConversationState) -> bool:
        """ê¸°ë³¸ ì²´ê³„ì  í”Œë¡œìš° ê²°ì • ë¡œì§"""
        
        # ì²´ê³„ì  ì§„í–‰ í‚¤ì›Œë“œ
        structured_keywords = [
            "ì²´ê³„ì ", "ë‹¨ê³„ë³„", "ì²˜ìŒë¶€í„°", "ì°¨ê·¼ì°¨ê·¼", "ìˆœì„œëŒ€ë¡œ", 
            "4ë‹¨ê³„", "ì „ì²´ì ìœ¼ë¡œ", "ì™„ì „íˆ", "ìƒë‹´ ì‹œì‘"
        ]
        
        # ì‚¬ìš©ìê°€ ì²´ê³„ì  ì§„í–‰ì„ ì›í•˜ëŠ” ê²½ìš°
        if any(keyword in user_input for keyword in structured_keywords):
            return True
        
        # í˜„ì¬ ìƒíƒœê°€ ì²´ê³„ì  ì§„í–‰ ì¤‘ì¸ ê²½ìš°
        if (state.user_preferences.get("prefers_structured", False) and 
            state.current_stage != MarketingStage.ANY_QUESTION):
            return True
        
        # ì˜ë„ ë¶„ì„ì—ì„œ ì²´ê³„ì  ì§„í–‰ì„ ê¶Œì¥í•˜ëŠ” ê²½ìš°
        if intent_analysis.get("flow_control", {}).get("wants_structured", False):
            return True
            
        return False
