"""
LLM ê¸°ë°˜ ìœ ì—°í•œ 4ë‹¨ê³„ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ë§¤ë‹ˆì €
- ìˆœì„œ ë¬´ê´€ ì¦‰ì‹œ ì‘ë‹µ
- ì¤‘ê°„ ë‹¨ê³„ë¶€í„° ì‹œì‘
- ë‹¨ê³„ ê±´ë„ˆë›°ê¸°
- ëª¨ë“  ì˜ë„ ë¶„ì„ LLM ê¸°ë°˜
- ë§ˆì¼€íŒ… íˆ´ ìë™ í™œìš©
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from enum import Enum
import json
from datetime import datetime

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸ (ì•ˆì „í•œ import)
try:
    from shared_modules import (
        get_config,
        get_llm_manager,
        get_vector_manager,
        get_or_create_conversation_session,
        create_message,
        get_recent_messages,
        insert_message_raw,
        get_session_context,
        create_success_response,
        create_error_response,
        create_marketing_response,
        get_current_timestamp,
        format_conversation_history,
        load_prompt_from_file,
        PromptTemplate
    )
except ImportError as e:
    logger = logging.getLogger(__name__)
    logger.warning(f"shared_modules import ì‹¤íŒ¨: {e}")

try:
    from marketing_agent.config.persona_config import PERSONA_CONFIG
except ImportError:
    PERSONA_CONFIG = {}

try:
    from marketing_agent.config.prompts_config import PROMPT_META
except ImportError:
    PROMPT_META = {}

try:
    from marketing_agent.utils import get_marketing_analysis_tools
except ImportError as e:
    logger = logging.getLogger(__name__)
    logger.warning(f"analysis_tools import ì‹¤íŒ¨: {e}")
    def get_marketing_analysis_tools():
        return None

logger = logging.getLogger(__name__)

class MarketingStage(Enum):
    """4ë‹¨ê³„ ë§ˆì¼€íŒ… í”„ë¡œì„¸ìŠ¤"""
    ANY_QUESTION = "any_question"                   # ìˆœì„œ ë¬´ê´€ ì¦‰ì‹œ ì‘ë‹µ
    STAGE_1_GOAL = "stage_1_goal"                   # 1ë‹¨ê³„: ëª©í‘œ ì •ì˜
    STAGE_2_TARGET = "stage_2_target"               # 2ë‹¨ê³„: íƒ€ê²Ÿ ë¶„ì„
    STAGE_3_STRATEGY = "stage_3_strategy"           # 3ë‹¨ê³„: ì „ëµ ê¸°íš
    STAGE_4_EXECUTION = "stage_4_execution"         # 4ë‹¨ê³„: ì‹¤í–‰ ê³„íš
    COMPLETED = "completed"                         # ì™„ë£Œ

class ResponseType(Enum):
    """ì‘ë‹µ íƒ€ì…"""
    IMMEDIATE_ANSWER = "immediate_answer"           # ì¦‰ì‹œ ì‘ë‹µ
    STAGE_PROGRESS = "stage_progress"               # ë‹¨ê³„ ì§„í–‰
    FLOW_CONTROL = "flow_control"                   # ì§„í–‰ ì œì–´
    COMPREHENSIVE = "comprehensive"                 # ì¢…í•© ì „ëµ
    CLARIFICATION = "clarification"                 # ëª…í™•í™” í•„ìš”
    TOOL_REQUIRED = "tool_required"                 # ë§ˆì¼€íŒ… íˆ´ í•„ìš”


def clean_json_response(response: str) -> str:
    """
    LLM ì‘ë‹µì—ì„œ ì½”ë“œë¸”ë¡(````json ... ````)ì„ ì œê±°í•˜ê³  JSONë§Œ ì¶”ì¶œ
    """
    cleaned = response.strip()
    if cleaned.startswith("```"):
        # ì²«ë²ˆì§¸ ``` ì œê±°
        cleaned = cleaned.strip("`")
        # "json" íƒœê·¸ ì œê±°
        cleaned = cleaned.replace("json", "", 1).strip()
        # ë§ˆì§€ë§‰ ``` ì œê±°
        if cleaned.endswith("```"):
            cleaned = cleaned[:cleaned.rfind("```")].strip()
    return cleaned

class Enhanced4StageMarketingManager:
    """LLM ê¸°ë°˜ ìœ ì—°í•œ 4ë‹¨ê³„ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ê´€ë¦¬ì"""
    
    def __init__(self):
        """ë§ˆì¼€íŒ… ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        self.config = get_config()
        self.llm_manager = get_llm_manager()
        self.vector_manager = get_vector_manager()
        self.analysis_tools = get_marketing_analysis_tools()
        
        # í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.prompts_dir = Path(__file__).parent.parent / 'prompts'
        
        # ëŒ€í™” ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self.conversation_states: Dict[int, 'FlexibleConversationState'] = {}
        
        # LLM í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤
        self.intent_analysis_system_prompt = self._create_intent_analysis_prompt()
        self.response_generation_system_prompt = self._create_response_generation_prompt()
        self.flow_control_system_prompt = self._create_flow_control_prompt()
    
    def _create_intent_analysis_prompt(self) -> str:
        """ì˜ë„ ë¶„ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì‘ë‹µ ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.

ë¶„ì„ ê¸°ì¤€:
1. ì‘ë‹µ íƒ€ì… ê²°ì •:
   - immediate_answer: ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì¼ë°˜ì  ì§ˆë¬¸
   - stage_progress: íŠ¹ì • ë‹¨ê³„ ì§„í–‰ ê´€ë ¨
   - flow_control: ëŒ€í™” ì œì–´ (ì¤‘ë‹¨/ì¬ê°œ/ê±´ë„ˆë›°ê¸°)
   - comprehensive: ì¢…í•©ì  ì „ëµ í•„ìš”
   - clarification: ì¶”ê°€ ì •ë³´ í•„ìš”
   - tool_required: ë§ˆì¼€íŒ… íˆ´ ì‚¬ìš© í•„ìš”

2. ì‚¬ìš©ì ì˜ë„:
   - ì£¼ìš” ëª©ì ê³¼ ì •ë³´ í•„ìš”ë„
   - ê¸´ê¸‰ë„ì™€ êµ¬ì²´ì„± ìˆ˜ì¤€
   - ì§„í–‰ ë°©ì‹ ì„ í˜¸ë„

3. ì»¨í…ìŠ¤íŠ¸ í™œìš©:
   - ê¸°ì¡´ ì •ë³´ í™œìš© í•„ìš”ì„±
   - ê°œì¸í™” ìˆ˜ì¤€
   - ì—…ì¢…ë³„ ë§ì¶¤í™”

4. ë§ˆì¼€íŒ… íˆ´ í•„ìš”ì„± íŒë‹¨:
   - íŠ¸ë Œë“œ ë¶„ì„: í‚¤ì›Œë“œ íŠ¸ë Œë“œ, ê²€ìƒ‰ëŸ‰ ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš° (ëª¨ë“  ë‹¨ê³„ì—ì„œ ê°€ëŠ¥)
   - í•´ì‹œíƒœê·¸ ë¶„ì„: ì¸ìŠ¤íƒ€ê·¸ë¨, SNS ë§ˆì¼€íŒ… ê´€ë ¨ ì§ˆë¬¸ (ëª¨ë“  ë‹¨ê³„ì—ì„œ ê°€ëŠ¥)
   - ì½˜í…ì¸  ìƒì„±: ë¸”ë¡œê·¸, ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ì œì‘ ìš”ì²­ (**ë‹¨, 4ë‹¨ê³„(ì‹¤í–‰ ê³„íš)ì—ì„œë§Œ ê°€ëŠ¥**)
   - í‚¤ì›Œë“œ ì—°êµ¬: SEO, ê²€ìƒ‰ ë§ˆì¼€íŒ… ê´€ë ¨ ì§ˆë¬¸ (ëª¨ë“  ë‹¨ê³„ì—ì„œ ê°€ëŠ¥)

5. ë‹¨ê³„ë³„ ì œí•œ ì‚¬í•­:
   - ì½˜í…ì¸  ìƒì„±ì€ ë°˜ë“œì‹œ 4ë‹¨ê³„(ì‹¤í–‰ ê³„íš)ì—ì„œë§Œ ìˆ˜í–‰
   - ë‹¤ë¥¸ ë‹¨ê³„ì—ì„œ ì½˜í…ì¸  ìƒì„± ìš”ì²­ì‹œ flow_controlë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ë‹¨ê³„ ì´ë™ ì•ˆë‚´

ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”."""

    def _create_response_generation_prompt(self) -> str:
        """ì‘ë‹µ ìƒì„± ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ìƒí™©ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

ì‘ë‹µ ì›ì¹™:
1. ê°œì¸í™”ëœ êµ¬ì²´ì  ì¡°ì–¸
2. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ íŒ
3. ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í†¤
4. ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©
5. 300-500ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ

ì—…ì¢…ë³„ ì „ë¬¸ì„±ê³¼ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”."""

    def _create_flow_control_prompt(self) -> str:
        """ì§„í–‰ ì œì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ëŒ€í™” ì§„í–‰ì„ ìµœì í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ì˜ë„ì— ë”°ë¼ ìµœì ì˜ ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •í•©ë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì•¡ì…˜:
- continue_immediate: ì¦‰ì‹œ ì‘ë‹µìœ¼ë¡œ ì™„ë£Œ
- start_structured: ì²´ê³„ì  4ë‹¨ê³„ ìƒë‹´ ì‹œì‘
- jump_to_stage: íŠ¹ì • ë‹¨ê³„ë¡œ ì´ë™
- collect_more_info: ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
- provide_strategy: ì „ëµ ì œì•ˆ
- pause_conversation: ëŒ€í™” ì¼ì‹œ ì¤‘ë‹¨

ì‚¬ìš©ìì—ê²Œ ìµœëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ ê²°ì •í•˜ì„¸ìš”."""

    def analyze_user_intent_with_llm(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        logger.info(f"[ë‹¨ê³„ ë¡œê·¸] ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì‹œì‘ - ì…ë ¥: {user_input[:50]}...")
        
        # ë¨¼ì € ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜•
        detected_business = self.detect_business_type_with_llm(user_input, context)
        if detected_business != "ì¼ë°˜":
            context["business_type"] = detected_business
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ë¹„ì¦ˆë‹ˆìŠ¤ ìœ í˜• ê°ì§€: {detected_business}")
        
        analysis_prompt = f"""í˜„ì¬ ë§ˆì¼€íŒ… ìƒë‹´ ìƒí™©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì…ë ¥: "{user_input}"

í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:
- ëŒ€í™” ëª¨ë“œ: {context.get('conversation_mode', 'flexible')}
- í˜„ì¬ ë‹¨ê³„: {context.get('current_stage', 'none')}
- ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(context.get('collected_info', {}), ensure_ascii=False, indent=2)}
- ì—…ì¢…: {context.get('business_type', 'ë¯¸í™•ì¸')}
- ëŒ€í™” íˆìŠ¤í† ë¦¬: {context.get('history_summary', 'ìƒˆ ëŒ€í™”')}

ë‹¤ìŒì„ JSON í˜•íƒœë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
{{
    "response_type": "immediate_answer|stage_progress|flow_control|comprehensive|clarification|tool_required",
    "user_intent": {{
        "primary_goal": "ì‚¬ìš©ìì˜ ì£¼ìš” ëª©ì ",
        "information_need": "í•„ìš”í•œ ì •ë³´",
        "urgency_level": "high|medium|low",
        "specificity": "general|specific|very_specific"
    }},
    "flow_control": {{
        "wants_immediate": true/false,
        "wants_structured": true/false,
        "stage_preference": "1|2|3|4|any|none",
        "control_command": "pause|resume|skip|restart|next|none"
    }},
    "context_needs": {{
        "use_existing_info": true/false,
        "business_type_detection": "í•„ìš”ì‹œ ì—…ì¢…",
        "personalization_level": "high|medium|low"
    }},
    "tool_requirements": {{
        "needs_tool": true/false,
        "tool_type": "trend_analysis|hashtag_analysis|content_generation|keyword_research|none",
        "target_keyword": "ë¶„ì„í•  ì£¼ìš” í‚¤ì›Œë“œ",
        "content_type": "blog|instagram|general",
        "reasoning": "íˆ´ ì‚¬ìš© ì´ìœ "
    }},
    "suggested_action": "ì¶”ì²œí•˜ëŠ” ë‹¤ìŒ ì•¡ì…˜"
}}"""

        try:
            messages = [
                SystemMessage(content=self.intent_analysis_system_prompt),
                HumanMessage(content=analysis_prompt)
            ]
            
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            # JSON íŒŒì‹±
            if isinstance(response, str):
                cleaned = clean_json_response(response)
                try:
                    logger.info("[ë‹¨ê³„ ë¡œê·¸] ì •ë³´ ì¶”ì¶œ ê²°ê³¼ íŒŒì‹± ì‹œì‘")
                    return json.loads(cleaned)
                except json.JSONDecodeError:
                    logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {cleaned[:100]}")
                    return self._create_default_intent_analysis(user_input)
                
            return response
            
        except Exception as e:
            logger.error(f"ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_default_intent_analysis(user_input)

    def _create_default_intent_analysis(self, user_input: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ì˜ë„ ë¶„ì„ ê²°ê³¼"""
        return {
            "response_type": "immediate_answer",
            "user_intent": {
                "primary_goal": "ë§ˆì¼€íŒ… ì •ë³´ íšë“",
                "information_need": user_input,
                "urgency_level": "medium",
                "specificity": "general"
            },
            "flow_control": {
                "wants_immediate": True,
                "wants_structured": False,
                "stage_preference": "any",
                "control_command": "none"
            },
            "context_needs": {
                "use_existing_info": False,
                "business_type_detection": "ì¼ë°˜",
                "personalization_level": "medium"
            },
            "tool_requirements": {
                "needs_tool": False,
                "tool_type": "none",
                "target_keyword": "",
                "content_type": "general",
                "reasoning": ""
            },
            "suggested_action": "provide_immediate_answer"
        }

    def generate_contextual_response(self, user_input: str, intent: Dict[str, Any], 
                                         context: Dict[str, Any]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        logger.info(f"[ë‹¨ê³„ ë¡œê·¸] ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì‹œì‘ - í˜„ì¬ ë‹¨ê³„: {context.get('current_stage', 'ì—†ìŒ')}")

        
        # ì—…ì¢…ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        stage_prompts = {}
        if context.get('business_type') and context['business_type'] != 'ì¼ë°˜':
            stage_prompts = self.load_stage_prompts_for_business(context['business_type'])
        else:
            stage_prompts = self.load_all_stage_prompts()
        
        response_prompt = f"""ì‚¬ìš©ìì˜ ë§ˆì¼€íŒ… ì§ˆë¬¸ì— ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ì˜ë„ ë¶„ì„:
{json.dumps(intent, ensure_ascii=False, indent=2)}

í˜„ì¬ ìƒí™©:
- ì—…ì¢…: {context.get('business_type', 'ì¼ë°˜')}
- ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(context.get('collected_info', {}), ensure_ascii=False)}
- í˜„ì¬ ë‹¨ê³„: {context.get('current_stage', 'ì—†ìŒ')}
- ì´ì „ ëŒ€í™”: {context.get('history_summary', 'ìƒˆë¡œìš´ ëŒ€í™”')}

ì¤‘ìš” ì§€ì¹¨:
1. ì´ë¯¸ ì•Œê³  ìˆëŠ” ì‚¬ìš©ì ì •ë³´ë¥¼ ì ê·¹ í™œìš©í•˜ì„¸ìš”
2. ì—…ì¢…ì´ í™•ì¸ëœ ê²½ìš°, í•´ë‹¹ ì—…ì¢…ì„ ì§ì ‘ ì–¸ê¸‰í•˜ë©° ë§ì¶¤í˜• ì¡°ì–¸ ì œê³µ
3. ì˜ˆ: "ì¹´í˜ ì°½ì—…"ì„ ì–¸ê¸‰í–ˆë‹¤ë©´, "ì–´ë–¤ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ í•˜ì‹œë‚˜ìš”?" ëŒ€ì‹  "ì¹´í˜ ì°½ì—…ì— ëŒ€í•œ..."ë¡œ ì‹œì‘
4. ì‚¬ìš©ìê°€ ì œê³µí•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¬´ì‹œí•˜ì§€ ë§ê³  ì—°ê²°ì„± ìˆê²Œ ì‘ë‹µ

í™œìš© ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ê°€ì´ë“œë¼ì¸:
{self._format_prompts_for_response(stage_prompts)}

ì‘ë‹µ ìš”êµ¬ì‚¬í•­:
1. ì‚¬ìš©ì ìƒí™©ì— ë§ëŠ” ê°œì¸í™”ëœ ì¡°ì–¸
2. ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  íŒ
3. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤
4. ì ì ˆí•œ ì´ëª¨ì§€ì™€ êµ¬ì¡°í™”
5. í•„ìš”ì‹œ í›„ì† ì§„í–‰ ì œì•ˆ

ì‘ë‹µ ê¸¸ì´: 300-500ì ë‚´ì™¸"""

        try:
            messages = [
                SystemMessage(content=self.response_generation_system_prompt),
                HumanMessage(content=response_prompt)
            ]
            
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            return response
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ë§ˆì¼€íŒ… ì§ˆë¬¸ì— ëŒ€í•œ ì¡°ì–¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹ ê²Œ í•„ìš”í•©ë‹ˆë‹¤."

    def _format_prompts_for_response(self, prompts: Dict[str, str]) -> str:
        """ì‘ë‹µ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…"""
        if not prompts:
            return "ì¼ë°˜ì ì¸ ë§ˆì¼€íŒ… ê°€ì´ë“œë¼ì¸ì„ í™œìš©í•©ë‹ˆë‹¤."
        
        formatted = []
        for name, content in prompts.items():
            # í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ìš”ì•½í•´ì„œ í¬í•¨ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„)
            summary = content[:200] + "..." if len(content) > 200 else content
            formatted.append(f"[{name}] {summary}")
        
        return "\n".join(formatted)

    def determine_next_action(self, user_input: str, intent: Dict[str, Any], 
                                  context: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¤ìŒ ì•¡ì…˜ ê²°ì •"""
        logger.info(f"[ë‹¨ê³„ ë¡œê·¸] ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ì‹œì‘ - ì˜ë„ íƒ€ì…: {intent.get('response_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}")

        
        action_prompt = f"""í˜„ì¬ ë§ˆì¼€íŒ… ìƒë‹´ ìƒí™©ì—ì„œ ë‹¤ìŒ ì•¡ì…˜ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì…ë ¥: "{user_input}"
ì˜ë„ ë¶„ì„: {json.dumps(intent, ensure_ascii=False)}
í˜„ì¬ ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}

JSON í˜•íƒœë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "recommended_action": "continue_immediate|start_structured|jump_to_stage|collect_info|provide_strategy|pause",
    "reasoning": "ì¶”ì²œ ì´ìœ ",
    "parameters": {{
        "target_stage": "ì´ë™í•  ë‹¨ê³„ (í•´ë‹¹ì‹œ)",
        "info_needed": ["ìˆ˜ì§‘í•  ì •ë³´ë“¤"],
        "immediate_response": true/false
    }},
    "user_options": ["ì‚¬ìš©ì ì„ íƒì§€ë“¤"],
    "follow_up": "í›„ì† ì§„í–‰ ë°©í–¥"
}}"""

        try:
            messages = [
                SystemMessage(content=self.flow_control_system_prompt),
                HumanMessage(content=action_prompt)
            ]
            
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            # JSON íŒŒì‹±
            if isinstance(response, str):
                cleaned = clean_json_response(response)
                try:
                    return json.loads(cleaned)
                except json.JSONDecodeError:
                    logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {cleaned[:100]}")
                    return self._create_default_action_result()
            return response
            
        except Exception as e:
            logger.error(f"ë‹¤ìŒ ì•¡ì…˜ ê²°ì • ì‹¤íŒ¨: {e}")
            return self._create_default_action_result()
    
    def _create_default_action_result(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì•¡ì…˜ ê²°ê³¼"""
        return {
            "recommended_action": "continue_immediate",
            "reasoning": "ì¦‰ì‹œ ì‘ë‹µ ì œê³µ",
            "parameters": {"immediate_response": True},
            "user_options": ["ì²´ê³„ì  ìƒë‹´ ì‹œì‘", "ì¶”ê°€ ì§ˆë¬¸"],
            "follow_up": "ìƒí™©ì— ë”°ë¼ ì§„í–‰"
        }

    def detect_business_type_with_llm(self, user_input: str, context: Dict[str, Any]) -> str:
        """LLM ê¸°ë°˜ ì—…ì¢… ê°ì§€"""
        logger.info(f"[ë‹¨ê³„ ë¡œê·¸] ì—…ì¢… ê°ì§€ ì‹œì‘ - í˜„ì¬ ì»¨í…ìŠ¤íŠ¸: {context.get('business_type', 'ë¯¸í™•ì¸')}")

        
        detection_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ì—…ì¢…ì„ ê°ì§€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì…ë ¥: "{user_input}"
ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸: {json.dumps(context.get('collected_info', {}), ensure_ascii=False)}

ë‹¤ìŒ ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ì—…ì¢…ì„ ì„ íƒí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì—…ì¢…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:
- ì•± (ëª¨ë°”ì¼ì•±, ê²Œì„ì•±, ìƒì‚°ì„±ì•± ë“±)
- ë·°í‹° (ë¯¸ìš©ì‹¤, ë„¤ì¼ìƒµ, í”¼ë¶€ê´€ë¦¬, ë·°í‹° í”Œë«í¼ ë“±)
- í¬ë¦¬ì—ì´í„° (ìœ íŠœë¸Œ, ì¸í”Œë£¨ì–¸ì„œ, 1ì¸ ì½˜í…ì¸  ì œì‘ì ë“±)
- ìŒì‹ì  (ì¹´í˜, ë ˆìŠ¤í† ë‘, ë°°ë‹¬ì „ë¬¸ì , í‘¸ë“œíŠ¸ëŸ­ ë“±)
- ì˜¨ë¼ì¸ì‡¼í•‘ëª° (ì´ì»¤ë¨¸ìŠ¤, ì˜¨ë¼ì¸ ì…€ëŸ¬, ë¼ì´ë¸Œì»¤ë¨¸ìŠ¤ ë“±)
- ì„œë¹„ìŠ¤ì—… (ì»¨ì„¤íŒ…, êµìœ¡, í—¬ìŠ¤ì¼€ì–´ ë“±)
- ê¸°íƒ€ (ì‹ ê·œ ì—…ì¢… ë˜ëŠ” ìœµí•© ì—…ì¢… ë“±)

ì—…ì¢…ëª…ë§Œ ê°„ë‹¨íˆ ë‹µë³€í•´ì£¼ì„¸ìš”. (ì˜ˆ: "ë·°í‹°", "ìŒì‹ì ", "ì˜¨ë¼ì¸ì‡¼í•‘ëª°")"""

        try:
            messages = [
                SystemMessage(content="ì—…ì¢… ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê²Œ ì—…ì¢…ëª…ë§Œ ë‹µë³€í•©ë‹ˆë‹¤."),
                HumanMessage(content=detection_prompt)
            ]
            
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            return response.strip() if response else "ì¼ë°˜"
            
        except Exception as e:
            logger.error(f"ì—…ì¢… ê°ì§€ ì‹¤íŒ¨: {e}")
            return "ì¼ë°˜"

    async def execute_marketing_tool(self, user_input: str, intent_analysis: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ë§ˆì¼€íŒ… íˆ´ ì‹¤í–‰"""
        try:
            tool_requirements = intent_analysis.get("tool_requirements", {})
            tool_type = tool_requirements.get("tool_type", "none")
            target_keyword = tool_requirements.get("target_keyword", "")
            content_type = tool_requirements.get("content_type", "general")
            current_stage = context.get("current_stage", "any_question")
            
            if not self.analysis_tools:
                return {
                    "success": False,
                    "error": "ë§ˆì¼€íŒ… ë¶„ì„ ë„êµ¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "tool_type": tool_type
                }
            
            logger.info(f"[íˆ´ ì‹¤í–‰] íˆ´ íƒ€ì…: {tool_type}, í‚¤ì›Œë“œ: {target_keyword}, í˜„ì¬ ë‹¨ê³„: {current_stage}")
            
            # ì½˜í…ì¸  ìƒì„±ì€ 4ë‹¨ê³„(ì‹¤í–‰ ê³„íš)ì—ì„œë§Œ ê°€ëŠ¥
            if tool_type == "content_generation":
                if current_stage != "stage_4_execution":
                    return {
                        "success": False,
                        "error": "ì½˜í…ì¸  ìƒì„±ì€ 4ë‹¨ê³„(ì‹¤í–‰ ê³„íš) ë‹¨ê³„ì—ì„œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                        "tool_type": tool_type,
                        "stage_requirement": "stage_4_execution",
                        "current_stage": current_stage,
                        "suggestion": "ë¨¼ì € 1ë‹¨ê³„(ëª©í‘œ ì •ì˜) â†’ 2ë‹¨ê³„(íƒ€ê²Ÿ ë¶„ì„) â†’ 3ë‹¨ê³„(ì „ëµ ê¸°íš)ë¥¼ ì™„ë£Œí•œ í›„ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ë³´ì„¸ìš”."
                    }
            
            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì¶”ì¶œ
            if not target_keyword:
                target_keyword = await self._extract_keyword_from_input(user_input)
            
            # íˆ´ íƒ€ì…ë³„ ì‹¤í–‰
            if tool_type == "trend_analysis":
                keywords = [target_keyword] + await self._generate_related_keywords(target_keyword, 4)
                result = await self.analysis_tools.analyze_naver_trends(keywords)
                
            elif tool_type == "hashtag_analysis":
                result = await self.analysis_tools.analyze_instagram_hashtags(
                    question=user_input,
                    user_hashtags=[target_keyword]
                )
                
            elif tool_type == "content_generation":
                # ì´ë¯¸ ìœ„ì—ì„œ ë‹¨ê³„ ì²´í¬ë¥¼ í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë°”ë¡œ ì‹¤í–‰
                if content_type == "blog":
                    result = await self.analysis_tools.create_blog_content_workflow(target_keyword)
                elif content_type == "instagram":
                    result = await self.analysis_tools.create_instagram_content_workflow(target_keyword)
                else:
                    # ì¼ë°˜ì ì¸ ì½˜í…ì¸  ìƒì„±
                    result = await self.analysis_tools.generate_instagram_content()
                    
            elif tool_type == "keyword_research":
                keywords = await self.analysis_tools.generate_related_keywords(target_keyword, 15)
                trend_result = await self.analysis_tools.analyze_naver_trends(keywords[:5])
                result = {
                    "success": True,
                    "keywords": keywords,
                    "trend_data": trend_result
                }
                
            else:
                return {
                    "success": False,
                    "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íˆ´ íƒ€ì…: {tool_type}",
                    "tool_type": tool_type
                }
            
            # ê²°ê³¼ì— íˆ´ ì •ë³´ ì¶”ê°€
            if isinstance(result, dict):
                result["tool_type"] = tool_type
                result["target_keyword"] = target_keyword
                result["content_type"] = content_type
            
            logger.info(f"[íˆ´ ì‹¤í–‰] ì™„ë£Œ: {result.get('success', False)}")
            return result
            
        except Exception as e:
            logger.error(f"ë§ˆì¼€íŒ… íˆ´ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "tool_type": tool_requirements.get("tool_type", "unknown")
            }
    
    async def generate_response_with_tool_result(self, user_input: str, intent_analysis: Dict[str, Any], 
                                               context: Dict[str, Any], tool_result: Dict[str, Any]) -> str:
        """íˆ´ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì‘ë‹µ ìƒì„±"""
        try:
            tool_type = tool_result.get("tool_type", "unknown")
            success = tool_result.get("success", False)
            
            if not success:
                error_msg = tool_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                
                # ë‹¨ê³„ ì œí•œ ì˜¤ë¥˜ íŠ¹ë³„ ì²˜ë¦¬ (ì½˜í…ì¸  ìƒì„±)
                if "stage_requirement" in tool_result:
                    current_stage = tool_result.get("current_stage", "unknown")
                    required_stage = tool_result.get("stage_requirement", "unknown")
                    suggestion = tool_result.get("suggestion", "")
                    
                    response = f"ğŸš§ **ì½˜í…ì¸  ìƒì„± ë‹¨ê³„ ì•ˆë‚´**\n\n"
                    response += f"í˜„ì¬ ë‹¨ê³„: **{current_stage}**\n"
                    response += f"ìš”êµ¬ ë‹¨ê³„: **{required_stage}**\n\n"
                    response += f"ğŸ“„ **ì•ˆë‚´ì‚¬í•­**:\n{suggestion}\n\n"
                    response += "ğŸš€ **ë‹¨ê³„ë³„ ì§„í–‰ ë°©ë²•**:\n"
                    response += "â€¢ 'ë‹¨ê³„ ì´ë™' ë˜ëŠ” '4ë‹¨ê³„ë¡œ ì´ë™'ì´ë¼ê³  ë§ì”©í•˜ì„¸ìš”\n"
                    response += "â€¢ 'ì²´ê³„ì  ìƒë‹´ ì‹œì‘'ìœ¼ë¡œ 1ë‹¨ê³„ë¶€í„° ì§„í–‰í•˜ì„¸ìš”\n"
                    response += "â€¢ í˜„ì¬ ë‹¨ê³„ì—ì„œ ë‹¤ë¥¸ ë§ˆì¼€íŒ… ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”"
                    
                    return response
                
                # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬
                return f"ì£„ì†¡í•©ë‹ˆë‹¤. {tool_type} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}\n\nì¼ë°˜ì ì¸ ë§ˆì¼€íŒ… ì¡°ì–¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            
            # íˆ´ íƒ€ì…ë³„ ê²°ê³¼ í¬ë§·íŒ…
            if tool_type == "trend_analysis":
                return await self._format_trend_analysis_response(user_input, tool_result, context)
            elif tool_type == "hashtag_analysis":
                return await self._format_hashtag_analysis_response(user_input, tool_result, context)
            elif tool_type == "content_generation":
                return await self._format_content_generation_response(user_input, tool_result, context)
            elif tool_type == "keyword_research":
                return await self._format_keyword_research_response(user_input, tool_result, context)
            else:
                return await self._format_general_tool_response(user_input, tool_result, context)
                
        except Exception as e:
            logger.error(f"íˆ´ ê²°ê³¼ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë§ˆì¼€íŒ… ë¶„ì„ì„ ì§„í–‰í–ˆì§€ë§Œ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    async def _extract_keyword_from_input(self, user_input: str) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            from shared_modules import get_llm_manager
            llm_manager = get_llm_manager()
            
            messages = [
                {"role": "system", "content": "ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë§ˆì¼€íŒ… ë¶„ì„ì— ê°€ì¥ ì í•©í•œ ì£¼ìš” í‚¤ì›Œë“œ 1ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. í‚¤ì›Œë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”."},
                {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”: {user_input}"}
            ]
            
            result = llm_manager.generate_response_sync(messages)
            return result.strip() if result else "ë§ˆì¼€íŒ…"
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "ë§ˆì¼€íŒ…"
    
    async def _generate_related_keywords(self, base_keyword: str, count: int = 5) -> List[str]:
        """ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„± (ê°„ë‹¨ ë²„ì „)"""
        try:
            if self.analysis_tools:
                keywords = await self.analysis_tools.generate_related_keywords(base_keyword, count)
                return keywords[1:]  # ê¸°ë³¸ í‚¤ì›Œë“œ ì œì™¸
            return []
        except Exception as e:
            logger.error(f"ê´€ë ¨ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    async def _format_trend_analysis_response(self, user_input: str, tool_result: Dict[str, Any], context: Dict[str, Any]) -> str:
        """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        try:
            data = tool_result.get("data", [])
            keywords = tool_result.get("keywords", [])
            period = tool_result.get("period", "")
            
            response = f"ğŸ“ˆ **í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼**\n\n"
            response += f"ğŸ” **ë¶„ì„ ê¸°ê°„**: {period}\n"
            response += f"ğŸ¯ **ë¶„ì„ í‚¤ì›Œë“œ**: {', '.join(keywords)}\n\n"
            
            if data:
                response += "ğŸ“Š **íŠ¸ë Œë“œ ìˆœìœ„**:\n"
                # íŠ¸ë Œë“œ ë°ì´í„° ì •ë ¬ ë° í‘œì‹œ
                trend_scores = []
                for result in data[:5]:  # ìƒìœ„ 5ê°œë§Œ
                    if "data" in result:
                        scores = [item["ratio"] for item in result["data"] if "ratio" in item]
                        avg_score = sum(scores) / len(scores) if scores else 0
                        trend_scores.append((result["title"], avg_score))
                
                trend_scores.sort(key=lambda x: x[1], reverse=True)
                
                for i, (keyword, score) in enumerate(trend_scores, 1):
                    response += f"{i}. **{keyword}** (í‰ê·  ê²€ìƒ‰ëŸ‰: {score:.1f})\n"
                
                response += "\nğŸ’¡ **ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸**:\n"
                if trend_scores:
                    top_keyword = trend_scores[0][0]
                    response += f"â€¢ '{top_keyword}'ê°€ ê°€ì¥ ë†’ì€ ê²€ìƒ‰ íŠ¸ë Œë“œë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.\n"
                    response += f"â€¢ ì´ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì½˜í…ì¸ ë¥¼ ì œì‘í•˜ë©´ ë†’ì€ ê´€ì‹¬ë„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                
            else:
                response += "íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ í™œìš© ë°©ì•ˆì„ ì œì‹œë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n"
            
            # í›„ì† ì œì•ˆ
            response += "\nğŸ¬ **ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ**:\n"
            response += "â€¢ ë¸”ë¡œê·¸ ì½˜í…ì¸  ì œì‘\nâ€¢ ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„\nâ€¢ SEO ìµœì í™” ì „ëµ ìˆ˜ë¦½\n"
            
            return response
            
        except Exception as e:
            logger.error(f"íŠ¸ë Œë“œ ë¶„ì„ ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return "íŠ¸ë Œë“œ ë¶„ì„ì„ ì™„ë£Œí–ˆì§€ë§Œ ê²°ê³¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _format_hashtag_analysis_response(self, user_input: str, tool_result: Dict[str, Any], context: Dict[str, Any]) -> str:
        """í•´ì‹œíƒœê·¸ ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        try:
            searched_hashtags = tool_result.get("searched_hashtags", [])
            popular_hashtags = tool_result.get("popular_hashtags", [])
            total_posts = tool_result.get("total_posts", 0)
            
            response = f"#ï¸âƒ£ **ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ ê²°ê³¼**\n\n"
            response += f"ğŸ” **ë¶„ì„ í•´ì‹œíƒœê·¸**: #{', #'.join(searched_hashtags)}\n"
            response += f"ğŸ“Š **ë¶„ì„ëœ í¬ìŠ¤íŠ¸ ìˆ˜**: {total_posts:,}ê°œ\n\n"
            
            if popular_hashtags:
                response += "ğŸ”¥ **ì¶”ì²œ ì¸ê¸° í•´ì‹œíƒœê·¸**:\n"
                for i, hashtag in enumerate(popular_hashtags[:15], 1):
                    if not hashtag.startswith('#'):
                        hashtag = f"#{hashtag}"
                    response += f"{i}. {hashtag}\n"
                
                response += "\nğŸ’¡ **í•´ì‹œíƒœê·¸ í™œìš© íŒ**:\n"
                response += "â€¢ ì¸ê¸° í•´ì‹œíƒœê·¸ì™€ í‹ˆìƒˆ í•´ì‹œíƒœê·¸ë¥¼ ì ì ˆíˆ ì¡°í•©í•˜ì„¸ìš”\n"
                response += "â€¢ í¬ìŠ¤íŠ¸ë‹¹ 20-30ê°œì˜ í•´ì‹œíƒœê·¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤\n"
                response += "â€¢ ë¸Œëœë“œë§Œì˜ ê³ ìœ  í•´ì‹œíƒœê·¸ë„ í•¨ê»˜ í™œìš©í•˜ì„¸ìš”\n"
            else:
                response += "í•´ì‹œíƒœê·¸ ë°ì´í„° ìˆ˜ì§‘ì— ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ í•´ì‹œíƒœê·¸ ì „ëµì„ ì œì•ˆë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n"
            
            # í›„ì† ì œì•ˆ
            response += "\nğŸ“ **ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ**:\n"
            response += "â€¢ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ì œì‘\nâ€¢ í•´ì‹œíƒœê·¸ ì„±ê³¼ ë¶„ì„\nâ€¢ ê²½ìŸì‚¬ í•´ì‹œíƒœê·¸ ì—°êµ¬\n"
            
            return response
            
        except Exception as e:
            logger.error(f"í•´ì‹œíƒœê·¸ ë¶„ì„ ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return "í•´ì‹œíƒœê·¸ ë¶„ì„ì„ ì™„ë£Œí–ˆì§€ë§Œ ê²°ê³¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _format_content_generation_response(self, user_input: str, tool_result: Dict[str, Any], context: Dict[str, Any]) -> str:
        """ì½˜í…ì¸  ìƒì„± ê²°ê³¼ í¬ë§·íŒ…"""
        try:
            content_type = tool_result.get("content_type", "general")
            base_keyword = tool_result.get("base_keyword", "")
            
            response = f"âœï¸ **{content_type.upper()} ì½˜í…ì¸  ìƒì„± ì™„ë£Œ**\n\n"
            response += f"ğŸ¯ **ì£¼ìš” í‚¤ì›Œë“œ**: {base_keyword}\n\n"
            
            if content_type == "blog":
                blog_content = tool_result.get("blog_content", {})
                if blog_content and "full_content" in blog_content:
                    response += "ğŸ“ **ìƒì„±ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸ **:\n"
                    response += f"{blog_content['full_content'][:1000]}...\n\n"
                    response += f"ğŸ“Š **ì½˜í…ì¸  ì •ë³´**: ì•½ {blog_content.get('word_count', 0)}ë‹¨ì–´\n"
                
            elif content_type == "instagram":
                instagram_content = tool_result.get("instagram_content", {})
                if instagram_content and "post_content" in instagram_content:
                    response += "ğŸ“± **ìƒì„±ëœ ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸**:\n"
                    response += f"{instagram_content['post_content']}\n\n"
                    
                    hashtags = instagram_content.get("selected_hashtags", [])
                    if hashtags:
                        response += f"#ï¸âƒ£ **ì¶”ì²œ í•´ì‹œíƒœê·¸** ({len(hashtags)}ê°œ):\n"
                        response += " ".join(hashtags[:20]) + "\n\n"
            
            # ê´€ë ¨ í‚¤ì›Œë“œ ì •ë³´
            related_keywords = tool_result.get("related_keywords", [])
            if related_keywords:
                response += f"ğŸ”‘ **ê´€ë ¨ í‚¤ì›Œë“œ**: {', '.join(related_keywords[:10])}\n\n"
            
            response += "ğŸ’¡ **í™œìš© ê°€ì´ë“œ**:\n"
            response += "â€¢ ìƒì„±ëœ ì½˜í…ì¸ ë¥¼ ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”\n"
            response += "â€¢ íƒ€ê²Ÿ ê³ ê°ì˜ ê´€ì‹¬ì‚¬ë¥¼ ë°˜ì˜í•´ ê°œì¸í™”í•˜ì„¸ìš”\n"
            response += "â€¢ ì •ê¸°ì ì¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸ë¡œ ì§€ì†ì ì¸ ê´€ì‹¬ì„ ìœ ë„í•˜ì„¸ìš”\n"
            
            return response
            
        except Exception as e:
            logger.error(f"ì½˜í…ì¸  ìƒì„± ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return "ì½˜í…ì¸  ìƒì„±ì„ ì™„ë£Œí–ˆì§€ë§Œ ê²°ê³¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _format_keyword_research_response(self, user_input: str, tool_result: Dict[str, Any], context: Dict[str, Any]) -> str:
        """í‚¤ì›Œë“œ ì—°êµ¬ ê²°ê³¼ í¬ë§·íŒ…"""
        try:
            keywords = tool_result.get("keywords", [])
            trend_data = tool_result.get("trend_data", {})
            
            response = f"ğŸ” **í‚¤ì›Œë“œ ì—°êµ¬ ê²°ê³¼**\n\n"
            
            if keywords:
                response += f"ğŸ“ **ì¶”ì²œ í‚¤ì›Œë“œ** ({len(keywords)}ê°œ):\n"
                for i, keyword in enumerate(keywords[:15], 1):
                    response += f"{i}. {keyword}\n"
                response += "\n"
            
            if trend_data.get("success") and trend_data.get("data"):
                response += "ğŸ“ˆ **íŠ¸ë Œë“œ ë¶„ì„**:\n"
                for result in trend_data["data"][:5]:
                    if "data" in result:
                        scores = [item["ratio"] for item in result["data"] if "ratio" in item]
                        avg_score = sum(scores) / len(scores) if scores else 0
                        response += f"â€¢ {result['title']}: í‰ê·  ê²€ìƒ‰ëŸ‰ {avg_score:.1f}\n"
                response += "\n"
            
            response += "ğŸ¯ **SEO í™œìš© ì „ëµ**:\n"
            response += "â€¢ ì¥ê¼¬ë¦¬ í‚¤ì›Œë“œ(Long-tail)ë¥¼ í™œìš©í•´ ê²½ìŸë„ë¥¼ ë‚®ì¶”ì„¸ìš”\n"
            response += "â€¢ ê³„ì ˆì„±ê³¼ íŠ¸ë Œë“œë¥¼ ê³ ë ¤í•œ í‚¤ì›Œë“œ ì„ íƒì„ í•˜ì„¸ìš”\n"
            response += "â€¢ ì§€ì—­ ê¸°ë°˜ í‚¤ì›Œë“œë¡œ ë¡œì»¬ SEOë¥¼ ê°•í™”í•˜ì„¸ìš”\n"
            
            return response
            
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì—°êµ¬ ì‘ë‹µ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
            return "í‚¤ì›Œë“œ ì—°êµ¬ë¥¼ ì™„ë£Œí–ˆì§€ë§Œ ê²°ê³¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _format_general_tool_response(self, user_input: str, tool_result: Dict[str, Any], context: Dict[str, Any]) -> str:
        """ì¼ë°˜ íˆ´ ê²°ê³¼ í¬ë§·íŒ…"""
        return f"ë§ˆì¼€íŒ… ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì „ëµì„ ì œì•ˆë“œë¦¬ê² ìŠµë‹ˆë‹¤."

    def load_stage_prompts_for_business(self, business_type: str) -> Dict[str, str]:
        """ì—…ì¢…ë³„ ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        prompts = {}
        
        # ì—…ì¢…ë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë§¤í•‘
        business_prompt_mapping = {
            "ë·°í‹°": [
                "personal_branding.md", "social_media_marketing.md", "local_marketing.md",
                "content_marketing.md", "influencer_marketing.md", "blog_marketing.md"
            ],
            "ìŒì‹ì ": [
                "local_marketing.md", "social_media_marketing.md", "content_marketing.md",
                "email_marketing.md", "blog_marketing.md", "marketing_fundamentals.md"
            ],
            "ì˜¨ë¼ì¸ì‡¼í•‘ëª°": [
                "digital_advertising.md", "content_marketing.md", "conversion_optimization.md",
                "marketing_automation.md", "email_marketing.md", "marketing_metrics.md"
            ],
            "ì„œë¹„ìŠ¤ì—…": [
                "personal_branding.md", "content_marketing.md", "blog_marketing.md",
                "marketing_fundamentals.md", "marketing_metrics.md"
            ],
            "ì•±": [
                "viral_marketing.md", "email_marketing.md", "marketing_metrics.md",
                "content_marketing.md"
            ],
            "í¬ë¦¬ì—ì´í„°": [
                "personal_branding.md",
                "content_marketing.md", "blog_marketing.md", "social_media_marketing.md",
                "influencer_marketing.md"
            ]
        }

        
        prompt_files = business_prompt_mapping.get(business_type, [])
        
        for prompt_file in prompt_files:
            try:
                prompt_path = self.prompts_dir / prompt_file
                if prompt_path.exists():
                    with open(prompt_path, 'r', encoding='utf-8') as f:
                        prompts[prompt_file.replace('.md', '')] = f.read()
            except Exception as e:
                logger.error(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({prompt_file}): {e}")
        
        return prompts

    def load_all_stage_prompts(self) -> Dict[str, str]:
        """ëª¨ë“  ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        prompts = {}
        
        all_prompt_files = [
            "marketing_fundamentals.md",
            "marketing_metrics.md", 
            "personal_branding.md",
            "social_media_marketing.md",
            "influencer_marketing.md",
            "local_marketing.md",
            "digital_advertising.md",
            "content_marketing.md",
            "blog_marketing.md",
            "viral_marketing.md",
            "conversion_optimization.md",
            "email_marketing.md",
            "marketing_automation.md"
        ]
        
        for prompt_file in all_prompt_files:
            try:
                prompt_path = self.prompts_dir / prompt_file
                if prompt_path.exists():
                    with open(prompt_path, 'r', encoding='utf-8') as f:
                        prompts[prompt_file.replace('.md', '')] = f.read()
            except Exception as e:
                logger.error(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({prompt_file}): {e}")
        
        return prompts

    def get_or_create_conversation_state(self, conversation_id: int, user_id: int) -> 'FlexibleConversationState':
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ ë˜ëŠ” ìƒì„±"""
        if conversation_id not in self.conversation_states:
            self.conversation_states[conversation_id] = FlexibleConversationState(conversation_id, user_id)
        return self.conversation_states[conversation_id]

    def handle_flow_control(self, command: str, state: 'FlexibleConversationState', 
                                user_input: str) -> Dict[str, Any]:
        """ì§„í–‰ ì œì–´ ì²˜ë¦¬"""
        logger.info(f"[ë‹¨ê³„ ë¡œê·¸] ì§„í–‰ ì œì–´ ì²˜ë¦¬ - ëª…ë ¹: {command}, í˜„ì¬ ë‹¨ê³„: {state.current_stage.value}")

        
        if command == "pause":
            state.is_paused = True
            return {
                "action": "paused",
                "message": f"ğŸ›‘ ëŒ€í™”ë¥¼ ì¼ì‹œ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬ ì§„í–‰ ìƒí™©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤. 'ì¬ê°œ'ë¼ê³  ë§ì”€í•˜ì‹œë©´ ì´ì–´ì„œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.",
                "pause_info": {
                    "stage": state.current_stage.value,
                    "completion": state.get_overall_completion_rate(),
                    "paused_at": datetime.now().isoformat()
                }
            }
        
        elif command == "resume":
            state.is_paused = False
            return {
                "action": "resumed", 
                "message": f"â–¶ï¸ ëŒ€í™”ë¥¼ ì¬ê°œí•©ë‹ˆë‹¤!\n\ní˜„ì¬ {state.current_stage.value} ë‹¨ê³„ì—ì„œ ê³„ì† ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.",
                "current_stage": state.current_stage.value
            }
        
        elif command == "skip":
            available_stages = [s for s in MarketingStage if s != state.current_stage and s not in [MarketingStage.ANY_QUESTION, MarketingStage.COMPLETED]]
            return {
                "action": "stage_selection",
                "message": "ì–´ë–¤ ë‹¨ê³„ë¡œ ì´ë™í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                "options": [s.value for s in available_stages]
            }
        
        elif command == "restart":
            state.reset_conversation()
            return {
                "action": "restarted",
                "message": "ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤!\n\nì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                "options": ["ì²´ê³„ì  4ë‹¨ê³„ ì§„í–‰", "ì¦‰ì‹œ ì§ˆë¬¸ ì‘ë‹µ", "íŠ¹ì • ë‹¨ê³„ë¡œ ì´ë™"]
            }
        
        elif command == "next":
            next_stage = state.get_next_stage()
            if next_stage:
                state.current_stage = next_stage
                
                # ë‹¨ê³„ ì´ë™ í›„ í•´ë‹¹ ë‹¨ê³„ì˜ ì§ˆë¬¸ ìë™ ìƒì„±
                stage_questions = {
                    MarketingStage.STAGE_1_GOAL: "ğŸ¯ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ë§ˆì¼€íŒ… ëª©í‘œë¥¼ ëª…í™•íˆ í•´ë³´ì„¸ìš”! êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ê²°ê³¼ë¥¼ ì–»ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (ì˜ˆ: ë§¤ì¶œ ì¦ëŒ€, ë¸Œëœë“œ ì¸ì§€ë„ í–¥ìƒ, ê³ ê° ìœ ì¹˜ ë“±)",
                    MarketingStage.STAGE_2_TARGET: "ğŸ¯ íƒ€ê²Ÿ ê³ ê° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤! ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì€ ëˆ„êµ¬ì¸ê°€ìš”? ì—°ë ¹ëŒ€, ì„±ë³„, ê´€ì‹¬ì‚¬, ë¼ì´í”„ìŠ¤íƒ€ì¼ ë“±ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
                    MarketingStage.STAGE_3_STRATEGY: "ğŸ“Š ë§ˆì¼€íŒ… ì „ëµ ê¸°íš ë‹¨ê³„ì…ë‹ˆë‹¤! ì–´ë–¤ ë§ˆì¼€íŒ… ì±„ë„ì— ì§‘ì¤‘í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (ì˜ˆ: SNS, ë¸”ë¡œê·¸, ê´‘ê³ , ì´ë²¤íŠ¸ ë“±) ì˜ˆì‚°ê³¼ ëª©í‘œë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.",
                    MarketingStage.STAGE_4_EXECUTION: "ğŸš€ ë§ˆì¼€íŒ… ì‹¤í–‰ ë‹¨ê³„ì…ë‹ˆë‹¤! ì´ì œ êµ¬ì²´ì ì¸ ì½˜í…ì¸ ë‚˜ ìº í˜ì¸ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”. ë¸”ë¡œê·¸ ê¸€, ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸, ê´‘ê³  ì½˜í…ì¸  ì¤‘ ë¬´ì—‡ì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
                }
                
                stage_message = f"â­ï¸ {next_stage.value} ë‹¨ê³„ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.\n\n"
                stage_question = stage_questions.get(next_stage, "ìƒˆë¡œìš´ ë‹¨ê³„ì—ì„œ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?")
                
                return {
                    "action": "next_stage",
                    "message": stage_message + stage_question,
                    "new_stage": next_stage.value,
                    "include_question": True
                }
            else:
                return {
                    "action": "no_next_stage",
                    "message": "ë” ì´ìƒ ì§„í–‰í•  ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”."
                }
        
        return {"action": "unknown_command", "message": f"'{command}' ëª…ë ¹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    def jump_to_stage(self, target_stage: str, state: 'FlexibleConversationState') -> Dict[str, Any]:
        """íŠ¹ì • ë‹¨ê³„ë¡œ ì´ë™"""
        
        stage_mapping = {
            "1": MarketingStage.STAGE_1_GOAL,
            "2": MarketingStage.STAGE_2_TARGET,
            "3": MarketingStage.STAGE_3_STRATEGY,
            "4": MarketingStage.STAGE_4_EXECUTION,
            "ëª©í‘œ": MarketingStage.STAGE_1_GOAL,
            "íƒ€ê²Ÿ": MarketingStage.STAGE_2_TARGET,
            "ì „ëµ": MarketingStage.STAGE_3_STRATEGY,
            "ì‹¤í–‰": MarketingStage.STAGE_4_EXECUTION,
            "any": MarketingStage.ANY_QUESTION
        }
        
        if target_stage not in stage_mapping:
            return {
                "success": False,
                "message": f"'{target_stage}' ë‹¨ê³„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "available_stages": list(stage_mapping.keys())
            }
        
        target_stage_enum = stage_mapping[target_stage]
        state.current_stage = target_stage_enum
        state.updated_at = datetime.now()
        
        # ìì—°ìŠ¤ëŸ¬ìš´ ë‹¨ê³„ ì „í™˜ ë©”ì‹œì§€ (ìˆ˜ì§‘ëœ ì •ë³´ í™œìš©)
        business_info = state.get_information("business_info_business_type") or "ë¹„ì¦ˆë‹ˆìŠ¤"
        
        stage_messages = {
            MarketingStage.STAGE_1_GOAL: "ğŸ¯ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ë§ˆì¼€íŒ… ëª©í‘œë¥¼ ëª…í™•íˆ í•´ë³´ì„¸ìš”! êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ê²°ê³¼ë¥¼ ì–»ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (ì˜ˆ: ë§¤ì¶œ ì¦ëŒ€, ë¸Œëœë“œ ì¸ì§€ë„ í–¥ìƒ, ê³ ê° ìœ ì¹˜ ë“±)",
            MarketingStage.STAGE_2_TARGET: "ğŸ¯íƒ€ê²Ÿ ê³ ê° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤! ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì€ ëˆ„êµ¬ì¸ê°€ìš”? ì—°ë ¹ëŒ€, ì„±ë³„, ê´€ì‹¬ì‚¬, ë¼ì´í”„ìŠ¤íƒ€ì¼ ë“±ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
            MarketingStage.STAGE_3_STRATEGY: "ğŸ“Š ë§ˆì¼€íŒ… ì „ëµ ê¸°íš ë‹¨ê³„ì…ë‹ˆë‹¤! ì–´ë–¤ ë§ˆì¼€íŒ… ì±„ë„ì— ì§‘ì¤‘í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?(ì˜ˆ: SNS, ë¸”ë¡œê·¸, ê´‘ê³ , ì´ë²¤íŠ¸ ë“±) ì˜ˆì‚°ê³¼ ëª©í‘œë„ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.",
            MarketingStage.STAGE_4_EXECUTION: "ğŸš€ ë§ˆì¼€íŒ… ì‹¤í–‰ ë‹¨ê³„ì…ë‹ˆë‹¤! ì´ì œ êµ¬ì²´ì ì¸ ì½˜í…ì¸ ë‚˜ ìºí˜ì¸ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”. ë¸”ë¡œê·¸ ê¸€, ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸, ê´‘ê³  ì½˜í…ì¸  ì¤‘ ë¬´ì—‡ì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
            MarketingStage.ANY_QUESTION: "ììœ ë¡­ê²Œ ë§ˆì¼€íŒ… ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. ë°”ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"
        }
        
        return {
            "success": True,
            "message": stage_messages[target_stage_enum],
            "new_stage": target_stage_enum.value
        }
    
    def prepare_conversation_context(self, user_id: int, conversation_id: Optional[int]) -> Dict[str, Any]:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        
        context = {
            "user_id": user_id,
            "conversation_id": conversation_id,
            "conversation_mode": "flexible",
            "current_stage": MarketingStage.ANY_QUESTION.value,
            "collected_info": {},
            "business_type": "ì¼ë°˜",
            "history_summary": "ìƒˆë¡œìš´ ëŒ€í™”"
        }
        
        if conversation_id and conversation_id in self.conversation_states:
            state = self.conversation_states[conversation_id]
            context.update({
                "current_stage": state.current_stage.value,
                "collected_info": state.collected_info,
                "business_type": state.detected_business_type,
                "history_summary": self.summarize_conversation_history(state)
            })
        
        return context

    def summarize_conversation_history(self, state: 'FlexibleConversationState') -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½"""
        
        if not hasattr(state, 'conversation_history') or not state.conversation_history:
            return "ìƒˆë¡œìš´ ëŒ€í™”"
        
        # ìµœê·¼ ëŒ€í™” ìš”ì•½ (ê°„ë‹¨í•˜ê²Œ)
        recent = state.conversation_history[-3:]
        collected_info = state.collected_info
        
        summary_parts = []
        if collected_info:
            summary_parts.append(f"ìˆ˜ì§‘ëœ ì •ë³´: {len(collected_info)}ê°œ í•­ëª©")
        if state.detected_business_type != "ì¼ë°˜":
            summary_parts.append(f"ì—…ì¢…: {state.detected_business_type}")
        
        return " | ".join(summary_parts) if summary_parts else "ë§ˆì¼€íŒ… ìƒë‹´ ì§„í–‰ ì¤‘"

    async def process_user_query(self, user_input: str, user_id: int, 
                          conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """ë©”ì¸ ì¿¼ë¦¬ ì²˜ë¦¬ í•¨ìˆ˜"""
        return await self._process_user_query_async(user_input, user_id, conversation_id)

    async def _process_user_query_async(self, user_input: str, user_id: int, 
                                      conversation_id: Optional[int] = None) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬"""
        
        try:
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] === ë§ˆì¼€íŒ… ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘ ===\nì‚¬ìš©ì ì…ë ¥: {user_input[:50]}...\nì‚¬ìš©ì ID: {user_id}\nëŒ€í™” ID: {conversation_id}")
            
            # ëŒ€í™” ì„¸ì…˜ ì²˜ë¦¬
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 1. ëŒ€í™” ì„¸ì…˜ ì²˜ë¦¬ ì‹œì‘")
            session_info = get_or_create_conversation_session(user_id, conversation_id)
            conversation_id = session_info["conversation_id"]
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ì„¸ì…˜ ì²˜ë¦¬ ì™„ë£Œ: {conversation_id}")
            
            # ëŒ€í™” ìƒíƒœ ì¡°íšŒ/ìƒì„±
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 2. ëŒ€í™” ìƒíƒœ ì¡°íšŒ/ìƒì„±")
            state = self.get_or_create_conversation_state(conversation_id, user_id)
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - í˜„ì¬ ë‹¨ê³„: {state.current_stage.value}")
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            with get_session_context() as db:
                create_message(db, conversation_id, "user", "marketing", user_input)
            
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 3. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„")
            context = self.prepare_conversation_context(user_id, conversation_id)
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ: {context.get('business_type')}, {context.get('current_stage')}")
            
            # 1. LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 4. LLM ì˜ë„ ë¶„ì„ ì‹œì‘")
            intent_analysis = self.analyze_user_intent_with_llm(user_input, context)
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent_analysis.get('response_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            
            # 2. ì—…ì¢… ê°ì§€ (í•„ìš”ì‹œ) ë° ì •ë³´ ì—…ë°ì´íŠ¸
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 5. ì—…ì¢… ê°ì§€ ë° ì •ë³´ ì—…ë°ì´íŠ¸")
            
            # ì²« ë²ˆì§¸ ëŒ€í™”ì—ì„œ ì—…ì¢… ê°ì§€ ë° ì €ì¥
            if context.get("business_type") and context["business_type"] != "ì¼ë°˜":
                state.detected_business_type = context["business_type"]
                state.add_information("business_info_business_type", context["business_type"], "auto_detected")
                logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ì—…ì¢… ì •ë³´ ì €ì¥: {context['business_type']}")
            
            # ì¶”ê°€ ì¶”ì¶œ ë˜ëŠ” LLM ê¸°ë°˜ ê°ì§€
            if intent_analysis.get("context_needs", {}).get("business_type_detection"):
                detected_type = self.detect_business_type_with_llm(user_input, context)
                if detected_type != "ì¼ë°˜" and detected_type != state.detected_business_type:
                    state.detected_business_type = detected_type
                    state.add_information("business_info_business_type", detected_type, "llm_detected")
                    context["business_type"] = detected_type
            
            # 3. ì§„í–‰ ì œì–´ ëª…ë ¹ ì²˜ë¦¬
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 6. ì§„í–‰ ì œì–´ ëª…ë ¹ ì²˜ë¦¬")
            flow_control = intent_analysis.get("flow_control", {})
            control_command = flow_control.get("control_command", "none")
            stage_preference = flow_control.get("stage_preference")
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ì œì–´ ëª…ë ¹: {control_command}")
            
            if control_command != "none":
                control_result = self.handle_flow_control(control_command, state, user_input)
                response_content = control_result["message"]
                
                # íŠ¹ë³„í•œ ê²½ìš° ì²˜ë¦¬
                if control_command == "skip" and "options" in control_result:
                    response_content += "\n\nì„ íƒ ê°€ëŠ¥í•œ ë‹¨ê³„:\n" + "\n".join([f"â€¢ {opt}" for opt in control_result["options"]])
            
            elif stage_preference and stage_preference != "any" and stage_preference != "none":
                # 4. ë‹¨ê³„ ì´ë™ ì²˜ë¦¬ - ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±
                logger.info("[ë‹¨ê³„ ë¡œê·¸] 7. ë‹¨ê³„ ì´ë™ ì²˜ë¦¬")
                jump_result = self.jump_to_stage(stage_preference, state)
                
                if jump_result["success"]:
                    # ë‹¨ê³„ ì´ë™ ì„±ê³µ - ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì‹œì§€ë¡œ ì‘ë‹µ
                    response_content = jump_result["message"]
                else:
                    # ë‹¨ê³„ ì´ë™ ì‹¤íŒ¨ - ì˜¤ë¥˜ ë©”ì‹œì§€
                    response_content = jump_result["message"]
            
            # 5. ë§ˆì¼€íŒ… íˆ´ ì‚¬ìš© í•„ìš”ì„± ê²€ì‚¬
            elif intent_analysis.get("response_type") == "tool_required" or intent_analysis.get("tool_requirements", {}).get("needs_tool"):
                logger.info("[ë‹¨ê³„ ë¡œê·¸] 8. ë§ˆì¼€íŒ… íˆ´ ì‚¬ìš© ì‹œì‘")
                tool_result = await self.execute_marketing_tool(user_input, intent_analysis, context)
                logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - íˆ´ ì‹¤í–‰ ì™„ë£Œ: {tool_result.get('success', False)}")
                
                # íˆ´ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì‘ë‹µ ìƒì„±
                response_content = await self.generate_response_with_tool_result(
                    user_input, intent_analysis, context, tool_result
                )
                
            # 6. ì¼ë°˜ ì‘ë‹µ ìƒì„±
            else:
                try:
                    logger.info("[ë‹¨ê³„ ë¡œê·¸] 9. ì¼ë°˜ ì‘ë‹µ ìƒì„± ì‹œì‘")
                    # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
                    response_content = self.generate_contextual_response(user_input, intent_analysis, context)
                    logger.info("[ë‹¨ê³„ ë¡œê·¸] - ì‘ë‹µ ìƒì„± ì™„ë£Œ")
                    
                    # ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
                    next_action = self.determine_next_action(user_input, intent_analysis, context)
                    
                    # ì‚¬ìš©ì ì˜µì…˜ ì¶”ê°€
                    if next_action and next_action.get("user_options"):
                        options_text = "\n\nğŸ’¡ **ë‹¤ìŒ ì˜µì…˜:**\n" + "\n".join([f"â€¢ {opt}" for opt in next_action["user_options"]])
                        response_content += options_text
                except Exception as e:
                    logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    response_content = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
            # ì •ë³´ ìˆ˜ì§‘ ë° ì—…ë°ì´íŠ¸
            logger.info("[ë‹¨ê³„ ë¡œê·¸] 10. ì •ë³´ ìˆ˜ì§‘ ë° ì—…ë°ì´íŠ¸")
            self.update_collected_information(user_input, intent_analysis, state)
            logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ìˆ˜ì§‘ëœ ì •ë³´ ìˆ˜: {len(state.collected_info)}")
            
            # ì‘ë‹µ ë©”ì‹œì§€ ì €ì¥
            insert_message_raw(
                conversation_id=conversation_id,
                sender_type="agent",
                agent_type="marketing",
                content=response_content
            )
            
            # í‘œì¤€ ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            logger.info("[ë‹¨ê³„ ë¡œê·¸] === ë§ˆì¼€íŒ… ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ ===")
            return create_marketing_response(
                conversation_id=conversation_id,
                answer=response_content,
                topics=[],
                sources="LLM ê¸°ë°˜ ìœ ì—°í•œ ë§ˆì¼€íŒ… ì‹œìŠ¤í…œ",
                intent=intent_analysis.get("response_type", "flexible"),
                confidence=0.9,
                conversation_stage=state.current_stage.value,
                completion_rate=state.get_overall_completion_rate(),
                collected_info=state.collected_info,
                mcp_results={},
                multiturn_flow=True,
                flexible_mode=True,
                intent_analysis=intent_analysis
            )
            
        except Exception as e:
            logger.error(f"LLM ê¸°ë°˜ ë§ˆì¼€íŒ… ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return create_error_response(
                error_message=f"ë§ˆì¼€íŒ… ìƒë‹´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                error_code="LLM_MARKETING_ERROR"
            )

    def update_collected_information(self, user_input: str, intent_analysis: Dict[str, Any], 
                                         state: 'FlexibleConversationState'):
        """ìˆ˜ì§‘ëœ ì •ë³´ ì—…ë°ì´íŠ¸"""
        logger.info(f"[ë‹¨ê³„ ë¡œê·¸] ì •ë³´ ìˆ˜ì§‘ ì‹œì‘ - í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´: {len(state.collected_info)}ê°œ")
        
        # LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì •ë³´ ì¶”ì¶œ
        extraction_prompt = f"""ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë§ˆì¼€íŒ… ìƒë‹´ì— ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì…ë ¥: "{user_input}"
ê¸°ì¡´ ì •ë³´: {json.dumps(state.collected_info, ensure_ascii=False)}

ë‹¤ìŒ í•­ëª©ë“¤ì„ JSON í˜•íƒœë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
{{
    "business_info": {{
        "business_type": "ì—…ì¢…",
        "business_name": "ì‚¬ì—…ëª…",
        "location": "ìœ„ì¹˜",
        "scale": "ê·œëª¨"
    }},
    "goals": {{
        "main_goal": "ì£¼ìš” ëª©ì ",
        "target_metrics": "ëª©í‘œ ì§€í‘œ",
        "timeline": "ëª©í‘œ ê¸°í•œ"
    }},
    "target_audience": {{
        "age_group": "ì—°ë ¹ëŒ€",
        "gender": "ì„±ë³„",
        "interests": "ê´€ì‹¬ì‚¬",
        "behavior": "í–‰ë™ íŒ¨í„´"
    }},
    "marketing_info": {{
        "budget": "ì˜ˆì‚°",
        "channels": "ì„ í˜¸ ì±„ë„",
        "experience": "ê²½í—˜ ìˆ˜ì¤€",
        "tools": "ì‚¬ìš© ë„êµ¬"
    }},
    "additional": {{
        "pain_points": "ê³ ë¯¼ ì‚¬í•­",
        "preferences": "ì„ í˜¸ì‚¬í•­",
        "constraints": "ì œì•½ì‚¬í•­"
    }}
}}

ì •ë³´ê°€ ì—†ëŠ” í•­ëª©ì€ nullë¡œ ì„¤ì •í•˜ì„¸ìš”."""

        try:
            messages = [
                SystemMessage(content="ë§ˆì¼€íŒ… ì •ë³´ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì…ë ¥ì—ì„œ ìœ ìš©í•œ ì •ë³´ë§Œ ì •í™•íˆ ì¶”ì¶œí•©ë‹ˆë‹¤."),
                HumanMessage(content=extraction_prompt)
            ]
            
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
            raw_response = llm.invoke(messages)
            response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
            
            # JSON íŒŒì‹±
            if isinstance(response, str):
                cleaned = clean_json_response(response)
                try:
                    extracted_info = json.loads(cleaned)
                    logger.info(f"[ë‹¨ê³„ ë¡œê·¸] - ì¶”ì¶œëœ ì •ë³´: {extracted_info}")
                    
                    # ì¶”ì¶œëœ ì •ë³´ë¥¼ ìƒíƒœì— ì—…ë°ì´íŠ¸
                    for category, info_dict in extracted_info.items():
                        if isinstance(info_dict, dict):
                            for key, value in info_dict.items():
                                if value and value != "null":
                                    state.add_information(f"{category}_{key}", value, "user_input")
                                    
                except json.JSONDecodeError:
                    logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨: {cleaned[:100]}")
                    return
            
        except Exception as e:
            logger.error(f"ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    def get_conversation_status(self, conversation_id: int) -> Dict[str, Any]:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ"""
        if conversation_id in self.conversation_states:
            state = self.conversation_states[conversation_id]
            return {
                "conversation_id": conversation_id,
                "current_stage": state.current_stage.value,
                "overall_completion": state.get_overall_completion_rate(),
                "collected_info_count": len(state.collected_info),
                "detected_business_type": state.detected_business_type,
                "is_paused": getattr(state, 'is_paused', False),
                "is_completed": state.current_stage == MarketingStage.COMPLETED,
                "last_updated": state.updated_at.isoformat(),
                "flexible_mode": True
            }
        else:
            return {"error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

    def reset_conversation(self, conversation_id: int) -> bool:
        """ëŒ€í™” ì´ˆê¸°í™”"""
        if conversation_id in self.conversation_states:
            del self.conversation_states[conversation_id]
            return True
        return False

    def get_agent_status(self) -> Dict[str, Any]:
        """ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ìƒíƒœ ë°˜í™˜"""
        return {
            "agent_type": "llm_based_flexible_marketing",
            "version": "5.0.0",
            "conversation_system": "llm_powered_flexible",
            "features": [
                "ìˆœì„œ ë¬´ê´€ ì¦‰ì‹œ ì‘ë‹µ",
                "ì¤‘ê°„ ë‹¨ê³„ë¶€í„° ì‹œì‘", 
                "ë‹¨ê³„ ê±´ë„ˆë›°ê¸°",
                "LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„",
                "ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°œì¸í™”",
                "ë§ˆì¼€íŒ… íˆ´ ìë™ í™œìš©"
            ],
            "active_conversations": len(self.conversation_states),
            "conversation_stages": {
                conv_id: state.current_stage.value 
                for conv_id, state in self.conversation_states.items()
            },
            "llm_status": self.llm_manager.get_status() if hasattr(self.llm_manager, 'get_status') else "active",
            "vector_store_status": self.vector_manager.get_status() if hasattr(self.vector_manager, 'get_status') else "active",
            "flexible_features": {
                "immediate_response": True,
                "stage_jumping": True,
                "flow_control": True,
                "context_awareness": True,
                "marketing_tools": bool(self.analysis_tools)
            },
            "available_tools": {
                "trend_analysis": {
                    "description": "ë„¤ì´ë²„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¶„ì„",
                    "stage_requirement": "ëª¨ë“  ë‹¨ê³„"
                },
                "hashtag_analysis": {
                    "description": "ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„",
                    "stage_requirement": "ëª¨ë“  ë‹¨ê³„"
                },
                "content_generation": {
                    "description": "ë¸”ë¡œê·¸/SNS ì½˜í…ì¸  ìƒì„±",
                    "stage_requirement": "4ë‹¨ê³„(ì‹¤í–‰ ê³„íš)ë§Œ"
                },
                "keyword_research": {
                    "description": "SEO í‚¤ì›Œë“œ ì—°êµ¬",
                    "stage_requirement": "ëª¨ë“  ë‹¨ê³„"
                }
            },
            "tool_stage_restrictions": {
                "content_generation": "stage_4_execution",
                "reason": "ì½˜í…ì¸  ìƒì„±ì€ ë§ˆì¼€íŒ… ì „ëµì´ ë° íƒ€ê²Ÿì´ ëª…í™•í•´ì§„ í›„ ì‹¤í–‰ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰ë˜ì–´ì•¼ í•¨"
            }
        }


class FlexibleConversationState:
    """ìœ ì—°í•œ ëŒ€í™” ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, conversation_id: int, user_id: int):
        self.conversation_id = conversation_id
        self.user_id = user_id
        self.current_stage = MarketingStage.ANY_QUESTION
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        
        # ìœ ì—°í•œ ì •ë³´ ìˆ˜ì§‘ (ë‹¨ê³„ êµ¬ë¶„ ì—†ì´)
        self.collected_info: Dict[str, Any] = {}
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.conversation_history: List[Dict[str, Any]] = []
        
        # ìƒíƒœ í”Œë˜ê·¸
        self.is_paused = False
        self.detected_business_type = "ì¼ë°˜"
        
        # ì‚¬ìš©ì ì„ í˜¸ë„
        self.user_preferences = {
            "prefers_structured": False,
            "wants_immediate_answers": True,
            "communication_style": "friendly"
        }
    
    def add_information(self, key: str, value: Any, source: str = "user_input"):
        """ì •ë³´ ì¶”ê°€"""
        self.collected_info[key] = {
            "value": value,
            "source": source,
            "timestamp": datetime.now().isoformat(),
            "confidence": 1.0
        }
        self.updated_at = datetime.now()
    
    def get_information(self, key: str) -> Any:
        """ì •ë³´ ì¡°íšŒ"""
        info = self.collected_info.get(key)
        return info["value"] if info else None
    
    def get_overall_completion_rate(self) -> float:
        """ì „ì²´ ì™„ë£Œìœ¨ ê³„ì‚°"""
        # ìˆ˜ì§‘ëœ ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ì™„ë£Œìœ¨ ê³„ì‚°
        essential_info_count = len([
            info for key, info in self.collected_info.items()
            if any(keyword in key.lower() for keyword in [
                "business_type", "main_goal", "target", "budget", "timeline"
            ])
        ])
        
        return min(essential_info_count / 10.0, 1.0)  # 10ê°œ í•„ìˆ˜ ì •ë³´ ê¸°ì¤€
    
    def get_next_stage(self) -> Optional[MarketingStage]:
        """ë‹¤ìŒ ë‹¨ê³„ ë°˜í™˜"""
        stage_order = [
            MarketingStage.STAGE_1_GOAL,
            MarketingStage.STAGE_2_TARGET,
            MarketingStage.STAGE_3_STRATEGY,
            MarketingStage.STAGE_4_EXECUTION
        ]
        
        if self.current_stage in stage_order:
            current_index = stage_order.index(self.current_stage)
            if current_index < len(stage_order) - 1:
                return stage_order[current_index + 1]
        
        return None
    
    def reset_conversation(self):
        """ëŒ€í™” ì´ˆê¸°í™”"""
        self.current_stage = MarketingStage.ANY_QUESTION
        self.collected_info = {}
        self.conversation_history = []
        self.is_paused = False
        self.updated_at = datetime.now()


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_enhanced_marketing_manager = None

def get_enhanced_4stage_marketing_manager() -> Enhanced4StageMarketingManager:
    """ê°œì„ ëœ 4ë‹¨ê³„ ë§ˆì¼€íŒ… ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _enhanced_marketing_manager
    if _enhanced_marketing_manager is None:
        _enhanced_marketing_manager = Enhanced4StageMarketingManager()
    return _enhanced_marketing_manager
