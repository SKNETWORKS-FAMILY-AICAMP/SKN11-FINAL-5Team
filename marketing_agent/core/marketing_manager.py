"""
í†µí•© ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ë§¤ë‹ˆì € - ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ
ì •ë³´ ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ì œì•ˆ â†’ í”¼ë“œë°± â†’ ìˆ˜ì • â†’ ìµœì¢… ê²°ê³¼ í”Œë¡œìš°
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from enum import Enum
import json
from datetime import datetime

# ê³µí†µ ëª¨ë“ˆ ì„í¬íŠ¸
from shared_modules import (
    get_config,
    get_llm_manager,
    get_vector_manager,
    get_or_create_conversation_session,
    create_message,
    get_recent_messages,
    insert_message_raw,
    get_session_context,
    create_success_response,
    create_error_response,
    create_marketing_response,
    get_current_timestamp,
    format_conversation_history,
    load_prompt_from_file,
    PromptTemplate
)

from marketing_agent.config.persona_config import PERSONA_CONFIG
from marketing_agent.config.prompts_config import PROMPT_META
from marketing_agent.utils import get_marketing_analysis_tools

logger = logging.getLogger(__name__)

class ConversationStage(Enum):
    """ëŒ€í™” ë‹¨ê³„ ì •ì˜"""
    INITIAL = "initial"                    # ì´ˆê¸° ì ‘ì´‰
    INFORMATION_GATHERING = "info_gathering"  # ì •ë³´ ìˆ˜ì§‘
    ANALYSIS = "analysis"                  # ë¶„ì„
    PROPOSAL = "proposal"                  # ì œì•ˆ
    FEEDBACK = "feedback"                  # í”¼ë“œë°± ìˆ˜ì§‘
    REFINEMENT = "refinement"              # ìˆ˜ì •
    FINAL_RESULT = "final_result"          # ìµœì¢… ê²°ê³¼
    COMPLETED = "completed"                # ì™„ë£Œ

class ConversationState:
    """ëŒ€í™” ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, conversation_id: int, user_id: int):
        self.conversation_id = conversation_id
        self.user_id = user_id
        self.stage = ConversationStage.INITIAL
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        
        # ìˆ˜ì§‘ëœ ì •ë³´
        self.collected_info = {
            "business_type": None,
            "target_audience": None,
            "product_service": None,
            "current_challenges": None,
            "goals": None,
            "budget": None,
            "timeline": None,
            "platforms": [],
            "industry": None,
            "competitors": [],
            "additional_context": {}
        }
        
        # ë¶„ì„ ê²°ê³¼
        self.analysis_results = {
            "primary_topics": [],
            "intent_analysis": {},
            "mcp_results": {},
            "recommendations": []
        }
        
        # ì œì•ˆ ë° í”¼ë“œë°±
        self.proposals = []
        self.feedback_history = []
        self.refinements = []
        
        # ìµœì¢… ê²°ê³¼
        self.final_strategy = None
        self.action_plan = None
        
        # ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ê¸°ë¡
        self.stage_prompts = {}
        
    def update_stage(self, new_stage: ConversationStage):
        """ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
        self.stage = new_stage
        self.updated_at = datetime.now()
        
    def add_collected_info(self, key: str, value: Any):
        """ìˆ˜ì§‘ëœ ì •ë³´ ì¶”ê°€"""
        self.collected_info[key] = value
        self.updated_at = datetime.now()
        
    def add_feedback(self, feedback: Dict[str, Any]):
        """í”¼ë“œë°± ì¶”ê°€"""
        feedback["timestamp"] = datetime.now()
        self.feedback_history.append(feedback)
        self.updated_at = datetime.now()
        
    def is_information_complete(self) -> bool:
        """ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
        required_fields = ["business_type", "target_audience", "product_service", "goals"]
        return all(self.collected_info.get(field) for field in required_fields)
        
    def get_completion_rate(self) -> float:
        """ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œìœ¨"""
        total_fields = len(self.collected_info)
        completed_fields = len([v for v in self.collected_info.values() if v])
        return completed_fields / total_fields if total_fields > 0 else 0.0

class MarketingAgentManager:
    """í†µí•© ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ê´€ë¦¬ì - ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        """ë§ˆì¼€íŒ… ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        self.config = get_config()
        self.llm_manager = get_llm_manager()
        self.vector_manager = get_vector_manager()
        self.analysis_tools = get_marketing_analysis_tools()
        
        # í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.prompts_dir = Path(__file__).parent.parent / 'prompts'
        
        # ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •
        self.knowledge_collection = 'marketing-knowledge'
        
        # ë§ˆì¼€íŒ… í† í”½ ì •ì˜
        self.marketing_topics = {
            "marketing_fundamentals": "ë§ˆì¼€íŒ… ê¸°ì´ˆ ì´ë¡ ",
            "social_media_marketing": "SNS ì „ë°˜ ì „ëµ",
            "email_marketing": "ì´ë©”ì¼, ë‰´ìŠ¤ë ˆí„°",
            "content_marketing": "ì½˜í…ì¸  ì „ëµ, í¬ë§· ê¸°íš",
            "personal_branding": "í¼ìŠ¤ë„ ë° ë¸Œëœë“œ í¬ì§€ì…”ë‹",
            "digital_advertising": "í˜ì´ë“œ ë¯¸ë””ì–´, ê´‘ê³  ì±„ë„",
            "conversion_optimization": "ì „í™˜ í¼ë„, A/B í…ŒìŠ¤íŠ¸",
            "influencer_marketing": "í˜‘ì—…, ì œíœ´ ë§ˆì¼€íŒ…",
            "marketing_automation": "ìë™í™”, ìº í˜ì¸ ì„¤ì •",
            "viral_marketing": "ë°”ì´ëŸ´, ì…ì†Œë¬¸ ì „ëµ",
            "blog_marketing": "ë¸”ë¡œê·¸ ë§ˆì¼€íŒ…",
            "marketing_metrics": "ROAS, CAC ë“± ì„±ê³¼ ì§€í‘œ",
            "local_marketing": "ì§€ì—­ ê¸°ë°˜ ë§ˆì¼€íŒ…"
        }
        
        # ëŒ€í™” ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self.conversation_states: Dict[int, ConversationState] = {}
        
        # ë‹¨ê³„ë³„ ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸ í…œí”Œë¦¿
        self.info_gathering_questions = {
            "business_type": "ì–´ë–¤ ë¹„ì¦ˆë‹ˆìŠ¤/ì—…ì¢…ì—ì„œ í™œë™í•˜ê³  ê³„ì‹ ê°€ìš”?",
            "target_audience": "ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì¸µì€ ëˆ„êµ¬ì¸ê°€ìš”? (ì—°ë ¹, ì„±ë³„, ê´€ì‹¬ì‚¬ ë“±)",
            "product_service": "êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ì‹œë‚˜ìš”?",
            "current_challenges": "í˜„ì¬ ë§ˆì¼€íŒ…ì—ì„œ ê°€ì¥ í° ì–´ë ¤ì›€ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "goals": "ë‹¬ì„±í•˜ê³  ì‹¶ì€ ë§ˆì¼€íŒ… ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "budget": "ì›” ë§ˆì¼€íŒ… ì˜ˆì‚°ì€ ëŒ€ëµ ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
            "timeline": "ì–¸ì œê¹Œì§€ ê²°ê³¼ë¥¼ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
            "platforms": "í˜„ì¬ í™œìš©í•˜ê³  ìˆê±°ë‚˜ ê´€ì‹¬ìˆëŠ” ë§ˆì¼€íŒ… ì±„ë„ì€?",
            "industry": "ì—…ê³„ íŠ¹ì„±ì´ë‚˜ ê²½ìŸ ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "competitors": "ì£¼ìš” ê²½ìŸì‚¬ë‚˜ ë²¤ì¹˜ë§ˆí‚¹í•˜ëŠ” ë¸Œëœë“œê°€ ìˆë‚˜ìš”?"
        }
        
        # ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì œì™¸)
        self._initialize_real_knowledge_base()
    
    def _initialize_real_knowledge_base(self):
        """ì‹¤ì œ ë§ˆì¼€íŒ… ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì œì™¸)"""
        try:
            # ë²¡í„° ìŠ¤í† ì–´ í™•ì¸
            vectorstore = self.vector_manager.get_vectorstore(
                collection_name=self.knowledge_collection,
                create_if_not_exists=True
            )
            
            if not vectorstore:
                logger.warning("ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨")
                return
            
            # âœ… ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ë°ì´í„°ë§Œ ë¡œë“œ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ì€ ì œì™¸)
            # í–¥í›„ ì‹¤ì œ ë§ˆì¼€íŒ… ì „ë¬¸ ì½˜í…ì¸ , ì‚¬ë¡€, ì´ë¡  ë“±ì„ ì—¬ê¸°ì„œ ë¡œë“œ
            # knowledge_data_dir = Path(__file__).parent.parent / 'knowledge_data'
            # ë˜ëŠ” ì™¸ë¶€ APIì—ì„œ ë§ˆì¼€íŒ… ì§€ì‹ ê°€ì ¸ì˜¤ê¸°
            
            logger.info("âœ… ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì œì™¸)")
            
        except Exception as e:
            logger.error(f"ì „ë¬¸ ì§€ì‹ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_knowledge_area(self, topic: str) -> str:
        """í† í”½ì— ë”°ë¥¸ ì§€ì‹ ì˜ì—­ ë¶„ë¥˜"""
        knowledge_areas = {
            "marketing_fundamentals": "ê¸°ì´ˆ ì´ë¡ ",
            "social_media_marketing": "ë””ì§€í„¸ ë§ˆì¼€íŒ…",
            "email_marketing": "ë””ì§€í„¸ ë§ˆì¼€íŒ…",
            "content_marketing": "ì½˜í…ì¸  ì „ëµ",
            "personal_branding": "ë¸Œëœë”©",
            "digital_advertising": "ê´‘ê³ /ë¯¸ë””ì–´",
            "conversion_optimization": "ë°ì´í„° ë¶„ì„",
            "influencer_marketing": "íŒŒíŠ¸ë„ˆì‹­",
            "marketing_automation": "ê¸°ìˆ /ë„êµ¬",
            "viral_marketing": "ì†Œì…œ/ë°”ì´ëŸ´",
            "blog_marketing": "ì½˜í…ì¸  ì „ëµ",
            "marketing_metrics": "ë°ì´í„° ë¶„ì„",
            "local_marketing": "ì§€ì—­ ë§ˆì¼€íŒ…"
        }
        return knowledge_areas.get(topic, "ì¼ë°˜")
    
    def get_or_create_conversation_state(self, conversation_id: int, user_id: int) -> ConversationState:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ ë˜ëŠ” ìƒì„±"""
        if conversation_id not in self.conversation_states:
            self.conversation_states[conversation_id] = ConversationState(conversation_id, user_id)
        return self.conversation_states[conversation_id]
    
    def load_topic_prompt(self, topic: str) -> str:
        """í† í”½ë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì§ì ‘ ë¡œë“œ"""
        try:
            prompt_file = self.prompts_dir / f"{topic}.md"
            if prompt_file.exists():
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    return f.read()
            else:
                logger.warning(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {topic}")
                return ""
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({topic}): {e}")
            return ""
    
    def _format_topic_prompts(self, topic_prompts: Dict[str, str]) -> str:
        """í† í”½ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        if not topic_prompts:
            return "ê¸°ë³¸ ë§ˆì¼€íŒ… ë¶„ì„ ìˆ˜í–‰"
        
        formatted = []
        for topic, prompt_content in topic_prompts.items():
            topic_name = self.marketing_topics.get(topic, topic)
            formatted.append(f"[{topic_name}]\n{prompt_content}\n")
        
        return "\n".join(formatted)
    
    def classify_marketing_topic_with_llm(self, user_input: str, context: str = "") -> List[str]:
        """LLMì„ í™œìš©í•œ ë§ˆì¼€íŒ… í† í”½ ë¶„ë¥˜"""
        try:
            # í† í”½ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
            topic_classification_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ëœ ë§ˆì¼€íŒ… í† í”½ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… í† í”½:
{chr(10).join([f"- {key}: {value}" for key, value in self.marketing_topics.items()])}

{f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸: {context}" if context else ""}

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ìœ„ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ í† í”½ì„ ìµœëŒ€ 3ê°œê¹Œì§€ ì„ íƒí•˜ì—¬ í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì˜ˆì‹œ: marketing_fundamentals, content_marketing, social_media_marketing

ë‹µë³€:"""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ì ì§ˆë¬¸ì„ ì •í™•í•œ ë§ˆì¼€íŒ… í† í”½ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."},
                {"role": "user", "content": topic_classification_prompt}
            ]
            
            response = self.llm_manager.generate_response_sync(messages)
            
            # ì‘ë‹µì—ì„œ í† í”½ ì¶”ì¶œ
            if response:
                topics = [topic.strip() for topic in response.split(',')]
                # ìœ íš¨í•œ í† í”½ë§Œ í•„í„°ë§
                valid_topics = [topic for topic in topics if topic in self.marketing_topics]
                return valid_topics[:3] if valid_topics else ["marketing_fundamentals"]
            
            return ["marketing_fundamentals"]
            
        except Exception as e:
            logger.error(f"LLM í† í”½ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return ["marketing_fundamentals", "content_marketing"]
    
    def analyze_user_intent_and_stage(self, user_input: str, state: ConversationState) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ë° ëŒ€í™” ë‹¨ê³„ ë¶„ì„"""
        try:
            # í˜„ì¬ ë‹¨ê³„ì™€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë„ ë¶„ì„
            context_info = {
                "current_stage": state.stage.value,
                "collected_info": state.collected_info,
                "completion_rate": state.get_completion_rate()
            }
            
            intent_analysis_prompt = f"""ì‚¬ìš©ìì˜ ë§ˆì¼€íŒ… ìƒë‹´ ì˜ë„ì™€ ëŒ€í™” ì§„í–‰ ë°©í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

í˜„ì¬ ëŒ€í™” ìƒíƒœ:
- ë‹¨ê³„: {state.stage.value}
- ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œìœ¨: {state.get_completion_rate():.1%}
- ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(state.collected_info, ensure_ascii=False, indent=2)}

ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë‹¤ìŒ JSON í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "intent_type": "info_provide|question_ask|feedback_give|refinement_request|completion_request|general_inquiry",
    "confidence": 0.9,
    "extracted_info": {{
        "field_name": "ì¶”ì¶œëœ ì •ë³´ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)"
    }},
    "next_stage_recommendation": "info_gathering|analysis|proposal|feedback|refinement|final_result",
    "requires_mcp_tools": true/false,
    "mcp_tools_needed": ["hashtag_analysis", "trend_analysis", "content_generation"],
    "user_sentiment": "positive|neutral|negative|frustrated",
    "urgency_level": "high|medium|low",
    "suggested_questions": ["ì¶”ê°€ë¡œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ë“¤"]
}}

ë¶„ì„ ê²°ê³¼:"""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ìƒë‹´ ì „ë¬¸ê°€ë¡œì„œ ëŒ€í™” íë¦„ê³¼ ì‚¬ìš©ì ì˜ë„ë¥¼ ì •í™•íˆ ë¶„ì„í•©ë‹ˆë‹¤."},
                {"role": "user", "content": intent_analysis_prompt}
            ]
            
            response = self.llm_manager.generate_response_sync(messages, output_format="json")
            
            # JSON ì‘ë‹µ íŒŒì‹±
            if isinstance(response, dict):
                return response
            elif isinstance(response, str):
                try:
                    return json.loads(response)
                except json.JSONDecodeError:
                    pass
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "intent_type": "general_inquiry",
                "confidence": 0.7,
                "extracted_info": {},
                "next_stage_recommendation": "info_gathering",
                "requires_mcp_tools": False,
                "mcp_tools_needed": [],
                "user_sentiment": "neutral",
                "urgency_level": "medium",
                "suggested_questions": []
            }
            
        except Exception as e:
            logger.error(f"ì˜ë„ ë° ë‹¨ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "intent_type": "general_inquiry",
                "confidence": 0.5,
                "extracted_info": {},
                "next_stage_recommendation": "info_gathering",
                "requires_mcp_tools": False,
                "mcp_tools_needed": [],
                "user_sentiment": "neutral",
                "urgency_level": "medium",
                "suggested_questions": []
            }
    
    async def execute_mcp_analysis(self, intent_analysis: Dict[str, Any], user_input: str, state: ConversationState) -> Dict[str, Any]:
        """MCP ë„êµ¬ ì‹¤í–‰"""
        results = {}
        
        try:
            if not intent_analysis.get("requires_mcp_tools", False):
                return results
            
            mcp_tools = intent_analysis.get("mcp_tools_needed", [])
            
            # í•´ì‹œíƒœê·¸ ë¶„ì„
            if "hashtag_analysis" in mcp_tools:
                logger.info("ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
                keywords = []
                if state.collected_info.get("product_service"):
                    keywords.append(state.collected_info["product_service"])
                if state.collected_info.get("industry"):
                    keywords.append(state.collected_info["industry"])
                
                hashtag_result = await self.analysis_tools.analyze_instagram_hashtags(
                    question=user_input,
                    user_hashtags=keywords
                )
                results["hashtag_analysis"] = hashtag_result
            
            # íŠ¸ë Œë“œ ë¶„ì„
            if "trend_analysis" in mcp_tools:
                logger.info("ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
                keywords = []
                if state.collected_info.get("product_service"):
                    keywords.append(state.collected_info["product_service"])
                if state.collected_info.get("industry"):
                    keywords.append(state.collected_info["industry"])
                
                if keywords:
                    trend_result = await self.analysis_tools.analyze_naver_trends(keywords)
                    results["trend_analysis"] = trend_result
            
            # ì½˜í…ì¸  ìƒì„±
            if "content_generation" in mcp_tools:
                logger.info("ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ ì¤‘...")
                content_result = await self.analysis_tools.generate_instagram_content()
                results["content_generation"] = content_result
            
            return results
            
        except Exception as e:
            logger.error(f"MCP ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def handle_information_gathering(self, user_input: str, state: ConversationState, intent_analysis: Dict[str, Any]) -> str:
        """ì •ë³´ ìˆ˜ì§‘ ë‹¨ê³„ ì²˜ë¦¬"""
        
        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì •ë³´ ì¶”ì¶œ
        extracted_info = intent_analysis.get("extracted_info", {})
        
        # ìˆ˜ì§‘ëœ ì •ë³´ ì—…ë°ì´íŠ¸
        for field, value in extracted_info.items():
            if field in state.collected_info and value:
                state.add_collected_info(field, value)
        
        # ë‹¤ìŒ ì§ˆë¬¸ ê²°ì •
        missing_info = []
        for field, question in self.info_gathering_questions.items():
            if not state.collected_info.get(field):
                missing_info.append((field, question))
        
        # ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ í™•ì¸
        if state.is_information_complete() or len(missing_info) <= 2:
            # ë¶„ì„ ë‹¨ê³„ë¡œ ì „í™˜
            state.update_stage(ConversationStage.ANALYSIS)
            return self._generate_transition_to_analysis_response(state)
        
        # ë‹¤ìŒ ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸
        next_field, next_question = missing_info[0]
        
        collected_summary = []
        for field, value in state.collected_info.items():
            if value:
                collected_summary.append(f"- {self.info_gathering_questions.get(field, field)}: {value}")
        
        response = f"""ê°ì‚¬í•©ë‹ˆë‹¤! ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤:

{chr(10).join(collected_summary) if collected_summary else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

ğŸ’¡ **ë‹¤ìŒ ì§ˆë¬¸**: {next_question}

ë” ì •í™•í•œ ë§ì¶¤ ì „ëµì„ ìœ„í•´ ìœ„ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"""
        
        return response
    
    def _generate_transition_to_analysis_response(self, state: ConversationState) -> str:
        """ë¶„ì„ ë‹¨ê³„ë¡œ ì „í™˜ ì‹œ ì‘ë‹µ ìƒì„±"""
        collected_info_summary = []
        for field, value in state.collected_info.items():
            if value:
                field_name = self.info_gathering_questions.get(field, field)
                collected_info_summary.append(f"- {field_name}: {value}")
        
        return f"""ğŸ¯ **ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!** 

ìˆ˜ì§‘ëœ ì •ë³´:
{chr(10).join(collected_info_summary)}

ì´ì œ ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¬ì¸µ ë¶„ì„**ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. 
ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”... ğŸ“Š"""
    
    def handle_analysis_stage(self, user_input: str, state: ConversationState, mcp_results: Dict[str, Any]) -> str:
        """ë¶„ì„ ë‹¨ê³„ ì²˜ë¦¬"""
        
        try:
            # ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í† í”½ ë¶„ë¥˜
            analysis_context = " ".join([str(v) for v in state.collected_info.values() if v])
            topics = self.classify_marketing_topic_with_llm(analysis_context)
            
            # âœ… í† í”½ë³„ í”„ë¡¬í”„íŠ¸ ì§ì ‘ ë¡œë“œ
            topic_prompts = {}
            for topic in topics:
                prompt_content = self.load_topic_prompt(topic)
                if prompt_content:
                    topic_prompts[topic] = prompt_content
            
            # âœ… ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰ (ë²¡í„°DBì—ì„œ - ë³„ë„ ë°ì´í„°)
            relevant_knowledge = self.get_relevant_knowledge(analysis_context, topics)
            
            # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            analysis_prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ ê´€ì ì—ì„œ ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

ìˆ˜ì§‘ëœ ê³ ê° ì •ë³´:
{json.dumps(state.collected_info, ensure_ascii=False, indent=2)}

ê´€ë ¨ ë§ˆì¼€íŒ… í† í”½: {', '.join(topics)}

í† í”½ë³„ ë¶„ì„ ì§€ì¹¨:
{self._format_topic_prompts(topic_prompts)}

ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ì°¸ê³ :
{chr(10).join(relevant_knowledge) if relevant_knowledge else "ê¸°ë³¸ ë§ˆì¼€íŒ… ì§€ì‹ í™œìš©"}

ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„°:
{json.dumps(mcp_results, ensure_ascii=False, indent=2) if mcp_results else "ì‹¤ì‹œê°„ ë°ì´í„° ì—†ìŒ"}

ìœ„ í† í”½ë³„ ì§€ì¹¨ì— ë”°ë¼ ë‹¤ìŒ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:

1. **í˜„í™© ë¶„ì„**: í˜„ì¬ ìƒí™©ê³¼ ë¬¸ì œì  íŒŒì•…
2. **ê¸°íšŒ ìš”ì†Œ**: í™œìš© ê°€ëŠ¥í•œ ê°•ì ê³¼ ê¸°íšŒ
3. **ìœ„í—˜ ìš”ì†Œ**: ì£¼ì˜í•´ì•¼ í•  ìœ„í˜‘ê³¼ ì•½ì   
4. **ì „ëµ ë°©í–¥**: ì¶”ì²œí•˜ëŠ” ë§ˆì¼€íŒ… ì ‘ê·¼ë²•
5. **ìš°ì„ ìˆœìœ„**: ê°€ì¥ ë¨¼ì € í•´ì•¼ í•  3ê°€ì§€

ì „ë¬¸ì ì´ë©´ì„œë„ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì „ëµ ì „ë¬¸ê°€ë¡œì„œ ì£¼ì–´ì§„ í† í”½ë³„ ì§€ì¹¨ì— ë”°ë¼ ë°ì´í„° ê¸°ë°˜ì˜ ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": analysis_prompt}
            ]
            
            analysis_result = self.llm_manager.generate_response_sync(messages)
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥
            state.analysis_results = {
                "primary_topics": topics,
                "topic_prompts_used": list(topic_prompts.keys()),
                "analysis_content": analysis_result,
                "mcp_results": mcp_results,
                "timestamp": datetime.now()
            }
            
            # ì œì•ˆ ë‹¨ê³„ë¡œ ì „í™˜
            state.update_stage(ConversationStage.PROPOSAL)
            
            return f"""ğŸ” **ì‹¬ì¸µ ë¶„ì„ ì™„ë£Œ**

{analysis_result}

---
ì´ì œ ì´ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ **êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ì „ëµê³¼ ì‹¤í–‰ ê³„íš**ì„ ì œì•ˆí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”! ğŸš€"""
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ë‹¨ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def handle_proposal_stage(self, user_input: str, state: ConversationState) -> str:
        """ì œì•ˆ ë‹¨ê³„ ì²˜ë¦¬ - í† í”½ë³„ í”„ë¡¬í”„íŠ¸ í™œìš©"""
        
        try:
            # ë¶„ì„ì—ì„œ ì‚¬ìš©ëœ í† í”½ë“¤ì˜ í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ë¡œë“œ
            topics = state.analysis_results.get("primary_topics", [])
            topic_prompts = {}
            for topic in topics:
                prompt_content = self.load_topic_prompt(topic)
                if prompt_content:
                    topic_prompts[topic] = prompt_content
            
            # âœ… í† í”½ë³„ ì§€ì¹¨ì´ í¬í•¨ëœ ì œì•ˆ í”„ë¡¬í”„íŠ¸
            proposal_prompt = f"""ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

ê³ ê° ì •ë³´:
{json.dumps(state.collected_info, ensure_ascii=False, indent=2)}

ë¶„ì„ ê²°ê³¼:
{state.analysis_results.get('analysis_content', '')}

í† í”½ë³„ ì œì•ˆ ì§€ì¹¨:
{self._format_topic_prompts(topic_prompts)}

ë‹¤ìŒ í˜•íƒœë¡œ ì œì•ˆì„ êµ¬ì„±í•´ì£¼ì„¸ìš”:

## ğŸ¯ ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµ

### 1ï¸âƒ£ í•µì‹¬ ì „ëµ
- ì „ëµëª…: 
- ëª©í‘œ: 
- ì˜ˆìƒ íš¨ê³¼:

### 2ï¸âƒ£ ì‹¤í–‰ ê³„íš (4ì£¼ ë¡œë“œë§µ)
**1ì£¼ì°¨:**
- [ ] ì•¡ì…˜ 1
- [ ] ì•¡ì…˜ 2

**2ì£¼ì°¨:**
- [ ] ì•¡ì…˜ 1  
- [ ] ì•¡ì…˜ 2

**3-4ì£¼ì°¨:**
- [ ] ì•¡ì…˜ 1
- [ ] ì•¡ì…˜ 2

### 3ï¸âƒ£ ì˜ˆì‚° ë°°ë¶„ ê¶Œì¥ì•ˆ
- ì½˜í…ì¸  ì œì‘: X%
- ê´‘ê³ ë¹„: X%  
- ë„êµ¬/ìë™í™”: X%

### 4ï¸âƒ£ ì„±ê³¼ ì¸¡ì • ì§€í‘œ
- ì£¼ìš” KPI: 
- ì¸¡ì • ë°©ë²•:
- ëª©í‘œì¹˜:

### 5ï¸âƒ£ ë¦¬ìŠ¤í¬ ê´€ë¦¬
- ì˜ˆìƒ ë¦¬ìŠ¤í¬:
- ëŒ€ì‘ ë°©ì•ˆ:

ì´ ì œì•ˆì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”? ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹¤ì „ ë§ˆì¼€íŒ… ì „ëµê°€ë¡œì„œ ì£¼ì–´ì§„ í† í”½ë³„ ì§€ì¹¨ì— ë”°ë¼ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ê³„íšì„ ì œì‹œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": proposal_prompt}
            ]
            
            proposal = self.llm_manager.generate_response_sync(messages)
            
            # ì œì•ˆ ì €ì¥
            proposal_data = {
                "content": proposal,
                "topics_used": topics,
                "timestamp": datetime.now(),
                "version": len(state.proposals) + 1
            }
            state.proposals.append(proposal_data)
            
            # í”¼ë“œë°± ë‹¨ê³„ë¡œ ì „í™˜
            state.update_stage(ConversationStage.FEEDBACK)
            
            return proposal
            
        except Exception as e:
            logger.error(f"ì œì•ˆ ë‹¨ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def handle_feedback_stage(self, user_input: str, state: ConversationState) -> str:
        """í”¼ë“œë°± ë‹¨ê³„ ì²˜ë¦¬"""
        
        # í”¼ë“œë°± ë¶„ì„
        feedback_analysis_prompt = f"""ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì œì•ˆëœ ì „ëµ:
{state.proposals[-1]['content'] if state.proposals else 'ì œì•ˆ ì—†ìŒ'}

ì‚¬ìš©ì í”¼ë“œë°±: "{user_input}"

ë‹¤ìŒ JSON í˜•íƒœë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
{{
    "feedback_type": "positive|negative|neutral|modification_request",
    "satisfaction_level": 0.8,
    "specific_concerns": ["êµ¬ì²´ì ì¸ ìš°ë ¤ì‚¬í•­ë“¤"],
    "modification_requests": ["ìˆ˜ì • ìš”ì²­ì‚¬í•­ë“¤"],
    "approved_elements": ["ìŠ¹ì¸ëœ ìš”ì†Œë“¤"],
    "needs_refinement": true/false,
    "next_action": "refine|finalize|gather_more_info"
}}"""

        try:
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° í”¼ë“œë°± ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": feedback_analysis_prompt}
            ]
            
            feedback_response = self.llm_manager.generate_response_sync(messages, output_format="json")
            
            if isinstance(feedback_response, str):
                feedback_analysis = json.loads(feedback_response)
            else:
                feedback_analysis = feedback_response
                
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ë¶„ì„ ì‹¤íŒ¨: {e}")
            feedback_analysis = {
                "feedback_type": "neutral",
                "satisfaction_level": 0.7,
                "needs_refinement": True,
                "next_action": "refine"
            }
        
        # í”¼ë“œë°± ì €ì¥
        state.add_feedback({
            "user_input": user_input,
            "analysis": feedback_analysis
        })
        
        # ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
        if feedback_analysis.get("next_action") == "finalize":
            state.update_stage(ConversationStage.FINAL_RESULT)
            return "ì™„ë²½í•©ë‹ˆë‹¤! ìµœì¢… ì „ëµ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤..."
        elif feedback_analysis.get("next_action") == "refine":
            state.update_stage(ConversationStage.REFINEMENT)
            return self.handle_refinement_stage(user_input, state, feedback_analysis)
        else:
            return f"""í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤! 

ë¶„ì„ ê²°ê³¼:
- ë§Œì¡±ë„: {feedback_analysis.get('satisfaction_level', 0.7):.1%}
- í”¼ë“œë°± ìœ í˜•: {feedback_analysis.get('feedback_type', 'neutral')}

ë” êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ë©´ ì¢‹ì„ì§€ ì•Œë ¤ì£¼ì„¸ìš”!"""
    
    def handle_refinement_stage(self, user_input: str, state: ConversationState, feedback_analysis: Dict[str, Any]) -> str:
        """ìˆ˜ì • ë‹¨ê³„ ì²˜ë¦¬"""
        
        try:
            # ìˆ˜ì • í”„ë¡¬í”„íŠ¸
            refinement_prompt = f"""ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

ê¸°ì¡´ ì œì•ˆ:
{state.proposals[-1]['content'] if state.proposals else ''}

ì‚¬ìš©ì í”¼ë“œë°± ë¶„ì„:
{json.dumps(feedback_analysis, ensure_ascii=False, indent=2)}

ì‚¬ìš©ì ì˜ê²¬: "{user_input}"

í”¼ë“œë°±ì„ ì ê·¹ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •ëœ ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”. 
ê¸°ì¡´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë˜, ì‚¬ìš©ìê°€ ìš°ë ¤í•œ ë¶€ë¶„ì„ ê°œì„ í•˜ê³  ìš”ì²­ì‚¬í•­ì„ ë°˜ì˜í•´ì£¼ì„¸ìš”."""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° ë§ì¶¤í˜• ì „ëµ ìˆ˜ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": refinement_prompt}
            ]
            
            refined_proposal = self.llm_manager.generate_response_sync(messages)
            
            # ìˆ˜ì •ëœ ì œì•ˆ ì €ì¥
            refinement_data = {
                "content": refined_proposal,
                "original_feedback": user_input,
                "feedback_analysis": feedback_analysis,
                "timestamp": datetime.now(),
                "version": len(state.refinements) + 1
            }
            state.refinements.append(refinement_data)
            
            # ë‹¤ì‹œ í”¼ë“œë°± ë‹¨ê³„ë¡œ
            state.update_stage(ConversationStage.FEEDBACK)
            
            return f"""âœ¨ **ìˆ˜ì •ëœ ì „ëµ ì œì•ˆ**

{refined_proposal}

---
ì´ë²ˆ ìˆ˜ì •ì•ˆì€ ì–´ë– ì‹ ê°€ìš”? ì¶”ê°€ë¡œ ì¡°ì •í•  ë¶€ë¶„ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!"""
            
        except Exception as e:
            logger.error(f"ìˆ˜ì • ë‹¨ê³„ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return "ì „ëµ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def handle_final_result_stage(self, user_input: str, state: ConversationState) -> str:
        """ìµœì¢… ê²°ê³¼ ë‹¨ê³„ ì²˜ë¦¬"""
        
        try:
            # ìµœì¢… ì „ëµ ë¬¸ì„œ ìƒì„±
            final_prompt = f"""ëª¨ë“  í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìµœì¢… ë§ˆì¼€íŒ… ì „ëµ ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ê³ ê° ì •ë³´:
{json.dumps(state.collected_info, ensure_ascii=False, indent=2)}

ìµœì¢… ì œì•ˆ:
{(state.refinements[-1]['content'] if state.refinements else state.proposals[-1]['content']) if (state.refinements or state.proposals) else ''}

í”¼ë“œë°± íˆìŠ¤í† ë¦¬:
{json.dumps([f['analysis'] for f in state.feedback_history], ensure_ascii=False, indent=2)}

ë‹¤ìŒ í˜•íƒœë¡œ ì™„ì„±ëœ ìµœì¢… ë¬¸ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

# ğŸ¯ [ê³ ê°ëª…] ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµ ë¬¸ì„œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”
- ê³ ê°: [ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´]
- ëª©í‘œ: [ì£¼ìš” ëª©í‘œ]
- ê¸°ê°„: [íƒ€ì„ë¼ì¸]
- ì˜ˆì‚°: [ì˜ˆì‚° ì •ë³´]

## ğŸ” í˜„í™© ë¶„ì„
[ë¶„ì„ ìš”ì•½]

## ğŸš€ ì‹¤í–‰ ì „ëµ
[í™•ì •ëœ ì „ëµ]

## ğŸ“… 4ì£¼ ì‹¤í–‰ ë¡œë“œë§µ
[ìƒì„¸ ì‹¤í–‰ ê³„íš]

## ğŸ’° ì˜ˆì‚° ê°€ì´ë“œ
[ì˜ˆì‚° ë°°ë¶„]

## ğŸ“Š ì„±ê³¼ ì¸¡ì •
[KPI ë° ì¸¡ì • ë°©ë²•]

## âš ï¸ ì£¼ì˜ì‚¬í•­ & íŒ
[ì‹¤í–‰ ì‹œ ì£¼ì˜ì ]

## ğŸ”„ ë‹¤ìŒ ë‹¨ê³„
[ì „ëµ ì‹¤í–‰ í›„ í•´ì•¼í•  ì¼ë“¤]

---
**ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!** ğŸ‰
ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì‹¤í–‰ ê³¼ì •ì—ì„œ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ì—°ë½í•´ì£¼ì„¸ìš”."""

            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìµœì¢… ë§ˆì¼€íŒ… ì „ëµ ë¬¸ì„œ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": final_prompt}
            ]
            
            final_document = self.llm_manager.generate_response_sync(messages)
            
            # ìµœì¢… ê²°ê³¼ ì €ì¥
            state.final_strategy = {
                "content": final_document,
                "timestamp": datetime.now(),
                "total_iterations": len(state.refinements) + 1
            }
            
            # ì™„ë£Œ ë‹¨ê³„ë¡œ ì „í™˜
            state.update_stage(ConversationStage.COMPLETED)
            
            return final_document
            
        except Exception as e:
            logger.error(f"ìµœì¢… ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ìµœì¢… ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def get_relevant_knowledge(self, query: str, topics: List[str] = None) -> List[str]:
        """ì‹¤ì œ ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰ (ë²¡í„°DB - í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì œì™¸)"""
        try:
            # âœ… ì‹¤ì œ ì „ë¬¸ ì§€ì‹ë§Œ ê²€ìƒ‰ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ì€ ì œì™¸)
            search_results = self.vector_manager.search_documents(
                query=query,
                collection_name=self.knowledge_collection,
                k=5
            )
            
            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì€ í•„í„°ë§ ì œì™¸
            filtered_results = []
            for doc in search_results:
                # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì•„ë‹Œ ì‹¤ì œ ì§€ì‹ ì½˜í…ì¸ ë§Œ
                if doc.metadata.get('type') != 'prompt_template':
                    filtered_results.append(doc)
            
            # ì „ë¬¸ ì§€ì‹ ë‚´ìš© ì¶”ì¶œ
            knowledge_texts = []
            for doc in filtered_results[:3]:
                knowledge_area = doc.metadata.get('knowledge_area', 'ì¼ë°˜')
                content = doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content
                knowledge_texts.append(f"[{knowledge_area}]\n{content}")
            
            return knowledge_texts
            
        except Exception as e:
            logger.error(f"ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def process_user_query(
        self, 
        user_input: str, 
        user_id: int, 
        conversation_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ - ë©€í‹°í„´ ëŒ€í™” í”Œë¡œìš° ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
        
        try:
            logger.info(f"ë©€í‹°í„´ ë§ˆì¼€íŒ… ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: {user_input[:50]}...")
            
            # ëŒ€í™” ì„¸ì…˜ ì²˜ë¦¬
            session_info = get_or_create_conversation_session(user_id, conversation_id)
            conversation_id = session_info["conversation_id"]
            
            # ëŒ€í™” ìƒíƒœ ì¡°íšŒ/ìƒì„±
            state = self.get_or_create_conversation_state(conversation_id, user_id)
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            with get_session_context() as db:
                create_message(db, conversation_id, "user", "marketing", user_input)
            
            # ì˜ë„ ë° ë‹¨ê³„ ë¶„ì„
            intent_analysis = self.analyze_user_intent_and_stage(user_input, state)
            
            # MCP ë„êµ¬ ì‹¤í–‰ (í•„ìš”í•œ ê²½ìš°)
            mcp_results = {}
            if intent_analysis.get("requires_mcp_tools", False):
                logger.info("MCP ë¶„ì„ ë„êµ¬ ì‹¤í–‰ ì¤‘...")
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        import concurrent.futures
                        with concurrent.futures.ThreadPoolExecutor() as executor:
                            future = executor.submit(
                                lambda: asyncio.run(self.execute_mcp_analysis(intent_analysis, user_input, state))
                            )
                            mcp_results = future.result(timeout=30)
                    else:
                        mcp_results = loop.run_until_complete(self.execute_mcp_analysis(intent_analysis, user_input, state))
                except Exception as e:
                    logger.warning(f"MCP ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    mcp_results = {}
            
            # í˜„ì¬ ë‹¨ê³„ì— ë”°ë¥¸ ì²˜ë¦¬
            if state.stage == ConversationStage.INITIAL:
                # ì´ˆê¸° ì ‘ì´‰ ì‹œ ì •ë³´ ìˆ˜ì§‘ ë‹¨ê³„ë¡œ ì „í™˜
                state.update_stage(ConversationStage.INFORMATION_GATHERING)
                response_content = f"""ì•ˆë…•í•˜ì„¸ìš”! ì†”ë¡œí”„ë¦¬ë„ˆì„ ìœ„í•œ ë§ˆì¼€íŒ… ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ğŸš€

ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ì œê³µí•˜ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ì§ˆë¬¸ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì²« ë²ˆì§¸ ì§ˆë¬¸**: {list(self.info_gathering_questions.values())[0]}

ì •í™•í•œ ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•´ ì°¨ê·¼ì°¨ê·¼ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤!"""
                
            elif state.stage == ConversationStage.INFORMATION_GATHERING:
                response_content = self.handle_information_gathering(user_input, state, intent_analysis)
                
            elif state.stage == ConversationStage.ANALYSIS:
                response_content = self.handle_analysis_stage(user_input, state, mcp_results)
                
            elif state.stage == ConversationStage.PROPOSAL:
                response_content = self.handle_proposal_stage(user_input, state)
                
            elif state.stage == ConversationStage.FEEDBACK:
                response_content = self.handle_feedback_stage(user_input, state)
                
            elif state.stage == ConversationStage.REFINEMENT:
                # ì´ë¯¸ handle_feedback_stageì—ì„œ ì²˜ë¦¬ë¨
                response_content = "ìˆ˜ì • ì¤‘ì…ë‹ˆë‹¤..."
                
            elif state.stage == ConversationStage.FINAL_RESULT:
                response_content = self.handle_final_result_stage(user_input, state)
                
            elif state.stage == ConversationStage.COMPLETED:
                response_content = f"""ì „ëµ ìˆ˜ë¦½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰

ìƒˆë¡œìš´ ë§ˆì¼€íŒ… ìƒë‹´ì„ ì›í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”.
í˜¹ì€ ê¸°ì¡´ ì „ëµì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ë„ í™˜ì˜í•©ë‹ˆë‹¤!

í˜„ì¬ ì™„ë£Œëœ ì „ëµ:
- ì´ {len(state.proposals) + len(state.refinements)}ë²ˆì˜ ì œì•ˆ/ìˆ˜ì •
- {len(state.feedback_history)}ë²ˆì˜ í”¼ë“œë°± ë°˜ì˜
- ìµœì¢… ì™„ë£Œì¼: {state.final_strategy['timestamp'].strftime('%Y-%m-%d %H:%M')}"""
            
            else:
                response_content = "ëŒ€í™” íë¦„ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
            
            # ì‘ë‹µ ë©”ì‹œì§€ ì €ì¥
            insert_message_raw(
                conversation_id=conversation_id,
                sender_type="agent",
                agent_type="marketing",
                content=response_content
            )
            
            # í‘œì¤€ ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            return create_marketing_response(
                conversation_id=conversation_id,
                answer=response_content,
                topics=getattr(state.analysis_results, 'primary_topics', []),
                sources=f"ë©€í‹°í„´ ëŒ€í™” ì‹œìŠ¤í…œ (ë‹¨ê³„: {state.stage.value})",
                intent=intent_analysis.get("intent_type"),
                confidence=intent_analysis.get("confidence"),
                conversation_stage=state.stage.value,
                completion_rate=state.get_completion_rate(),
                collected_info=state.collected_info,
                mcp_results=mcp_results,
                multiturn_flow=True
            )
            
        except Exception as e:
            logger.error(f"ë©€í‹°í„´ ë§ˆì¼€íŒ… ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return create_error_response(
                error_message=f"ë§ˆì¼€íŒ… ìƒë‹´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                error_code="MULTITURN_MARKETING_ERROR"
            )
    
    def get_conversation_status(self, conversation_id: int) -> Dict[str, Any]:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ"""
        if conversation_id in self.conversation_states:
            state = self.conversation_states[conversation_id]
            return {
                "conversation_id": conversation_id,
                "stage": state.stage.value,
                "completion_rate": state.get_completion_rate(),
                "collected_info": state.collected_info,
                "total_proposals": len(state.proposals),
                "total_refinements": len(state.refinements),
                "total_feedback": len(state.feedback_history),
                "is_completed": state.stage == ConversationStage.COMPLETED,
                "last_updated": state.updated_at.isoformat()
            }
        else:
            return {"error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    
    def reset_conversation(self, conversation_id: int) -> bool:
        """ëŒ€í™” ì´ˆê¸°í™”"""
        if conversation_id in self.conversation_states:
            del self.conversation_states[conversation_id]
            return True
        return False
    
    def get_agent_status(self) -> Dict[str, Any]:
        """ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ ìƒíƒœ ë°˜í™˜"""
        return {
            "agent_type": "marketing",
            "version": "3.0.0",
            "conversation_system": "multiturn",
            "stages": [stage.value for stage in ConversationStage],
            "active_conversations": len(self.conversation_states),
            "conversation_stages": {
                conv_id: state.stage.value 
                for conv_id, state in self.conversation_states.items()
            },
            "llm_status": self.llm_manager.get_status(),
            "vector_store_status": self.vector_manager.get_status(),
            "mcp_tools_available": ["hashtag_analysis", "trend_analysis", "content_generation"]
        }
