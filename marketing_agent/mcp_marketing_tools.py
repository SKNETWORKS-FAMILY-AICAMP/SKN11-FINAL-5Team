"""
MCP ë§ˆì¼€íŒ… ë„êµ¬ - ê°œì„ ëœ ë²„ì „
âœ… ì»¨í…ìŠ¤íŠ¸ í™œìš© ê°•í™”, ì‹¤í–‰ë ¥ ì¤‘ì‹¬, ë§ì¶¤í™” ê°œì„ , ê²°ê³¼ ìµœì í™”
"""

import asyncio
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import openai
from config import config

# MCP ê´€ë ¨ ì•ˆì „í•œ ì„í¬íŠ¸
try:
    from shared_modules import get_llm_manager
    from shared_modules.mcp_client import MCPClientManager
except ImportError as e:
    logger = logging.getLogger(__name__)
    logger.warning(f"MCP ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    
    def get_llm_manager():
        return None
    
    class MCPClientManager:
        def __init__(self):
            pass
        
        async def call_tool(self, tool_name: str, **kwargs):
            return {"success": False, "error": "MCP í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ë¶ˆê°€"}

logger = logging.getLogger(__name__)

class MarketingAnalysisTools:
    """ğŸ†• ê°œì„ ëœ MCP ë§ˆì¼€íŒ… ë¶„ì„ ë„êµ¬ - ì»¨í…ìŠ¤íŠ¸ í™œìš© ë° ê²°ê³¼ ìµœì í™”"""
    
    def __init__(self):
        self.client = openai.OpenAI(api_key=config.OPENAI_API_KEY)
        self.mcp_client = MCPClientManager()
        self.llm_manager = get_llm_manager()
        self.logger = logging.getLogger(__name__)
        
        # ğŸ†• ë¶„ì„ ê²°ê³¼ í–¥ìƒì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ê°œì„ 
        self._init_analysis_prompts()
        
        # ğŸ†• ì—…ì¢…ë³„ ë¶„ì„ íŠ¹í™” ì„¤ì •
        self._init_industry_analysis_configs()
    
    def _init_analysis_prompts(self):
        """ğŸ†• ë¶„ì„ ì „ìš© í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”"""
        
        # ğŸ†• íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ í•´ì„ í”„ë¡¬í”„íŠ¸
        self.trend_analysis_prompt = """ë‹¤ìŒ ë„¤ì´ë²„ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

### íŠ¸ë Œë“œ ë°ì´í„°
{trend_data}

### ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸
- ì—…ì¢…: {business_type}
- ì œí’ˆ/ì„œë¹„ìŠ¤: {product}
- íƒ€ê²Ÿ ê³ ê°: {target_audience}
- ë§ˆì¼€íŒ… ëª©í‘œ: {main_goal}

### ë¶„ì„ ìš”êµ¬ì‚¬í•­
1. **íŠ¸ë Œë“œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸**: ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ëŠ” ì£¼ìš” íŒ¨í„´ê³¼ ë³€í™”
2. **ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ**: í•´ë‹¹ ì—…ì¢…ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ê¸°íšŒ
3. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ**: íŠ¸ë Œë“œë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ… ë°©ë²•
4. **íƒ€ì´ë° ì „ëµ**: ì–¸ì œ, ì–´ë–»ê²Œ í™œìš©í• ì§€ êµ¬ì²´ì  ê³„íš
5. **ê²½ìŸ ìš°ìœ„**: íŠ¸ë Œë“œë¥¼ í†µí•´ ì–»ì„ ìˆ˜ ìˆëŠ” ì°¨ë³„í™” í¬ì¸íŠ¸

### ì¶œë ¥ í˜•ì‹
**ğŸ“Š íŠ¸ë Œë“œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸**
[ì£¼ìš” ë°œê²¬ì‚¬í•­ 3ê°œ, ê°ê° í•œ ì¤„ë¡œ ìš”ì•½]

**ğŸ’¡ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒ**
[ì—…ì¢… íŠ¹ì„±ì„ ë°˜ì˜í•œ êµ¬ì²´ì  ê¸°íšŒ 3ê°œ]

**ğŸ¯ ì‹¤í–‰ ì „ëµ**
1. **ì¦‰ì‹œ ì‹¤í–‰**: [ë°”ë¡œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ë°©ë²•]
2. **ë‹¨ê¸° ì „ëµ** (1-2ì£¼): [íŠ¸ë Œë“œ í™œìš© ë°©ë²•]
3. **ì¤‘ê¸° ì „ëµ** (1-2ê°œì›”): [ì§€ì†ì  í™œìš© ê³„íš]

**â° ìµœì  íƒ€ì´ë°**
[ì–¸ì œ, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í™œìš©í• ì§€ êµ¬ì²´ì  ê°€ì´ë“œ]

**ğŸ† ê²½ìŸ ìš°ìœ„ í™•ë³´**
[ì´ íŠ¸ë Œë“œë¡œ ì°¨ë³„í™”í•  ìˆ˜ ìˆëŠ” ë°©ë²•]

**ğŸ“ˆ ì„±ê³¼ ì˜ˆì¸¡**
[ì˜ˆìƒë˜ëŠ” ë§ˆì¼€íŒ… íš¨ê³¼ ë° ì§€í‘œ]

ì—…ì¢… íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        # ğŸ†• í•´ì‹œíƒœê·¸ ë¶„ì„ ê²°ê³¼ í•´ì„ í”„ë¡¬í”„íŠ¸
        self.hashtag_analysis_prompt = """ë‹¤ìŒ ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íš¨ê³¼ì ì¸ SNS ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•´ì£¼ì„¸ìš”.

### í•´ì‹œíƒœê·¸ ë¶„ì„ ë°ì´í„°
{hashtag_data}

### ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸
- ì—…ì¢…: {business_type}
- ì œí’ˆ/ì„œë¹„ìŠ¤: {product}
- íƒ€ê²Ÿ ê³ ê°: {target_audience}
- í˜„ì¬ ì‚¬ìš© í•´ì‹œíƒœê·¸: {current_hashtags}

### ë¶„ì„ ëª©í‘œ
1. **í•´ì‹œíƒœê·¸ ì„±ê³¼ ë¶„ì„**: í˜„ì¬ í•´ì‹œíƒœê·¸ì˜ íš¨ê³¼ì„± í‰ê°€
2. **ìµœì  í•´ì‹œíƒœê·¸ ì¡°í•©**: ë„ë‹¬ë¥ ê³¼ ì°¸ì—¬ë„ë¥¼ ë†’ì´ëŠ” ì¡°í•©
3. **ì—…ì¢…ë³„ íŠ¹í™” ì „ëµ**: í•´ë‹¹ ë¶„ì•¼ì— íŠ¹í™”ëœ í•´ì‹œíƒœê·¸ í™œìš©ë²•
4. **íŠ¸ë Œë“œ ë°˜ì˜**: ìµœì‹  íŠ¸ë Œë“œ í•´ì‹œíƒœê·¸ ì ìš© ë°©ì•ˆ
5. **ì„±ì¥ ì „ëµ**: íŒ”ë¡œì›Œì™€ ì¸ê²Œì´ì§€ë¨¼íŠ¸ ì¦ëŒ€ ë°©ë²•

### ì¶œë ¥ í˜•ì‹
**ğŸ” í˜„ì¬ í•´ì‹œíƒœê·¸ ë¶„ì„**
[ì‚¬ìš© ì¤‘ì¸ í•´ì‹œíƒœê·¸ì˜ íš¨ê³¼ì„±ê³¼ ê°œì„ ì ]

**âœ¨ ì¶”ì²œ í•´ì‹œíƒœê·¸ ì¡°í•©**
**ìƒì‹œ ì‚¬ìš©** (ë¸Œëœë“œ/ì—…ì¢…): #íƒœê·¸1 #íƒœê·¸2 #íƒœê·¸3 #íƒœê·¸4 #íƒœê·¸5
**íŠ¸ë Œë“œ í™œìš©** (ì‹œì¦Œ/ì´ìŠˆ): #íƒœê·¸6 #íƒœê·¸7 #íƒœê·¸8 #íƒœê·¸9 #íƒœê·¸10
**íƒ€ê²Ÿ íŠ¹í™”** (ê³ ê°ì¸µ): #íƒœê·¸11 #íƒœê·¸12 #íƒœê·¸13 #íƒœê·¸14 #íƒœê·¸15
**ì§€ì—­/ì»¤ë®¤ë‹ˆí‹°**: #íƒœê·¸16 #íƒœê·¸17 #íƒœê·¸18 #íƒœê·¸19 #íƒœê·¸20

**ğŸ“‹ í•´ì‹œíƒœê·¸ ì „ëµ**
1. **ë„ë‹¬ë¥  ê·¹ëŒ€í™”**: [ë„“ì€ ë…¸ì¶œì„ ìœ„í•œ ì¸ê¸° í•´ì‹œíƒœê·¸]
2. **íƒ€ê²Ÿ ì •í™•ë„**: [ì •í™•í•œ íƒ€ê²ŸíŒ…ì„ ìœ„í•œ ë‹ˆì¹˜ í•´ì‹œíƒœê·¸]
3. **ì°¸ì—¬ë„ í–¥ìƒ**: [ì¸ê²Œì´ì§€ë¨¼íŠ¸ë¥¼ ë†’ì´ëŠ” í•´ì‹œíƒœê·¸]

**ğŸ“… í™œìš© ì¼ì •**
- **ì›”ìš”ì¼**: [í•´ì‹œíƒœê·¸ ì¡°í•© A + ì‚¬ìš© ì´ìœ ]
- **ìˆ˜ìš”ì¼**: [í•´ì‹œíƒœê·¸ ì¡°í•© B + ì‚¬ìš© ì´ìœ ]
- **ê¸ˆìš”ì¼**: [í•´ì‹œíƒœê·¸ ì¡°í•© C + ì‚¬ìš© ì´ìœ ]

**ğŸ“Š ì„±ê³¼ ì¸¡ì •**
[ì¶”ì í•´ì•¼ í•  ì§€í‘œì™€ ê°œì„  ë°©í–¥]

**ğŸ’¡ ì¶”ê°€ íŒ**
[í•´ì‹œíƒœê·¸ ì™¸ SNS ì„±ì¥ì„ ìœ„í•œ ì‹¤ìš©ì  ì¡°ì–¸]

ì—…ì¢… íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ê³ ê°ì— ë§ëŠ” ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ í•´ì‹œíƒœê·¸ ì „ëµì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        # ğŸ†• í‚¤ì›Œë“œ ë¦¬ì„œì¹˜ ì¢…í•© ë¶„ì„ í”„ë¡¬í”„íŠ¸
        self.keyword_research_prompt = """ë‹¤ìŒ í‚¤ì›Œë“œ ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… í™œìš© ì „ëµì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.

### í‚¤ì›Œë“œ ë°ì´í„°
- íƒ€ê²Ÿ í‚¤ì›Œë“œ: {target_keywords}
- íŠ¸ë Œë“œ ë°ì´í„°: {trend_data}
- ê´€ë ¨ í‚¤ì›Œë“œ: {related_keywords}

### ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´
- ì—…ì¢…: {business_type}
- ì œí’ˆ/ì„œë¹„ìŠ¤: {product}
- ë§ˆì¼€íŒ… ëª©í‘œ: {main_goal}
- íƒ€ê²Ÿ ê³ ê°: {target_audience}

### í‚¤ì›Œë“œ ì „ëµ ìˆ˜ë¦½ ìš”êµ¬ì‚¬í•­
1. **ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ**: íš¨ê³¼ì™€ ê²½ìŸë„ë¥¼ ê³ ë ¤í•œ í•µì‹¬ í‚¤ì›Œë“œ
2. **ì½˜í…ì¸  ì „ëµ**: í‚¤ì›Œë“œ ê¸°ë°˜ ì½˜í…ì¸  ê¸°íš
3. **SEO ìµœì í™”**: ê²€ìƒ‰ ë…¸ì¶œ í–¥ìƒ ë°©ì•ˆ
4. **ê´‘ê³  í™œìš©**: ìœ ë£Œ ê´‘ê³ ì—ì„œì˜ í‚¤ì›Œë“œ í™œìš©
5. **ì¥ê¸° ì „ëµ**: ì§€ì† ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ë§ˆì¼€íŒ…

### ì¶œë ¥ í˜•ì‹
**ğŸ¯ í•µì‹¬ í‚¤ì›Œë“œ ì „ëµ**
**1ìˆœìœ„** (ì¦‰ì‹œ ì§‘ì¤‘): [í‚¤ì›Œë“œ 3ê°œ + ì„ ì • ì´ìœ ]
**2ìˆœìœ„** (ë‹¨ê¸° ëª©í‘œ): [í‚¤ì›Œë“œ 4ê°œ + í™œìš© ë°©ë²•]  
**3ìˆœìœ„** (ì¥ê¸° ì „ëµ): [í‚¤ì›Œë“œ 3ê°œ + ì„±ì¥ ê³„íš]

**ğŸ“ ì½˜í…ì¸  ê¸°íš**
- **ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸**: [í‚¤ì›Œë“œ ê¸°ë°˜ ì£¼ì œ 5ê°œ]
- **SNS ì½˜í…ì¸ **: [í‚¤ì›Œë“œ í™œìš© í¬ìŠ¤íŠ¸ ì•„ì´ë””ì–´ 3ê°œ]
- **ì˜ìƒ ì½˜í…ì¸ **: [í‚¤ì›Œë“œ ë°˜ì˜ ì˜ìƒ ê¸°íš 2ê°œ]

**ğŸ” SEO ìµœì í™” ê³„íš**
1. **ì˜¨í˜ì´ì§€ SEO**: [ì›¹ì‚¬ì´íŠ¸ ë‚´ í‚¤ì›Œë“œ ìµœì í™” ë°©ë²•]
2. **ì½˜í…ì¸  SEO**: [ê²€ìƒ‰ ì¹œí™”ì  ì½˜í…ì¸  ì‘ì„±ë²•]
3. **ê¸°ìˆ ì  SEO**: [êµ¬ì¡°ì  ê°œì„ ì‚¬í•­]

**ğŸ’° ê´‘ê³  í‚¤ì›Œë“œ ì „ëµ**
- **ê²€ìƒ‰ ê´‘ê³ **: [Google/ë„¤ì´ë²„ ê²€ìƒ‰ ê´‘ê³ ìš© í‚¤ì›Œë“œ]
- **ë””ìŠ¤í”Œë ˆì´**: [ë°°ë„ˆ ê´‘ê³  íƒ€ê²ŸíŒ… í‚¤ì›Œë“œ]
- **ì†Œì…œ ê´‘ê³ **: [SNS ê´‘ê³  ê´€ì‹¬ì‚¬ í‚¤ì›Œë“œ]

**ğŸ“ˆ ì„±ê³¼ ì¸¡ì • ë° ìµœì í™”**
[í‚¤ì›Œë“œë³„ ì„±ê³¼ ì§€í‘œì™€ ê°œì„  ë°©ë²•]

**ğŸ—“ï¸ 3ê°œì›” ì‹¤í–‰ ë¡œë“œë§µ**
**1ê°œì›”ì°¨**: [ì´ˆê¸° ì§‘ì¤‘ í‚¤ì›Œë“œì™€ ê¸°ë°˜ êµ¬ì¶•]
**2ê°œì›”ì°¨**: [í™•ì¥ í‚¤ì›Œë“œì™€ ì½˜í…ì¸  ë‹¤ì–‘í™”]
**3ê°œì›”ì°¨**: [ìµœì í™” ë° ìƒˆë¡œìš´ ê¸°íšŒ íƒìƒ‰]

ì—…ì¢… íŠ¹ì„±ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë§ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ë§ˆì¼€íŒ… ì „ëµì„ ì œê³µí•´ì£¼ì„¸ìš”."""
    
    def _init_industry_analysis_configs(self):
        """ğŸ†• ì—…ì¢…ë³„ ë¶„ì„ íŠ¹í™” ì„¤ì •"""
        self.industry_analysis_configs = {
            "ë·°í‹°": {
                "trend_focus": ["ê³„ì ˆ íŠ¸ë Œë“œ", "ì„±ë¶„ íŠ¸ë Œë“œ", "ë·°í‹° ê¸°ë²•", "ì…€ëŸ½ ìŠ¤íƒ€ì¼"],
                "hashtag_categories": ["ë·°í‹°íŒ", "ì œí’ˆë¦¬ë·°", "ë©”ì´í¬ì—…", "ìŠ¤í‚¨ì¼€ì–´", "íŠ¸ë Œë“œ"],
                "keyword_priorities": ["íš¨ê³¼", "ì„±ë¶„", "í›„ê¸°", "ì¶”ì²œ", "íŠ¸ë Œë“œ"],
                "analysis_angle": "ë·°í‹° íŠ¸ë Œë“œì™€ ì†Œë¹„ì ë‹ˆì¦ˆ ë³€í™”"
            },
            "ìŒì‹ì ": {
                "trend_focus": ["ê³„ì ˆ ë©”ë‰´", "ìŒì‹ íŠ¸ë Œë“œ", "ê±´ê°•ì‹", "ì§€ì—­ íŠ¹ì‚°ë¬¼"],
                "hashtag_categories": ["ë§›ì§‘", "ìŒì‹ìŠ¤íƒ€ê·¸ë¨", "ì§€ì—­íƒœê·¸", "ë¶„ìœ„ê¸°", "ë©”ë‰´"],
                "keyword_priorities": ["ë§›ì§‘", "ì§€ì—­ëª…", "ìŒì‹ëª…", "ë¶„ìœ„ê¸°", "ê°€ê²©ëŒ€"],
                "analysis_angle": "ì™¸ì‹ íŠ¸ë Œë“œì™€ ì§€ì—­ íŠ¹ì„±"
            },
            "ì˜¨ë¼ì¸ì‡¼í•‘ëª°": {
                "trend_focus": ["ì‡¼í•‘ íŠ¸ë Œë“œ", "ìƒí’ˆ ì¹´í…Œê³ ë¦¬", "ê°€ê²© ë¯¼ê°ë„", "ë°°ì†¡ ì„œë¹„ìŠ¤"],
                "hashtag_categories": ["ì‡¼í•‘", "í• ì¸", "ì‹ ìƒ", "í›„ê¸°", "ì¶”ì²œ"],
                "keyword_priorities": ["ì‡¼í•‘", "í• ì¸", "í›„ê¸°", "ë°°ì†¡", "í’ˆì§ˆ"],
                "analysis_angle": "ì´ì»¤ë¨¸ìŠ¤ íŠ¸ë Œë“œì™€ ì†Œë¹„ íŒ¨í„´"
            },
            "ì„œë¹„ìŠ¤ì—…": {
                "trend_focus": ["ì„œë¹„ìŠ¤ í˜ì‹ ", "ê³ ê° ë§Œì¡±", "ì „ë¬¸ì„±", "íš¨ìœ¨ì„±"],
                "hashtag_categories": ["ì„œë¹„ìŠ¤", "ì „ë¬¸ê°€", "ì†”ë£¨ì…˜", "ê³ ê°ë§Œì¡±", "ì‹ ë¢°"],
                "keyword_priorities": ["ì„œë¹„ìŠ¤", "ì „ë¬¸", "ì†”ë£¨ì…˜", "ì‹ ë¢°", "íš¨ê³¼"],
                "analysis_angle": "ì„œë¹„ìŠ¤ í’ˆì§ˆê³¼ ê³ ê° ê¸°ëŒ€ì¹˜"
            }
        }
    
    # ============================================
    # ğŸ†• ê°œì„ ëœ ë¶„ì„ ë„êµ¬ ë©”ì„œë“œë“¤
    # ============================================
    
    async def analyze_naver_trends(self, keywords: List[str], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ğŸ†• ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¶„ì„ - ì»¨í…ìŠ¤íŠ¸ í™œìš© ê°•í™”"""
        try:
            # MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•œ íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘
            trend_result = await self.mcp_client.call_tool(
                "naver_trends",
                keywords=keywords,
                period="3month"  # ìµœê·¼ 3ê°œì›” ë°ì´í„°
            )
            
            if not trend_result.get("success"):
                return await self._generate_fallback_trend_analysis(keywords, context)
            
            # ğŸ†• ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ ìˆ˜í–‰
            analysis_result = await self._analyze_trends_with_context(
                trend_result.get("data", {}), 
                keywords, 
                context or {}
            )
            
            return {
                "success": True,
                "type": "trend_analysis",
                "keywords": keywords,
                "raw_data": trend_result.get("data", {}),
                "business_analysis": analysis_result,
                "recommendations": await self._generate_trend_recommendations(analysis_result, context),
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return await self._generate_fallback_trend_analysis(keywords, context)
    
    async def analyze_instagram_hashtags(self, question: str, user_hashtags: List[str], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ğŸ†• ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ - ì—…ì¢…ë³„ ìµœì í™”"""
        try:
            # MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•œ í•´ì‹œíƒœê·¸ ë°ì´í„° ìˆ˜ì§‘
            hashtag_result = await self.mcp_client.call_tool(
                "instagram_hashtag_analysis",
                hashtags=user_hashtags,
                analysis_type="comprehensive"
            )
            
            if not hashtag_result.get("success"):
                return await self._generate_fallback_hashtag_analysis(user_hashtags, context)
            
            # ğŸ†• ì—…ì¢…ë³„ íŠ¹í™” í•´ì‹œíƒœê·¸ ë¶„ì„
            analysis_result = await self._analyze_hashtags_with_context(
                hashtag_result.get("data", {}),
                user_hashtags,
                context or {}
            )
            
            return {
                "success": True,
                "type": "hashtag_analysis",
                "question": question,
                "analyzed_hashtags": user_hashtags,
                "raw_data": hashtag_result.get("data", {}),
                "business_analysis": analysis_result,
                "optimized_hashtags": await self._generate_optimized_hashtags(analysis_result, context),
                "strategy": await self._generate_hashtag_strategy(analysis_result, context),
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì¸ìŠ¤íƒ€ê·¸ë¨ í•´ì‹œíƒœê·¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return await self._generate_fallback_hashtag_analysis(user_hashtags, context)
    
    async def create_blog_content_workflow(self, target_keyword: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ğŸ†• ë¸”ë¡œê·¸ ì½˜í…ì¸  ì›Œí¬í”Œë¡œìš° - í‚¤ì›Œë“œ ìµœì í™”"""
        try:
            # ğŸ†• í‚¤ì›Œë“œ ë¶„ì„ê³¼ ë¸”ë¡œê·¸ ì½˜í…ì¸  í†µí•© ìƒì„±
            keyword_analysis = await self.analyze_keyword_comprehensive([target_keyword], context)
            
            if not keyword_analysis.get("success"):
                return await self._generate_basic_blog_workflow(target_keyword, context)
            
            # ğŸ†• SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ ì½˜í…ì¸  ì›Œí¬í”Œë¡œìš° ìƒì„±
            workflow_result = await self._create_blog_workflow_with_seo(
                target_keyword, 
                keyword_analysis.get("analysis", {}),
                context or {}
            )
            
            return {
                "success": True,
                "type": "blog_workflow",
                "target_keyword": target_keyword,
                "keyword_analysis": keyword_analysis.get("analysis", {}),
                "content_workflow": workflow_result,
                "seo_optimization": await self._generate_seo_recommendations(target_keyword, context),
                "created_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ë¸”ë¡œê·¸ ì½˜í…ì¸  ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
            return await self._generate_basic_blog_workflow(target_keyword, context)
    
    async def create_instagram_content_workflow(self, target_keyword: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ğŸ†• ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ì›Œí¬í”Œë¡œìš° - ë¹„ì£¼ì–¼ ìµœì í™”"""
        try:
            # ğŸ†• í‚¤ì›Œë“œ ê¸°ë°˜ í•´ì‹œíƒœê·¸ ë¶„ì„
            hashtag_analysis = await self.analyze_instagram_hashtags(
                f"{target_keyword} ê´€ë ¨ ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸ ",
                [target_keyword],
                context
            )
            
            # ğŸ†• ë¹„ì£¼ì–¼ ì¤‘ì‹¬ì˜ ì¸ìŠ¤íƒ€ê·¸ë¨ ì›Œí¬í”Œë¡œìš° ìƒì„±
            workflow_result = await self._create_instagram_workflow_with_visuals(
                target_keyword,
                hashtag_analysis.get("optimized_hashtags", []),
                context or {}
            )
            
            return {
                "success": True,
                "type": "instagram_workflow",
                "target_keyword": target_keyword,
                "hashtag_analysis": hashtag_analysis.get("business_analysis", {}),
                "content_workflow": workflow_result,
                "visual_strategy": await self._generate_visual_strategy(target_keyword, context),
                "engagement_tips": await self._generate_engagement_tips(context),
                "created_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
            return await self._generate_basic_instagram_workflow(target_keyword, context)
    
    async def generate_instagram_content(self, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ğŸ†• ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ìƒì„± - í†µí•© ìµœì í™”"""
        try:
            if not context:
                context = {}
            
            # ğŸ†• ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ ê¸°ë°˜ ì½˜í…ì¸  ìƒì„±
            business_type = context.get("business_type", "ì¼ë°˜")
            product = context.get("product", "ì œí’ˆ/ì„œë¹„ìŠ¤")
            
            # ì—…ì¢…ë³„ íŠ¹í™” ì½˜í…ì¸  ìƒì„±
            content_result = await self._generate_instagram_content_optimized(business_type, product, context)
            
            return {
                "success": True,
                "type": "instagram_content",
                "business_type": business_type,
                "content": content_result,
                "optimization_applied": True,
                "generated_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "type": "instagram_content"
            }
    
    # ============================================
    # ğŸ†• ìƒˆë¡œìš´ ë¶„ì„ ë©”ì„œë“œë“¤
    # ============================================
    
    async def analyze_keyword_comprehensive(self, keywords: List[str], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ğŸ†• ì¢…í•©ì ì¸ í‚¤ì›Œë“œ ë¶„ì„"""
        try:
            # íŠ¸ë Œë“œ ë¶„ì„ê³¼ í‚¤ì›Œë“œ ë¶„ì„ì„ í†µí•©
            trend_analysis = await self.analyze_naver_trends(keywords, context)
            
            # ğŸ†• í‚¤ì›Œë“œë³„ ìƒì„¸ ë¶„ì„ ìˆ˜í–‰
            keyword_details = await self._analyze_keywords_detailed(keywords, context or {})
            
            # ğŸ†• ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ì „ëµ ìƒì„±
            utilization_strategy = await self._generate_keyword_utilization_strategy(
                keywords, keyword_details, context or {}
            )
            
            return {
                "success": True,
                "type": "keyword_comprehensive",
                "keywords": keywords,
                "trend_analysis": trend_analysis.get("business_analysis", {}),
                "keyword_details": keyword_details,
                "utilization_strategy": utilization_strategy,
                "recommendations": await self._generate_comprehensive_recommendations(keywords, context),
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "type": "keyword_comprehensive"
            }
    
    # ============================================
    # ğŸ†• ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ í—¬í¼ ë©”ì„œë“œë“¤
    # ============================================
    
    async def _analyze_trends_with_context(self, trend_data: Dict[str, Any], keywords: List[str], context: Dict[str, Any]) -> str:
        """ğŸ†• ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜")
            product = context.get("product", "ì œí’ˆ/ì„œë¹„ìŠ¤")
            target_audience = context.get("target_audience", "ì¼ë°˜ ê³ ê°")
            main_goal = context.get("main_goal", "ë¸Œëœë“œ ì¸ì§€ë„ í–¥ìƒ")
            
            # ì—…ì¢…ë³„ ë¶„ì„ ì„¤ì • ì ìš©
            industry_config = self.industry_analysis_configs.get(business_type, {})
            analysis_angle = industry_config.get("analysis_angle", "ì¼ë°˜ì ì¸ ë§ˆì¼€íŒ… ê´€ì ")
            
            formatted_prompt = self.trend_analysis_prompt.format(
                trend_data=json.dumps(trend_data, ensure_ascii=False),
                business_type=business_type,
                product=product,
                target_audience=target_audience,
                main_goal=main_goal
            )
            
            response = await self._call_analysis_llm(formatted_prompt)
            return response
            
        except Exception as e:
            self.logger.error(f"ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "íŠ¸ë Œë“œ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _analyze_hashtags_with_context(self, hashtag_data: Dict[str, Any], hashtags: List[str], context: Dict[str, Any]) -> str:
        """ğŸ†• ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í•´ì‹œíƒœê·¸ ë¶„ì„"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜")
            product = context.get("product", "ì œí’ˆ/ì„œë¹„ìŠ¤")
            target_audience = context.get("target_audience", "ì¼ë°˜ ê³ ê°")
            
            formatted_prompt = self.hashtag_analysis_prompt.format(
                hashtag_data=json.dumps(hashtag_data, ensure_ascii=False),
                business_type=business_type,
                product=product,
                target_audience=target_audience,
                current_hashtags=', '.join(hashtags)
            )
            
            response = await self._call_analysis_llm(formatted_prompt)
            return response
            
        except Exception as e:
            self.logger.error(f"ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í•´ì‹œíƒœê·¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "í•´ì‹œíƒœê·¸ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _analyze_keywords_detailed(self, keywords: List[str], context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• í‚¤ì›Œë“œ ìƒì„¸ ë¶„ì„"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜")
            main_goal = context.get("main_goal", "ë¸Œëœë“œ ì¸ì§€ë„ í–¥ìƒ")
            target_audience = context.get("target_audience", "ì¼ë°˜ ê³ ê°")
            
            # ì—…ì¢…ë³„ í‚¤ì›Œë“œ ìš°ì„ ìˆœìœ„ ì ìš©
            industry_config = self.industry_analysis_configs.get(business_type, {})
            priority_keywords = industry_config.get("keyword_priorities", [])
            
            analysis_prompt = f"""ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ {business_type} ì—…ì¢…ì˜ ê´€ì ì—ì„œ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”.

í‚¤ì›Œë“œ: {', '.join(keywords)}
ì—…ì¢… íŠ¹ì„±: {business_type}
ë§ˆì¼€íŒ… ëª©í‘œ: {main_goal}
íƒ€ê²Ÿ ê³ ê°: {target_audience}
ìš°ì„  í‚¤ì›Œë“œ ìœ í˜•: {', '.join(priority_keywords)}

ê° í‚¤ì›Œë“œë³„ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ê²€ìƒ‰ ì˜ë„ ë¶„ì„
2. ê²½ìŸë„ ì˜ˆìƒ (ìƒ/ì¤‘/í•˜)
3. ë¹„ì¦ˆë‹ˆìŠ¤ ì—°ê´€ì„± (ìƒ/ì¤‘/í•˜)
4. í™œìš© ìš°ì„ ìˆœìœ„ (1-5ì )
5. ì¶”ì²œ í™œìš© ë°©ë²•

JSON í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
            
            response = await self._call_analysis_llm(analysis_prompt)
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                return json.loads(response)
            except json.JSONDecodeError:
                return {"analysis": response, "parsed": False}
                
        except Exception as e:
            self.logger.error(f"í‚¤ì›Œë“œ ìƒì„¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def _call_analysis_llm(self, prompt: str) -> str:
        """ğŸ†• ë¶„ì„ ì „ìš© LLM í˜¸ì¶œ"""
        try:
            response = self.client.chat.completions.create(
                model=config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": """ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì‹¤í–‰ ì¤‘ì‹¬**: ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
2. **ì—…ì¢… íŠ¹í™”**: í•´ë‹¹ ì—…ì¢…ì˜ íŠ¹ì„±ê³¼ íŠ¸ë Œë“œ ë°˜ì˜
3. **ë§ì¶¤í™”**: ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ì— ë§ëŠ” ë¶„ì„
4. **ìš°ì„ ìˆœìœ„**: íš¨ê³¼ ë†’ì€ ê²ƒë¶€í„° ìˆœì„œëŒ€ë¡œ ì œì‹œ
5. **ì¸¡ì • ê°€ëŠ¥**: ì„±ê³¼ë¥¼ ì¶”ì í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë°©ë²• ì œì•ˆ

ë°ì´í„°ë¥¼ ë‹¨ìˆœíˆ ì„¤ëª…í•˜ì§€ ë§ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ë„ì›€ë˜ëŠ” ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # ë¶„ì„ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
                max_tokens=2000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            self.logger.error(f"ë¶„ì„ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    # ============================================
    # ğŸ†• ì „ëµ ìƒì„± ë©”ì„œë“œë“¤
    # ============================================
    
    async def _generate_trend_recommendations(self, analysis_result: str, context: Dict[str, Any]) -> List[str]:
        """ğŸ†• íŠ¸ë Œë“œ ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜") if context else "ì¼ë°˜"
            
            prompt = f"""ë‹¤ìŒ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ {business_type} ì—…ì¢…ì—ì„œ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ì•¡ì…˜ 5ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ë¶„ì„ ê²°ê³¼: {analysis_result}

ê° ì¶”ì²œì‚¬í•­ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
- êµ¬ì²´ì  ì•¡ì…˜: [ë¬´ì—‡ì„ í• ì§€]
- ì‹¤í–‰ ë°©ë²•: [ì–´ë–»ê²Œ í• ì§€]
- ì˜ˆìƒ íš¨ê³¼: [ì–´ë–¤ ê²°ê³¼ë¥¼ ê¸°ëŒ€í• ì§€]

JSON ë°°ì—´ í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
            
            response = await self._call_analysis_llm(prompt)
            
            try:
                return json.loads(response)
            except json.JSONDecodeError:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¶”ì²œì‚¬í•­ ë°˜í™˜
                return [
                    "íŠ¸ë Œë“œ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ ì½˜í…ì¸  ì œì‘",
                    "ì‹œì¦Œë³„ ë§ˆì¼€íŒ… ë©”ì‹œì§€ ì¡°ì •",
                    "íƒ€ê²Ÿ ê³ ê° ê´€ì‹¬ì‚¬ ë°˜ì˜í•œ ìº í˜ì¸ ê¸°íš",
                    "ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„í™” í¬ì¸íŠ¸ ê°•í™”",
                    "ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ… ì „ëµ ìµœì í™”"
                ]
                
        except Exception as e:
            self.logger.error(f"íŠ¸ë Œë“œ ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {e}")
            return ["íŠ¸ë Œë“œ ë¶„ì„ ê¸°ë°˜ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤."]
    
    async def _generate_optimized_hashtags(self, analysis_result: str, context: Dict[str, Any]) -> Dict[str, List[str]]:
        """ğŸ†• ìµœì í™”ëœ í•´ì‹œíƒœê·¸ ìƒì„±"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜") if context else "ì¼ë°˜"
            
            # ì—…ì¢…ë³„ í•´ì‹œíƒœê·¸ ì¹´í…Œê³ ë¦¬ ì ìš©
            industry_config = self.industry_analysis_configs.get(business_type, {})
            hashtag_categories = industry_config.get("hashtag_categories", ["ì¼ë°˜", "ë§ˆì¼€íŒ…", "ë¹„ì¦ˆë‹ˆìŠ¤"])
            
            optimized_hashtags = {
                "brand_core": [f"#{business_type}", "#ë¸Œëœë“œ", "#í’ˆì§ˆ", "#ì‹ ë¢°", "#ì „ë¬¸"],
                "trending": [f"#{cat}íŠ¸ë Œë“œ" for cat in hashtag_categories[:3]],
                "target_specific": [f"#{business_type}ì¶”ì²œ", f"#{business_type}íŒ", f"#{business_type}ì •ë³´"],
                "engagement": ["#ì¼ìƒ", "#ì†Œí†µ", "#ê³µê°", "#ì²´í—˜", "#í›„ê¸°"]
            }
            
            return optimized_hashtags
            
        except Exception as e:
            self.logger.error(f"ìµœì í™”ëœ í•´ì‹œíƒœê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "brand_core": ["#ë¸Œëœë“œ", "#í’ˆì§ˆ", "#ì „ë¬¸", "#ì‹ ë¢°", "#ì„œë¹„ìŠ¤"],
                "trending": ["#íŠ¸ë Œë“œ", "#ì¸ê¸°", "#í•«í•œ", "#ìµœì‹ ", "#í™”ì œ"],
                "target_specific": ["#ì¶”ì²œ", "#íŒ", "#ì •ë³´", "#ê°€ì´ë“œ", "#ë…¸í•˜ìš°"],
                "engagement": ["#ì¼ìƒ", "#ì†Œí†µ", "#ê³µê°", "#ì²´í—˜", "#í›„ê¸°"]
            }
    
    async def _generate_hashtag_strategy(self, analysis_result: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• í•´ì‹œíƒœê·¸ ì „ëµ ìƒì„±"""
        try:
            strategy = {
                "posting_schedule": {
                    "ì›”ìš”ì¼": "ë¸Œëœë“œ ì†Œê°œ + ì „ë¬¸ì„± ì–´í•„ í•´ì‹œíƒœê·¸",
                    "ìˆ˜ìš”ì¼": "ì œí’ˆ/ì„œë¹„ìŠ¤ ê´€ë ¨ + íŠ¸ë Œë“œ í•´ì‹œíƒœê·¸", 
                    "ê¸ˆìš”ì¼": "ê³ ê° ì†Œí†µ + ì°¸ì—¬ ìœ ë„ í•´ì‹œíƒœê·¸"
                },
                "engagement_tips": [
                    "í¬ìŠ¤íŠ¸ ë‚´ìš©ê³¼ ì—°ê´€ì„± ë†’ì€ í•´ì‹œíƒœê·¸ ìš°ì„  ì‚¬ìš©",
                    "ì¸ê¸° í•´ì‹œíƒœê·¸ì™€ ë‹ˆì¹˜ í•´ì‹œíƒœê·¸ ì¡°í•© (7:3 ë¹„ìœ¨)",
                    "ìŠ¤í† ë¦¬ì—ì„œëŠ” ìœ„ì¹˜ íƒœê·¸ì™€ í•¨ê»˜ í™œìš©",
                    "ëŒ“ê¸€ì—ì„œ ì¶”ê°€ í•´ì‹œíƒœê·¸ë¡œ ë…¸ì¶œ í™•ëŒ€"
                ],
                "monitoring_metrics": [
                    "í•´ì‹œíƒœê·¸ë³„ ë„ë‹¬ë¥ ",
                    "ì¸ê²Œì´ì§€ë¨¼íŠ¸ ë¹„ìœ¨",
                    "íŒ”ë¡œì›Œ ì¦ê°€ìœ¨",
                    "í”„ë¡œí•„ ë°©ë¬¸ë¥ "
                ]
            }
            
            return strategy
            
        except Exception as e:
            self.logger.error(f"í•´ì‹œíƒœê·¸ ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    # ============================================
    # ğŸ†• ì›Œí¬í”Œë¡œìš° ìƒì„± ë©”ì„œë“œë“¤ (ìŠ¤í…ìœ¼ë¡œ êµ¬í˜„)
    # ============================================
    
    async def _create_blog_workflow_with_seo(self, keyword: str, analysis: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• SEO ìµœì í™”ëœ ë¸”ë¡œê·¸ ì›Œí¬í”Œë¡œìš°"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜")
            
            workflow = {
                "planning_phase": {
                    "keyword_research": f"{keyword} ë° ê´€ë ¨ í‚¤ì›Œë“œ ì‹¬í™” ë¶„ì„",
                    "competitor_analysis": "ìƒìœ„ ë­í‚¹ ë¸”ë¡œê·¸ ì½˜í…ì¸  ë¶„ì„",
                    "content_gap": "ê²½ìŸì‚¬ê°€ ë‹¤ë£¨ì§€ ì•Šì€ ì°¨ë³„í™” í¬ì¸íŠ¸ ë°œêµ´"
                },
                "creation_phase": {
                    "title_optimization": f"SEO ì¹œí™”ì  ì œëª© (íƒ€ê²Ÿ í‚¤ì›Œë“œ: {keyword})",
                    "structure_planning": "H1-H2-H3 êµ¬ì¡°í™” ë° í‚¤ì›Œë“œ ë°°ì¹˜",
                    "content_writing": "ë…ì ì¤‘ì‹¬ì˜ ìœ ìš©í•œ ì •ë³´ ì œê³µ",
                    "internal_linking": "ê´€ë ¨ í¬ìŠ¤íŠ¸ ë° ì„œë¹„ìŠ¤ í˜ì´ì§€ ì—°ê²°"
                },
                "optimization_phase": {
                    "meta_tags": "ë©”íƒ€ ì œëª©, ì„¤ëª… ìµœì í™”",
                    "image_seo": "ì´ë¯¸ì§€ alt í…ìŠ¤íŠ¸ ë° íŒŒì¼ëª… ìµœì í™”",
                    "readability": "ê°€ë…ì„± í–¥ìƒ (ë¬¸ë‹¨, bullet point í™œìš©)",
                    "cta_placement": "ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜ ìœ ë„"
                },
                "distribution_phase": {
                    "social_sharing": "SNS ì±„ë„ë³„ ë§ì¶¤ ê³µìœ ",
                    "email_marketing": "ë‰´ìŠ¤ë ˆí„° êµ¬ë…ì ëŒ€ìƒ ë°°í¬",
                    "community_sharing": "ê´€ë ¨ ì»¤ë®¤ë‹ˆí‹° ë° í¬ëŸ¼ ê³µìœ "
                }
            }
            
            return workflow
            
        except Exception as e:
            self.logger.error(f"ë¸”ë¡œê·¸ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def _create_instagram_workflow_with_visuals(self, keyword: str, hashtags: List[str], context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• ë¹„ì£¼ì–¼ ì¤‘ì‹¬ ì¸ìŠ¤íƒ€ê·¸ë¨ ì›Œí¬í”Œë¡œìš°"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜")
            
            workflow = {
                "concept_development": {
                    "visual_theme": f"{business_type} ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° ë°˜ì˜",
                    "content_pillars": "êµìœ¡/ì˜ê°/ì—”í„°í…Œì¸ë¨¼íŠ¸/í™ë³´ 4ì¶• ê· í˜•",
                    "storytelling": f"{keyword} ì¤‘ì‹¬ì˜ ë¸Œëœë“œ ìŠ¤í† ë¦¬ ì „ê°œ"
                },
                "content_creation": {
                    "photo_shooting": "ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ ì¼ê´€ì„± ìœ ì§€",
                    "graphic_design": "ì •ë³´ ì „ë‹¬ìš© ì¹´ë“œë‰´ìŠ¤ ì œì‘",
                    "video_content": "ë¦´ìŠ¤/ìŠ¤í† ë¦¬ìš© ì§§ì€ ì˜ìƒ ì½˜í…ì¸ ",
                    "caption_writing": "íƒ€ê²Ÿ ê³ ê° ì–¸ì–´ë¡œ ì¹œê·¼í•œ í…ìŠ¤íŠ¸"
                },
                "posting_strategy": {
                    "optimal_timing": "íƒ€ê²Ÿ ê³ ê° í™œì„± ì‹œê°„ëŒ€ í¬ìŠ¤íŒ…",
                    "hashtag_rotation": "í•´ì‹œíƒœê·¸ ì¡°í•© 3ê°€ì§€ ìˆœí™˜ ì‚¬ìš©",
                    "story_utilization": "ì¼ìƒì  ì†Œí†µ ë° ë¹„í•˜ì¸ë“œ ê³µìœ ",
                    "reels_strategy": "íŠ¸ë Œë“œ ìŒì•…/íš¨ê³¼ í™œìš©í•œ ì°¸ì—¬ ìœ ë„"
                },
                "engagement_building": {
                    "community_interaction": "ëŒ“ê¸€ ì ê·¹ ì‘ë‹µ ë° íƒ€ ê³„ì • ì†Œí†µ",
                    "user_generated_content": "ê³ ê° í¬ìŠ¤íŠ¸ ë¦¬í¬ìŠ¤íŠ¸ ë° ê°ì‚¬ í‘œí˜„",
                    "collaboration": "ë™ì¢…ì—…ê³„ ì¸í”Œë£¨ì–¸ì„œ/ë¸Œëœë“œ í˜‘ì—…",
                    "live_streaming": "ì‹¤ì‹œê°„ ì†Œí†µì„ í†µí•œ ì¹œë°€ê° í˜•ì„±"
                }
            }
            
            return workflow
            
        except Exception as e:
            self.logger.error(f"ì¸ìŠ¤íƒ€ê·¸ë¨ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    # ============================================
    # ğŸ†• í´ë°± ë©”ì„œë“œë“¤ (MCP ì—°ê²° ì‹¤íŒ¨ ì‹œ)
    # ============================================
    
    async def _generate_fallback_trend_analysis(self, keywords: List[str], context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• MCP ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë°± íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜") if context else "ì¼ë°˜"
            
            # ì—…ì¢…ë³„ ê°€ìƒ íŠ¸ë Œë“œ ë¶„ì„ ìƒì„±
            analysis_prompt = f"""ë‹¤ìŒ í‚¤ì›Œë“œì— ëŒ€í•œ {business_type} ì—…ì¢… ê´€ì ì˜ íŠ¸ë Œë“œ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

í‚¤ì›Œë“œ: {', '.join(keywords)}
ì—…ì¢…: {business_type}

ì¼ë°˜ì ì¸ ì‹œì¥ íŠ¸ë Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í‚¤ì›Œë“œë³„ ê´€ì‹¬ë„ ë³€í™” ì˜ˆìƒ
2. ê³„ì ˆì /ì‹œê¸°ì  íŠ¹ì„±
3. íƒ€ê²Ÿ ê³ ê°ì˜ ê²€ìƒ‰ íŒ¨í„´
4. ë§ˆì¼€íŒ… í™œìš© ê¸°íšŒ
5. ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ ì œì•ˆ

ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
            
            analysis_result = await self._call_analysis_llm(analysis_prompt)
            
            return {
                "success": True,
                "type": "trend_analysis_fallback",
                "keywords": keywords,
                "analysis": analysis_result,
                "note": "ì™¸ë¶€ ë°ì´í„° ì—°ê²° ì—†ì´ ì¼ë°˜ì  íŠ¸ë Œë“œ ë¶„ì„ ìˆ˜í–‰",
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"í´ë°± íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "type": "trend_analysis_fallback"
            }
    
    async def _generate_fallback_hashtag_analysis(self, hashtags: List[str], context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• MCP ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë°± í•´ì‹œíƒœê·¸ ë¶„ì„"""
        try:
            business_type = context.get("business_type", "ì¼ë°˜") if context else "ì¼ë°˜"
            
            # ì—…ì¢…ë³„ í•´ì‹œíƒœê·¸ ìµœì í™” ì œì•ˆ
            optimized_hashtags = await self._generate_optimized_hashtags("", context or {})
            strategy = await self._generate_hashtag_strategy("", context or {})
            
            return {
                "success": True,
                "type": "hashtag_analysis_fallback",
                "analyzed_hashtags": hashtags,
                "optimized_hashtags": optimized_hashtags,
                "strategy": strategy,
                "note": "ì—…ì¢…ë³„ ëª¨ë²”ì‚¬ë¡€ ê¸°ë°˜ í•´ì‹œíƒœê·¸ ìµœì í™”",
                "analyzed_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"í´ë°± í•´ì‹œíƒœê·¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "type": "hashtag_analysis_fallback"
            }
    
    async def _generate_basic_blog_workflow(self, keyword: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• ê¸°ë³¸ ë¸”ë¡œê·¸ ì›Œí¬í”Œë¡œìš°"""
        workflow = await self._create_blog_workflow_with_seo(keyword, {}, context or {})
        
        return {
            "success": True,
            "type": "blog_workflow_basic",
            "target_keyword": keyword,
            "workflow": workflow,
            "note": "ê¸°ë³¸ SEO ì›Œí¬í”Œë¡œìš° ì ìš©",
            "created_at": datetime.now().isoformat()
        }
    
    async def _generate_basic_instagram_workflow(self, keyword: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ†• ê¸°ë³¸ ì¸ìŠ¤íƒ€ê·¸ë¨ ì›Œí¬í”Œë¡œìš°"""
        workflow = await self._create_instagram_workflow_with_visuals(keyword, [], context or {})
        
        return {
            "success": True,
            "type": "instagram_workflow_basic",
            "target_keyword": keyword,
            "workflow": workflow,
            "note": "ê¸°ë³¸ ë¹„ì£¼ì–¼ ì›Œí¬í”Œë¡œìš° ì ìš©",
            "created_at": datetime.now().isoformat()
        }

# ============================================
# ğŸ†• ëª¨ë“ˆ íŒ©í† ë¦¬ í•¨ìˆ˜
# ============================================

def get_marketing_mcp_marketing_tools() -> MarketingAnalysisTools:
    """ğŸ†• ë§ˆì¼€íŒ… ë¶„ì„ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return MarketingAnalysisTools()
