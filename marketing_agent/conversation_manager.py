"""
ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬ì - ê°œì„ ëœ ë²„ì „
âœ… ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ë§¥ë½ ì´í•´ ê°œì„ , ì¹œë°€ê° ê°•í™”, ì‚¬ìš©ì í”¼ë¡œë„ ê°ì†Œ
âœ… ëª¨ë“  ì‘ë‹µ LLM ìƒì„±, í•˜ë“œì½”ë”© ì™„ì „ ì œê±°
"""

import json
import logging
import os
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
from langchain_core.runnables.config import P
import openai
from general_marketing_tools import MarketingTools
from mcp_marketing_tools import MarketingAnalysisTools

general_marketing_tools = MarketingTools()
mcp_marketing_tools = MarketingAnalysisTools()

logger = logging.getLogger(__name__)

class MarketingStage(Enum):
    """ë§ˆì¼€íŒ… ë‹¨ê³„ ì •ì˜"""
    INITIAL = "INITIAL"           # ì´ˆê¸° ìƒíƒœ
    GOAL = "GOAL"                # 1ë‹¨ê³„: ëª©í‘œ ì„¤ì •  
    TARGET = "TARGET"            # 2ë‹¨ê³„: íƒ€ê²Ÿ ë¶„ì„
    STRATEGY = "STRATEGY"        # 3ë‹¨ê³„: ì „ëµ ê¸°íš
    EXECUTION = "EXECUTION"      # 4ë‹¨ê³„: ì‹¤í–‰ ê³„íš
    CONTENT_CREATION = "CONTENT_CREATION"  # 5ë‹¨ê³„: ì»¨í…ì¸  ì œì‘ (ë©€í‹°í„´)
    COMPLETED = "COMPLETED"      # ì™„ë£Œ

class ConversationMode(Enum):
    """ëŒ€í™” ëª¨ë“œ"""
    QUESTIONING = "QUESTIONING"   # ì§ˆë¬¸ ëª¨ë“œ (ì •ë³´ ìˆ˜ì§‘)
    SUGGESTING = "SUGGESTING"     # ì œì•ˆ ëª¨ë“œ (ì§ì ‘ ì¶”ì²œ/ì¡°ì–¸)
    CONTENT_CREATION = "CONTENT_CREATION"  # ì»¨í…ì¸  ì œì‘ ëª¨ë“œ

@dataclass
class ConversationState:
    """ëŒ€í™” ìƒíƒœ ê´€ë¦¬"""
    user_id: int
    conversation_id: int
    current_stage: MarketingStage = MarketingStage.INITIAL
    current_mode: ConversationMode = ConversationMode.QUESTIONING
    business_type: str = "ì¼ë°˜"
    collected_info: Dict[str, Any] = field(default_factory=dict)
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    stage_progress: Dict[str, float] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    last_activity: datetime = field(default_factory=datetime.now)
    
    # ğŸ†• ì‚¬ìš©ì ì‘ë‹µ íŒ¨í„´ ì¶”ì 
    negative_response_count: int = 0
    last_negative_response: Optional[str] = None
    suggestion_attempts: int = 0
    user_engagement_level: str = "high"  # high, medium, low
    
    # ğŸ†• ì»¨í…ì¸  ì œì‘ ê´€ë ¨ ìƒíƒœ
    current_content_session: Optional[Dict[str, Any]] = None
    content_history: List[Dict[str, Any]] = field(default_factory=list)
    
    # ğŸ†• í¬ìŠ¤íŒ… ê´€ë ¨ ìƒíƒœ
    awaiting_posting_confirmation: bool = False
    awaiting_scheduling_time: bool = False
    current_content_for_posting: Optional[Dict[str, Any]] = None
    
    def add_message(self, role: str, content: str, metadata: Optional[Dict] = None):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "stage": self.current_stage.value,
            "mode": self.current_mode.value
        }
        if metadata:
            message.update(metadata)
        
        self.conversation_history.append(message)
        self.last_activity = datetime.now()
        
        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœê·¼ 20ê°œë§Œ ìœ ì§€)
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
    
    def add_info(self, key: str, value: Any, source: str = "user"):
        """ì •ë³´ ìˆ˜ì§‘"""
        self.collected_info[key] = {
            "value": value,
            "source": source,
            "timestamp": datetime.now().isoformat()
        }
    
    def get_info(self, key: str) -> Any:
        """ì •ë³´ ì¡°íšŒ"""
        info = self.collected_info.get(key)
        return info["value"] if info else None
    
    # ğŸ†• ë¶€ì •ì  ì‘ë‹µ ì¶”ì 
    def record_negative_response(self, response: str):
        """ë¶€ì •ì  ì‘ë‹µ ê¸°ë¡"""
        self.negative_response_count += 1
        self.last_negative_response = response
        
        # ì°¸ì—¬ë„ ì¡°ì •
        if self.negative_response_count >= 2:
            self.user_engagement_level = "low"
        elif self.negative_response_count >= 1:
            self.user_engagement_level = "medium"
    
    def reset_negative_responses(self):
        """ë¶€ì •ì  ì‘ë‹µ ì¹´ìš´í„° ë¦¬ì…‹"""
        self.negative_response_count = 0
        self.last_negative_response = None
        self.user_engagement_level = "high"
    
    def should_switch_to_suggestion_mode(self) -> bool:
        """ì œì•ˆ ëª¨ë“œë¡œ ì „í™˜í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨"""
        return (self.negative_response_count >= 2 or 
                self.user_engagement_level == "low" or
                self.suggestion_attempts < 3)
    
    def switch_to_suggestion_mode(self):
        """ì œì•ˆ ëª¨ë“œë¡œ ì „í™˜"""
        self.current_mode = ConversationMode.SUGGESTING
        self.suggestion_attempts += 1
    
    def has_sufficient_info_for_suggestions(self) -> bool:
        """ì œì•ˆì„ ìœ„í•œ ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        # ìµœì†Œí•œì˜ ì •ë³´ë§Œ ìˆì–´ë„ ì œì•ˆ ê°€ëŠ¥
        return (self.business_type != "ì¼ë°˜" or 
                self.get_info('product') or 
                self.get_info('business_type') or
                self.get_info('main_goal') or
                len(self.collected_info) > 0)
    
    # ê¸°ì¡´ ë©”ì„œë“œë“¤...
    def start_content_session(self, content_type: str, initial_request: str):
        """ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì‹œì‘"""
        session_data = {
            "content_type": content_type,
            "initial_request": initial_request,
            "created_at": datetime.now().isoformat(),
            "iteration_count": 1,
            "last_content": None,
            "context_info": {
                "business_type": self.business_type,
                "keywords": self.get_info('keywords'),
                "trend_data": self.get_info('trend_data'),
                "product": self.get_info('product'),
                "target_audience": self.get_info('target_audience'),
                "main_goal": self.get_info('main_goal')
            }
        }
        self.current_content_session = session_data
        self.current_mode = ConversationMode.CONTENT_CREATION
        logger.info(f"ì»¨í…ì¸  ì„¸ì…˜ ì‹œì‘: {content_type}, ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í¬í•¨")
    
    def update_content_session(self, new_content: str, user_feedback: str = None):
        """ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì—…ë°ì´íŠ¸"""
        if self.current_content_session:
            self.current_content_session["last_content"] = new_content
            self.current_content_session["iteration_count"] += 1
            if user_feedback:
                self.current_content_session["last_feedback"] = user_feedback
            logger.info(f"ì»¨í…ì¸  ì„¸ì…˜ ì—…ë°ì´íŠ¸: ë°˜ë³µ {self.current_content_session['iteration_count']}íšŒ")
    
    def end_content_session(self):
        """ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì¢…ë£Œ"""
        if self.current_content_session:
            self.content_history.append(self.current_content_session.copy())
            self.current_content_session = None
            self.current_mode = ConversationMode.SUGGESTING
            logger.info("ì»¨í…ì¸  ì„¸ì…˜ ì¢…ë£Œ")
    
    def is_in_content_creation(self) -> bool:
        """ì»¨í…ì¸  ì œì‘ ë‹¨ê³„ ì—¬ë¶€"""
        return self.current_stage == MarketingStage.CONTENT_CREATION and self.current_content_session is not None
    
    # í¬ìŠ¤íŒ… ê´€ë ¨ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€)
    def start_posting_confirmation(self, content_data: Dict[str, Any]):
        """í¬ìŠ¤íŒ… í™•ì¸ ë‹¨ê³„ ì‹œì‘"""
        self.awaiting_posting_confirmation = True
        self.current_content_for_posting = content_data
        logger.info(f"í¬ìŠ¤íŒ… í™•ì¸ ë‹¨ê³„ ì‹œì‘: {content_data.get('type', 'unknown')}")
    
    def confirm_posting_and_request_schedule(self):
        """í¬ìŠ¤íŒ… í™•ì¸ í›„ ìŠ¤ì¼€ì¤„ ì…ë ¥ ìš”ì²­"""
        self.awaiting_posting_confirmation = False
        self.awaiting_scheduling_time = True
        logger.info("í¬ìŠ¤íŒ… í™•ì¸ë¨, ìŠ¤ì¼€ì¤„ ì…ë ¥ ëŒ€ê¸° ì¤‘")
    
    def complete_posting_process(self):
        """í¬ìŠ¤íŒ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ"""
        self.awaiting_posting_confirmation = False
        self.awaiting_scheduling_time = False
        self.current_content_for_posting = None
        logger.info("í¬ìŠ¤íŒ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
    
    def cancel_posting_process(self):
        """í¬ìŠ¤íŒ… í”„ë¡œì„¸ìŠ¤ ì·¨ì†Œ"""
        self.awaiting_posting_confirmation = False
        self.awaiting_scheduling_time = False
        self.current_content_for_posting = None
        logger.info("í¬ìŠ¤íŒ… í”„ë¡œì„¸ìŠ¤ ì·¨ì†Œë¨")
    
    def is_awaiting_posting_response(self) -> bool:
        """í¬ìŠ¤íŒ… ê´€ë ¨ ì‘ë‹µ ëŒ€ê¸° ì¤‘ì¸ì§€ í™•ì¸"""
        return self.awaiting_posting_confirmation or self.awaiting_scheduling_time
    
    def get_completion_rate(self) -> float:
        """ì „ì²´ ì™„ë£Œìœ¨ ê³„ì‚°"""
        required_fields = ["business_type", "product", "main_goal", "target_audience", "budget", "channels"]
        completed_fields = sum(1 for field in required_fields if self.get_info(field))
        return completed_fields / len(required_fields)
    
    def get_missing_info(self, for_content_creation: bool = False) -> List[str]:
        if for_content_creation:
            # ì»¨í…ì¸  ì œì‘ ì‹œì—ëŠ” í‚¤ì›Œë“œë‚˜ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìµœì†Œ ì •ë³´ë§Œ ìš”êµ¬
            has_keywords_or_trends = self.get_info('keywords') or self.get_info('trend_data')
            if has_keywords_or_trends:
                essential_fields = ["business_type", "product"]
                missing = [field for field in essential_fields if not self.get_info(field) and (field != "business_type" or self.business_type == "ì¼ë°˜")]
                return missing if len(missing) == len(essential_fields) else []
        
        required_fields = ["business_type", "product", "main_goal", "target_audience", "budget", "channels", "pain_points"]
        return [field for field in required_fields if not self.get_info(field)]
    
    def get_context_based_missing_info(self) -> Dict[str, Any]:
        """ğŸ†• ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶€ì¡±í•œ ì •ë³´ ë¶„ì„"""
        missing_info = self.get_missing_info()
        
        # ë‹¨ê³„ë³„ ìš°ì„ ìˆœìœ„ ì •ë³´ ì •ì˜
        stage_priorities = {
            MarketingStage.GOAL: ["main_goal", "business_type", "product"],
            MarketingStage.TARGET: ["target_audience", "main_goal", "product"],
            MarketingStage.STRATEGY: ["budget", "channels", "target_audience"],
            MarketingStage.EXECUTION: ["channels", "budget", "pain_points"],
            MarketingStage.CONTENT_CREATION: ["product", "target_audience", "main_goal"]
        }
        
        current_priorities = stage_priorities.get(self.current_stage, [])
        
        # ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ë¶€ì¡±í•œ ì •ë³´ í•„í„°ë§
        priority_missing = [field for field in current_priorities if field in missing_info]
        
        return {
            "total_missing": missing_info,
            "priority_missing": priority_missing,
            "completion_rate": self.get_completion_rate(),
            "current_stage": self.current_stage.value,
            "can_proceed": len(priority_missing) <= 1,  # ìš°ì„ ìˆœìœ„ ì •ë³´ 1ê°œ ì´í•˜ë©´ ì§„í–‰ ê°€ëŠ¥
            "suggested_focus": priority_missing[0] if priority_missing else None
        }

    def get_conversation_context(self) -> str:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìš”ì•½"""
        context_parts = []
        
        # ê¸°ë³¸ ì •ë³´
        if self.business_type != "ì¼ë°˜":
            context_parts.append(f"ì—…ì¢…: {self.business_type}")
        
        # ì‚¬ìš©ì ì°¸ì—¬ë„ ì •ë³´
        context_parts.append(f"ì°¸ì—¬ë„: {self.user_engagement_level}")
        context_parts.append(f"ëŒ€í™” ëª¨ë“œ: {self.current_mode.value}")
        
        if self.negative_response_count > 0:
            context_parts.append(f"ë¶€ì •ì  ì‘ë‹µ íšŸìˆ˜: {self.negative_response_count}")
        
        # ìˆ˜ì§‘ëœ ì •ë³´ ìš”ì•½
        key_info = {}
        special_info = {}
        
        for key, info in self.collected_info.items():
            if key in ['keywords', 'trend_data']:
                special_info[key] = info["value"]
            else:
                key_info[key] = info["value"]
        
        if special_info:
            context_parts.append(f"í‚¤ì›Œë“œ/íŠ¸ë Œë“œ ë°ì´í„°: {json.dumps(special_info, ensure_ascii=False)}")
        
        if key_info:
            context_parts.append(f"ê¸°íƒ€ ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(key_info, ensure_ascii=False)}")
        
        # ìµœê·¼ ëŒ€í™” 6ê°œ
        recent_messages = self.conversation_history[-6:] if self.conversation_history else []
        if recent_messages:
            context_parts.append("ìµœê·¼ ëŒ€í™”:")
            for msg in recent_messages:
                role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
                context_parts.append(f"- {role}: {msg['content'][:100]}...")
        
        return "\n".join(context_parts)
    
    def is_expired(self, timeout_minutes: int = 60) -> bool:
        """ì„¸ì…˜ ë§Œë£Œ í™•ì¸"""
        expiry_time = self.last_activity + timedelta(minutes=timeout_minutes)
        return datetime.now() > expiry_time

class ConversationManager:
    """ğŸ†• ê°œì„ ëœ ëŒ€í™” ê´€ë¦¬ì - ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ë§¥ë½ ì´í•´, ì¹œë°€ê° ê°•í™”"""
    
    def __init__(self):
        from config import config
        self.client = openai.OpenAI(api_key=config.OPENAI_API_KEY)
        self.model = config.OPENAI_MODEL
        self.temperature = config.TEMPERATURE
        self.conversations: Dict[int, ConversationState] = {}
        
        # LLM í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”
        self._init_llm_prompts()
        logger.info("ğŸ†• ê°œì„ ëœ ConversationManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_llm_prompts(self):
        """ğŸ†• ê°œì„ ëœ LLM í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”"""
        
        # ğŸ†• ë¶€ì •ì  ì‘ë‹µ ê°ì§€ í”„ë¡¬í”„íŠ¸
        self.negative_response_detection_prompt = """ì‚¬ìš©ìì˜ ì‘ë‹µì´ ë¶€ì •ì ì´ê±°ë‚˜ ì •ë³´ ì œê³µì„ ê±°ë¶€í•˜ëŠ” ë‚´ìš©ì¸ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ëŒ€ìƒ:
- "ëª°ë¼", "ëª¨ë¥´ê² ì–´", "ì˜ ëª¨ë¥´ê² ì–´"
- "ë‹ˆê°€ ì•Œë ¤ì¤˜", "ë‹¹ì‹ ì´ ë§í•´ì¤˜", "ì¶”ì²œí•´ì¤˜"
- "ì˜ ëª¨ë¥´ê² ëŠ”ë°", "í™•ì‹¤í•˜ì§€ ì•Šì•„"
- "ê·¸ëƒ¥", "ì•„ë¬´ê±°ë‚˜", "ìƒê´€ì—†ì–´"
- "ë³„ë¡œ", "ì‹«ì–´", "ì•ˆ ì¢‹ì•„"

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{
    "is_negative": true/false,
    "type": "no_knowledge|request_suggestion|indifferent|rejection|neutral",
    "confidence": 0.0-1.0,
    "suggested_action": "switch_to_suggestion|continue_questioning|provide_options"
}"""

        # ğŸ†• ì œì•ˆ ëª¨ë“œ ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸
        self.suggestion_mode_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ì–´ë ¤ì›Œí•˜ê±°ë‚˜ ëª¨ë¥¸ë‹¤ê³  í•  ë•Œ, ì§ì ‘ì ì¸ ì œì•ˆê³¼ ì¶”ì²œì„ ì œê³µí•´ì£¼ì„¸ìš”.

## ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. **ê³µê°ê³¼ ì´í•´**: ì‚¬ìš©ìê°€ ëª¨ë¥´ëŠ” ê²ƒì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ë“¤ì´ê¸°
2. **ì¦‰ì‹œ ì œì•ˆ**: ì§ˆë¬¸ ëŒ€ì‹  êµ¬ì²´ì ì¸ ì•„ì´ë””ì–´ë‚˜ ì „ëµ ì œì‹œ
3. **ê°œì¸í™”**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©
4. **ì‹¤ìš©ì„±**: ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ì‹¤ì§ˆì  ì¡°ì–¸
5. **ì¹œê·¼í•œ í†¤**: ìƒë‹´ì‚¬ì²˜ëŸ¼ ë”°ëœ»í•˜ê³  ì´í•´ì‹¬ ìˆëŠ” ë§íˆ¬

## ì‘ë‹µ ìŠ¤íƒ€ì¼:
- "ê·¸ëŸ´ ìˆ˜ ìˆì–´ìš”! ì´ëŸ° ìƒí™©ì—ì„œëŠ” ë³´í†µ..."
- "ê´œì°®ìŠµë‹ˆë‹¤. ì œê°€ ê²½í—˜ìƒ ì¶”ì²œë“œë¦¬ëŠ” ê±´..."
- "ì´í•´í•´ìš”. ê·¸ëŸ¼ ì´ëŸ° ì•„ì´ë””ì–´ëŠ” ì–´ë– ì„¸ìš”?"
- "ë§ì€ ë¶„ë“¤ì´ ë¹„ìŠ·í•˜ê²Œ ê³ ë¯¼í•˜ì‹œëŠ”ë°, ë³´í†µ ì´ë ‡ê²Œ ì‹œì‘í•˜ì‹œë”ë¼ê³ ìš”..."

## ì œì•ˆ ìœ í˜•:
- **ë§ì¶¤í˜• ì „ëµ**: ì—…ì¢…ë³„ íŠ¹í™” ì „ëµ
- **êµ¬ì²´ì  ì•„ì´ë””ì–´**: ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ë°©ë²•
- **ì„±ê³µ ì‚¬ë¡€**: ë¹„ìŠ·í•œ ì—…ì¢…ì˜ ì„±ê³µ ì‚¬ë¡€
- **ë‹¨ê³„ì  ê°€ì´ë“œ**: ì°¨ê·¼ì°¨ê·¼ ë”°ë¼í•  ìˆ˜ ìˆëŠ” ë°©ë²•

ì‘ë‹µì€ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ë˜, 2-4ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”."""

        # ğŸ†• ì‹±ê¸€í„´ ì™„ë£Œ íŒë‹¨ í”„ë¡¬í”„íŠ¸
        self.singleton_completion_prompt = """ì‚¬ìš©ìì˜ ìš”ì²­ì´ í•œ ë²ˆì˜ ì‘ë‹µìœ¼ë¡œ ì™„ì „íˆ í•´ê²°ë  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì‹±ê¸€í„´ìœ¼ë¡œ ì™„ë£Œ ê°€ëŠ¥í•œ ê²½ìš°:
- ê°„ë‹¨í•œ ë§ˆì¼€íŒ… ì§ˆë¬¸ (ì˜ˆ: "SNS ë§ˆì¼€íŒ…ì´ ë­ì•¼?")
- ì¼ë°˜ì ì¸ ì¡°ì–¸ ìš”ì²­ (ì˜ˆ: "ë¸Œëœë”© íŒ ì•Œë ¤ì¤˜")
- íŠ¹ì • ê°œë… ì„¤ëª… (ì˜ˆ: "íƒ€ê²Ÿ ë§ˆì¼€íŒ… ì„¤ëª…í•´ì¤˜")
- ì¦‰ì‹œ ë‹µë³€ ê°€ëŠ¥í•œ ì •ë³´ì„± ì§ˆë¬¸

ë©€í‹°í„´ì´ í•„ìš”í•œ ê²½ìš°:
- ë§ì¶¤í˜• ì „ëµ ìˆ˜ë¦½
- ê°œì¸ ìƒí™© ë¶„ì„ì´ í•„ìš”í•œ ìƒë‹´
- ì»¨í…ì¸  ì œì‘ ë° í”¼ë“œë°±
- ë‹¨ê³„ë³„ ì§„í–‰ì´ í•„ìš”í•œ ë³µì¡í•œ ë¬¸ì œ

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{
    "can_complete_as_singleton": true/false,
    "reasoning": "íŒë‹¨ ì´ìœ ",
    "suggested_response_type": "informational|advisory|strategic|conversational"
}"""

        # ğŸ†• êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ (í›„ì† ì§ˆë¬¸ í¬í•¨)
        self.structured_response_prompt = """
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ë§ˆì¼€íŒ… ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìƒí™©ì„ ê¹Šì´ ì´í•´í•˜ê³  ê³µê°í•˜ë©°, ì•„ë˜ ì§€ì¹¨ì— ë”°ë¼ ìœ ìš©í•œ ì¡°ì–¸ê³¼ í•¨ê»˜ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìˆëŠ” í›„ì† ì§ˆë¬¸ ë° ì‹¤í–‰ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•˜ì„¸ìš”.

---

### **â—† ë‹µë³€ ì‘ì„± ì›ì¹™:**

1. **ê³µê° ë° ì´í•´**: ì‚¬ìš©ìì˜ ê³ ë¯¼ì— ëŒ€í•´ ë¨¼ì € ê³µê°ê³¼ ì´í•´ë¥¼ í‘œí˜„í•˜ê³ , ë”°ëœ»í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ì¡°ì–¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.
2. **í•µì‹¬ ì¡°ì–¸ ì œì‹œ**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ì ì¸ ì¡°ì–¸ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤. ê´€ë ¨ì„± ë†’ì€ ì •ë³´ëŠ” í•œ ë¬¸ë‹¨ì— ì‘ì¶•í•˜ì—¬ ì œê³µí•˜ë©°, ë¶ˆí•„ìš”í•œ ê°œí–‰ì€ í”¼í•©ë‹ˆë‹¤.
3. **ì‹¤í–‰ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ ì œì•ˆ**: "ì´ëŸ° ê±¸ ì‹œë„í•´ë³´ì‹œë©´ ì–´ë–¨ê¹Œìš”?", "ì´ëŸ° ë°©í–¥ë„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆê² ì–´ìš”."ì™€ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì‹œë„í•  ìˆ˜ ìˆëŠ” 1~2ê°€ì§€ ì‹¤í–‰ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
4. **í›„ì† ì§ˆë¬¸ ë°°ì¹˜**: **í›„ì† ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ë‹µë³€ì˜ ë§ˆì§€ë§‰ ë¬¸ë‹¨ì— ë°°ì¹˜**í•˜ë©°, ë³¸ë¬¸ ë‚´ìš©ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤. "í˜¹ì‹œ ~~ í•˜ì‹  ì ì´ ìˆë‚˜ìš”?", "í˜¹ì‹œ ~~ ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?" ë“± ê°œë°©í˜• ì§ˆë¬¸ì„ 1~2ê°œ í¬í•¨í•©ë‹ˆë‹¤.
5. **ê°€ë…ì„± ë° êµ¬ì¡°**: ë§ˆí¬ë‹¤ìš´ í—¤ë”©(##), ë³¼ë“œì²´(**), êµ¬ë¶„ì„ (---), ëª©ë¡(-) ë“±ì„ ì „ëµì ìœ¼ë¡œ í™œìš©í•´ ë‹µë³€ì˜ ì£¼ìš” ë‚´ìš©ì„ ì‹œê°ì ìœ¼ë¡œ ê°•ì¡°í•˜ê³  êµ¬ì¡°í™”í•©ë‹ˆë‹¤. ì •ë³´ì˜ ë°€ë„ë¥¼ ë†’ì—¬ í•œëˆˆì— íŒŒì•…í•  ìˆ˜ ìˆê²Œ ì‘ì„±í•©ë‹ˆë‹¤.

---

### **â—† ì§ˆë¬¸ ìƒì„± ì„¸ë¶€ ì›ì¹™:**

- **íƒ€ì´ë°**: ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° ë³´í¸ì  ì§ˆë¬¸(ì˜ˆ: "ì–´ë–¤ ì œí’ˆ/ì„œë¹„ìŠ¤ë¥¼ í™ë³´í•˜ì‹œë‚˜ìš”?")ì„ ë§ˆì§€ë§‰ ë¬¸ë‹¨ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë˜ì§‘ë‹ˆë‹¤.
- **ë§¥ë½ ì í•©ì„±**: ì§ˆë¬¸ì€ ì•ì„  ì¡°ì–¸ê³¼ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ì•¼ í•˜ë©°, ë…ë¦½ëœ ì§ˆë¬¸ ëª©ë¡ì²˜ëŸ¼ ë³´ì´ì§€ ì•Šê²Œ í•©ë‹ˆë‹¤.
- **ì‹¤ìš©ì„± ë° ìœ ë„ì„±**: ë‹µë³€í•˜ê¸° ì‰¬ìš°ë©´ì„œ ë‹¤ìŒ ì»¨ì„¤íŒ… ë‹¨ê³„ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆë„ë¡ ì„¤ê³„í•©ë‹ˆë‹¤.
- **ë‹¤ì–‘ì„±**: ê°œë°©í˜•ê³¼ ì„ íƒí˜• ì§ˆë¬¸ì„ ì ì ˆíˆ í˜¼í•©í•©ë‹ˆë‹¤.

---

### **â—† ì˜ˆì‹œ ë‹µë³€ ìŠ¤íƒ€ì¼ (ì°¸ê³ ):**

**ì‚¬ìš©ì:** "ì €í¬ ì œí’ˆ ë§ˆì¼€íŒ…ì„ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”."

**AI ë‹µë³€ ìŠ¤íƒ€ì¼:**  
"ë§ˆì¼€íŒ… ë°©í–¥ì„ ì¡ëŠ” ê²Œ ì²˜ìŒì—” ë§‰ë§‰í•˜ê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆì£ . ì¶©ë¶„íˆ ê³µê°í•©ë‹ˆë‹¤! í•˜ì§€ë§Œ ê±±ì • ë§ˆì„¸ìš”. í•¨ê»˜ ì°¨ê·¼ì°¨ê·¼ ë°©í–¥ì„ ì°¾ì•„ë‚˜ê°€ë©´ ë¶„ëª… ì¢‹ì€ ê²°ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.  
ìš°ì„ , ìš°ë¦¬ ì œí’ˆì´ ê³ ê°ì—ê²Œ ì£¼ëŠ” **í•µì‹¬ ê°€ì¹˜**ë¥¼ ëª…í™•íˆ ì •ì˜í•˜ê³  ê·¸ ê°€ì¹˜ë¥¼ ê³ ê°ì˜ ì–¸ì–´ë¡œ í‘œí˜„í•´ë³´ëŠ” ì—°ìŠµë¶€í„° í•´ë³´ì‹œë©´ ì¢‹ê² ì–´ìš”.  
í˜¹ì‹œ **í˜„ì¬ ì–´ë–¤ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ í™ë³´í•˜ê³  ê³„ì‹ ì§€**, ê·¸ë¦¬ê³  **ì–´ë–¤ ê³ ê°ì¸µì„ ì£¼ìš” íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •í•˜ê³  ìˆëŠ”ì§€** ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
"""

        # ğŸ†• ê°œì„ ëœ ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì¹œë°€ê° ê°•í™”) - ë°±ì—…ìš©
        self.enhanced_response_prompt = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê³  ê°œì¸ì ì¸ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©° ë„ì›€ì„ ì£¼ì„¸ìš”.

## ì¹œë°€ê° ê°•í™” ê°€ì´ë“œë¼ì¸:
1. **ê°œì¸ì  ê²½í—˜ ê³µìœ **: "ì €ë„ ë¹„ìŠ·í•œ ê²½í—˜ì´ ìˆì–´ì„œ ì´í•´í•´ìš”"
2. **ê³µê°ì  í‘œí˜„**: "ì •ë§ ì–´ë ¤ìš°ì‹œê² ì–´ìš”", "ê·¸ëŸ° ê³ ë¯¼ ë§ì´ í•˜ì‹œì£ "
3. **ê²©ë ¤ì™€ ì§€ì§€**: "ì¶©ë¶„íˆ ê°€ëŠ¥í•˜ì„¸ìš”", "ì˜ í•˜ê³  ê³„ì‹œëŠ” ê²ƒ ê°™ì•„ìš”"
4. **ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬**: ë”±ë”±í•œ í‘œí˜„ë³´ë‹¤ëŠ” ì¼ìƒì ì´ê³  í¸ì•ˆí•œ ë§íˆ¬
5. **ë§ì¶¤í˜• í˜¸ì¹­**: ìƒí™©ì— ë”°ë¼ "ì‚¬ì¥ë‹˜", "ëŒ€í‘œë‹˜", "í¬ë¦¬ì—ì´í„°ë‹˜" ë“±

## í†¤ ë‹¤ì–‘ì„±:
- **ê²©ë ¤í˜•**: "ì •ë§ ì¢‹ì€ ì•„ì´ë””ì–´ë„¤ìš”! ì´ëŸ° ì ì´ íŠ¹íˆ ì¸ìƒì ì´ì—ìš”..."
- **ê³µê°í˜•**: "ì•„, ê·¸ëŸ° ì–´ë ¤ì›€ì´ ìˆìœ¼ì…¨êµ°ìš”. ë§ì€ ë¶„ë“¤ì´ ë¹„ìŠ·í•˜ê²Œ ê²ªìœ¼ì‹œëŠ” ë¶€ë¶„ì´ì—ìš”..."
- **ì „ë¬¸ê°€í˜•**: "ì—…ê³„ ê²½í—˜ìƒ ì´ëŸ° ê²½ìš°ì—ëŠ”..."
- **ì¹œêµ¬í˜•**: "ê°œì¸ì ìœ¼ë¡œ ì¶”ì²œë“œë¦¬ê³  ì‹¶ì€ ê±´..."

## ì‘ë‹µ êµ¬ì¡°:
1. **ê³µê°/ì¸ì‚¬**: ì‚¬ìš©ì ìƒí™©ì— ëŒ€í•œ ì´í•´ì™€ ê³µê°
2. **ê°œì¸í™”ëœ ì¡°ì–¸**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ í™œìš©í•œ ë§ì¶¤í˜• ì œì•ˆ
3. **êµ¬ì²´ì  ë°©ë²•**: ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œ
4. **ê²©ë ¤ì™€ ë™í–‰**: í•¨ê»˜ í•´ê²°í•´ë‚˜ê°„ë‹¤ëŠ” ëŠë‚Œ

ë§¤ë²ˆ ë‹¤ë¥¸ í‘œí˜„ê³¼ ì ‘ê·¼ìœ¼ë¡œ ì‘ë‹µí•˜ë˜, í•­ìƒ ë”°ëœ»í•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•´ì£¼ì„¸ìš”."""

        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ë“¤ (ê°œì„ )
        self.intent_analysis_prompt = """ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ìƒë‹´ì—ì„œ ì‚¬ìš©ìì˜ ì˜ë„ì™€ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•íƒœë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{
    "intent": {
        "primary": "ì •ë³´_ìš”ì²­|ëª©í‘œ_ì„¤ì •|íƒ€ê²Ÿ_ë¶„ì„|ì „ëµ_ê¸°íš|ì½˜í…ì¸ _ìƒì„±|ì½˜í…ì¸ _ìˆ˜ì •|ì¼ë°˜_ì§ˆë¬¸",
        "confidence": 0.0-1.0,
        "description": "ì˜ë„ ì„¤ëª…",
        "topic":"blog_marketing|content_marketing|conversion_optimization|digital_advertising|email_marketing|influencer_marketing|local_marketing|marketing_automation|marketing_fundamentals|marketing_metrics|personal_branding|social_media_marketing|viral_marketing"
    },
    "extracted_info": {
        "business_type": "ì¶”ì¶œëœ ì—…ì¢… (ì—†ìœ¼ë©´ null)",
        "product": "íŒë§¤ ì œí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´ (ì—†ìœ¼ë©´ null)",
        "main_goal": "ì£¼ìš” ëª©í‘œ (ì—†ìœ¼ë©´ null)",
        "target_audience": "íƒ€ê²Ÿ ê³ ê° ì •ë³´ (ì—†ìœ¼ë©´ null)",
        "budget": "ì˜ˆì‚° ì •ë³´ (ì—†ìœ¼ë©´ null)",
        "channels": "ì„ í˜¸ ì±„ë„ (ì—†ìœ¼ë©´ null)",
        "pain_points": "ê³ ë¯¼ê±°ë¦¬ (ì—†ìœ¼ë©´ null)"
    },
    "stage_assessment": {
        "current_stage_complete": true/false,
        "ready_for_next": true/false,
        "suggested_next_stage": "initial|goal|target|strategy|execution|content_creation|completed"
    },
    "content_intent": {
        "is_content_request": true/false,
        "content_type": "instagram|blog|strategy|campaign"
    },
    "user_sentiment": {
        "engagement_level": "high|medium|low",
        "frustration_level": "none|low|medium|high",
        "needs_encouragement": true/false
    }
}"""

        # ğŸ†• ì»¨í…ì¸  í”¼ë“œë°± ë¶„ì„ í”„ë¡¬í”„íŠ¸  
        self.content_feedback_prompt = """ë‹¹ì‹ ì€ ë§ˆì¼€íŒ… ì½˜í…ì¸  í”¼ë“œë°± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì½˜í…ì¸  ê´€ë ¨ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

{
    "request_type": "modify|regenerate|new_content|feedback|approval",
    "specific_changes": ["êµ¬ì²´ì ì¸ ìˆ˜ì • ìš”ì²­ë“¤"],
    "content_direction": {
        "tone": "ë³€ê²½í•˜ê³ ì í•˜ëŠ” í†¤ì•¤ë§¤ë„ˆ",
        "style": "ë³€ê²½í•˜ê³ ì í•˜ëŠ” ìŠ¤íƒ€ì¼",
        "length": "ê¸¸ì´ ì¡°ì • ìš”ì²­",
        "focus": "ì§‘ì¤‘í•˜ê³ ì í•˜ëŠ” í¬ì¸íŠ¸"
    },
    "action_needed": {
        "type": "revise_content|create_new|provide_feedback|end_session",
        "priority": "high|medium|low"
    }
}

ì‚¬ìš©ìê°€ ë§Œì¡±í•˜ë©´ ì„¸ì…˜ì„ ì¢…ë£Œí•˜ê³ , ìˆ˜ì • ìš”ì²­ì´ ìˆìœ¼ë©´ êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ì„ ì œì‹œí•´ì£¼ì„¸ìš”."""
    
    async def _call_llm(self, prompt: str, user_input: str, context: str = "") -> Dict[str, Any]:
        """LLM í˜¸ì¶œ ë° ì‘ë‹µ íŒŒì‹±"""
        try:
            full_prompt = f"""
{prompt}

í˜„ì¬ ìƒí™©:
{context}

ì‚¬ìš©ì ì…ë ¥:
"{user_input}"
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": full_prompt}
                ],
                temperature=self.temperature,
                max_tokens=1500
            )
            
            content = response.choices[0].message.content
            
            try:
                # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
                if "```json" in content:
                    json_start = content.find("```json") + 7
                    json_end = content.find("```", json_start)
                    json_content = content[json_start:json_end].strip()
                elif "{" in content and "}" in content:
                    json_start = content.find("{")
                    json_end = content.rfind("}") + 1
                    json_content = content[json_start:json_end]
                else:
                    return {"raw_response": content}
                
                return json.loads(json_content)
                
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜
                return {"raw_response": content}
                
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    # ğŸ†• ë¶€ì •ì  ì‘ë‹µ ê°ì§€
    async def detect_negative_response(self, user_input: str, conversation: ConversationState) -> Dict[str, Any]:
        """ë¶€ì •ì  ì‘ë‹µ ê°ì§€"""
        context = f"""
        í˜„ì¬ ëŒ€í™” ëª¨ë“œ: {conversation.current_mode.value}
        ë¶€ì •ì  ì‘ë‹µ íšŸìˆ˜: {conversation.negative_response_count}
        ì‚¬ìš©ì ì°¸ì—¬ë„: {conversation.user_engagement_level}
        """
        
        result = await self._call_llm(self.negative_response_detection_prompt, user_input, context)
        
        if "error" in result:
            return {"is_negative": False, "type": "neutral", "confidence": 0.0}
        
        return result
    
    # ğŸ†• ì‹±ê¸€í„´ ì™„ë£Œ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
    async def can_complete_as_singleton(self, user_input: str, conversation: ConversationState) -> bool:
        """ì‹±ê¸€í„´ìœ¼ë¡œ ì™„ë£Œ ê°€ëŠ¥í•œì§€ íŒë‹¨"""
        context = f"""
        í˜„ì¬ ë‹¨ê³„: {conversation.current_stage.value}
        ìˆ˜ì§‘ëœ ì •ë³´ ìˆ˜: {len(conversation.collected_info)}
        ì™„ë£Œìœ¨: {conversation.get_completion_rate():.1%}
        """
        
        result = await self._call_llm(self.singleton_completion_prompt, user_input, context)
        
        if "error" in result:
            return False
        
        return result.get("can_complete_as_singleton", False)
    
    # ğŸ†• ì œì•ˆ ëª¨ë“œ ì‘ë‹µ ìƒì„±
    async def generate_suggestion_response(self, user_input: str, conversation: ConversationState) -> str:
        """ì œì•ˆ ëª¨ë“œ ì‘ë‹µ ìƒì„± - ì§ˆë¬¸ ëŒ€ì‹  ì§ì ‘ ì œì•ˆ"""
        context = f"""
        ì—…ì¢…: {conversation.business_type}
        ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(conversation.collected_info, ensure_ascii=False)}
        ë¶€ì •ì  ì‘ë‹µ: {conversation.last_negative_response}
        ì‚¬ìš©ì ì°¸ì—¬ë„: {conversation.user_engagement_level}
        
        ëŒ€í™” íˆìŠ¤í† ë¦¬:
        {conversation.get_conversation_context()}
        """
        
        result = await self._call_llm(self.suggestion_mode_prompt, user_input, context)
        
        if "error" in result:
            # ê¸°ë³¸ ì œì•ˆ ë©”ì‹œì§€ (LLM ìƒì„±)
            fallback_prompt = f"""ì‚¬ìš©ìê°€ "{user_input}"ë¼ê³  í–ˆì„ ë•Œ, ë§ˆì¼€íŒ… ì „ë¬¸ê°€ë¡œì„œ ì¹œê·¼í•˜ê²Œ ë„ì›€ì„ ì£¼ëŠ” ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”. 
            ì§ˆë¬¸í•˜ì§€ ë§ê³  ì§ì ‘ì ì¸ ì¡°ì–¸ê³¼ ì œì•ˆì„ í•´ì£¼ì„¸ìš”."""
            
            fallback_result = await self._call_llm(fallback_prompt, "", "")
            return fallback_result.get("raw_response", "ê·¸ë ‡ë‹¤ë©´ ì œê°€ ëª‡ ê°€ì§€ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ë“œë¦´ê²Œìš”!")
        
        return result.get("raw_response", result.get("response", ""))
    
    # ğŸ†• ì¦‰ì‹œ ì¶”ì²œ ìƒì„±
    async def generate_instant_recommendations(self, conversation: ConversationState) -> str:
        """ìˆ˜ì§‘ëœ ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ì¦‰ì‹œ ì¶”ì²œ ìƒì„±"""
        context_info = "\n".join(
            [f"- {key}: {info['value']}" for key, info in conversation.collected_info.items()]
        )

        prompt = f"""
        ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ê²½í—˜ì´ í’ë¶€í•œ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.

        [ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½]
        ì—…ì¢…: {conversation.business_type}
        ì™„ë£Œìœ¨: {conversation.get_completion_rate():.1%}

        [ìˆ˜ì§‘ëœ ì •ë³´]
        {context_info}

        ìœ„ ì •ë³´ë¥¼ ìµœëŒ€í•œ ë°˜ì˜í•˜ì—¬, **ì§€ê¸ˆ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ë§ˆì¼€íŒ… ì „ëµê³¼ íŒ**ì„ ì‘ì„±í•˜ì„¸ìš”.
        - ê¸€ì€ ì¸ì‚¿ë§ ì—†ì´ ë³¸ë¬¸ìœ¼ë¡œ ì‹œì‘
        - ê° í•­ëª©ì€ ê°„ê²°í•˜ê²Œ, ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ìƒëµ
        - ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥´ë˜ ë„ˆë¬´ ë”±ë”±í•˜ì§€ ì•Šê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±:
        1. ì¦‰ì‹œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ë§ˆì¼€íŒ… ë°©ë²• 3ê°€ì§€
        2. ì˜ˆìƒ íš¨ê³¼ì™€ ì‹œì‘ ë°©ë²•
        3. ì„±ê³µì„ ìœ„í•œ í•µì‹¬ íŒ
        4. ë§ˆì§€ë§‰ ë¬¸ë‹¨ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§ˆ í›„ì† ì§ˆë¬¸ 1~2ê°œ í¬í•¨
        - ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ ìœ ì§€
        """
        
        result = await self._call_llm(prompt, "", "")
        return result.get("raw_response", "ì§€ê¸ˆê¹Œì§€ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì „ëµì„ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!")
    
    # ğŸ†• êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± ë©”ì„œë“œ
    async def generate_structured_response(self, user_input: str, conversation: ConversationState) -> Dict[str, Any]:
        """
        êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± - ë©”ì¸ ì‘ë‹µ + í›„ì† ì§ˆë¬¸ + í–‰ë™ ì œì•ˆ
        """
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            missing_info_analysis = conversation.get_context_based_missing_info()
            context = f"""
            í˜„ì¬ ë§ˆì¼€íŒ… ë‹¨ê³„: {conversation.current_stage.value}
            ëŒ€í™” ëª¨ë“œ: {conversation.current_mode.value}
            ì™„ë£Œìœ¨: {conversation.get_completion_rate():.1%}
            ë¶€ì¡±í•œ ì •ë³´ ë¶„ì„: {json.dumps(missing_info_analysis, ensure_ascii=False)}
            ì‚¬ìš©ì ì°¸ì—¬ë„: {conversation.user_engagement_level}
            ì—…ì¢…: {conversation.business_type}
            
            ìˆ˜ì§‘ëœ ì •ë³´:
            {json.dumps(conversation.collected_info, ensure_ascii=False)}
            
            ìµœê·¼ ëŒ€í™” íë¦„:
            {conversation.get_conversation_context()}
            """

            result = await self._call_llm(self.structured_response_prompt, user_input, context)
            return result.get("raw_response", "ì‘ë‹µ ì—†ìŒ")

        except Exception as e:
            self.logger.error(f"[{conversation.conversation_id}] êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return {
                "main_response": "ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "follow_up_questions": [],
                "suggested_actions": [],
                "conversation_direction": "continue_info_gathering"
            }

    
    async def _generate_fallback_follow_up_questions(self, conversation: ConversationState) -> List[str]:
        """ë°±ì—… í›„ì† ì§ˆë¬¸ ìƒì„±"""
        missing_info_analysis = conversation.get_context_based_missing_info()
        priority_missing = missing_info_analysis["priority_missing"]
        
        # ë‹¨ê³„ë³„ ê¸°ë³¸ í›„ì† ì§ˆë¬¸
        stage_questions = {
            MarketingStage.GOAL: [
                "ì–´ë–¤ ê²°ê³¼ë¥¼ ê°€ì¥ ë¹ ë¥´ê²Œ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                "í˜„ì¬ ê°€ì¥ í° ë§ˆì¼€íŒ… ê³ ë¯¼ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì„±ê³µì˜ ê¸°ì¤€ì„ ì–´ë–»ê²Œ ì •ì˜í•˜ì‹œë‚˜ìš”?"
            ],
            MarketingStage.TARGET: [
                "ì£¼ìš” ê³ ê°ì¸µì˜ ì—°ë ¹ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?",
                "ê³ ê°ë“¤ì´ ì£¼ë¡œ ì–´ë–¤ ì±„ë„ì„ ì´ìš©í•˜ë‚˜ìš”?",
                "ê³ ê°ë“¤ì´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê°€ì¹˜ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"
            ],
            MarketingStage.STRATEGY: [
                "ì›” ë§ˆì¼€íŒ… ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ ê³„íší•˜ê³  ê³„ì‹ ê°€ìš”?",
                "ì–´ë–¤ ë§ˆì¼€íŒ… ì±„ë„ì— ê°€ì¥ ê´€ì‹¬ì´ ìˆìœ¼ì‹ ê°€ìš”?",
                "ê²½ìŸì‚¬ë“¤ì€ ì–´ë–¤ ì „ëµì„ ì‚¬ìš©í•˜ê³  ìˆë‚˜ìš”?"
            ],
            MarketingStage.EXECUTION: [
                "ì–¸ì œë¶€í„° ë§ˆì¼€íŒ…ì„ ì‹œì‘í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                "í˜„ì¬ ìš´ì˜í•˜ê³  ìˆëŠ” ì˜¨ë¼ì¸ ì±„ë„ì´ ìˆë‚˜ìš”?",
                "ë§ˆì¼€íŒ… ë‹´ë‹¹ìê°€ ë”°ë¡œ ìˆìœ¼ì‹ ê°€ìš”?"
            ]
        }
        
        default_questions = stage_questions.get(conversation.current_stage, [
            "ë” ìì„¸íˆ ì•Œê³  ì‹¶ì€ ë¶€ë¶„ì´ ìˆìœ¼ì‹ ê°€ìš”?",
            "ì–´ë–¤ ë„ì›€ì´ ê°€ì¥ í•„ìš”í•˜ì‹ ê°€ìš”?",
            "ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì€ ì—†ìœ¼ì‹ ê°€ìš”?"
        ])
        
        return default_questions[:3]  # ìµœëŒ€ 3ê°œ
    
    async def _generate_fallback_actions(self, conversation: ConversationState) -> List[str]:
        """ë°±ì—… ì¶”ì²œ ì•¡ì…˜ ìƒì„±"""
        if conversation.current_stage == MarketingStage.GOAL:
            return [
                "ë§ˆì¼€íŒ… ëª©í‘œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì •ì˜í•´ë³´ê¸°",
                "íƒ€ê²Ÿ ê³ ê° í˜ë¥´ì†Œë‚˜ ë§Œë“¤ì–´ë³´ê¸°"
            ]
        elif conversation.current_stage == MarketingStage.TARGET:
            return [
                "ê³ ê° ì„¤ë¬¸ì¡°ì‚¬ ì§„í–‰í•´ë³´ê¸°",
                "ê²½ìŸì‚¬ ë¶„ì„ ì‹œì‘í•˜ê¸°"
            ]
        elif conversation.current_stage == MarketingStage.STRATEGY:
            return [
                "ë§ˆì¼€íŒ… ì˜ˆì‚° ê³„íš ì„¸ìš°ê¸°",
                "ì±„ë„ë³„ ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°"
            ]
        else:
            return [
                "ì²« ë²ˆì§¸ ë§ˆì¼€íŒ… ìº í˜ì¸ ê¸°íší•˜ê¸°",
                "ì„±ê³¼ ì¸¡ì • ë°©ë²• ì •í•˜ê¸°"
            ]

    # ğŸ†• ê°œì„ ëœ ë©”ì¸ ì‘ë‹µ ìƒì„± ë©”ì„œë“œ
    async def generate_response_with_context(self, user_input: str, conversation: ConversationState) -> str:
        """ğŸ†• ê°œì„ ëœ ë§¥ë½ì  ì‘ë‹µ ìƒì„± - ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ì¹œë°€ê° ê°•í™”"""
        conversation.add_message("user", user_input)
        logger.info(f"[{conversation.conversation_id}] ì‚¬ìš©ì ì…ë ¥: {user_input}")

        try:
            # ğŸ†• í¬ìŠ¤íŒ… ê´€ë ¨ ì‘ë‹µ ì²˜ë¦¬ ìš°ì„ 
            if conversation.is_awaiting_posting_response():
                return await self._handle_posting_response(user_input, conversation)
            
            # ğŸ†• ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì¤‘ì¸ì§€ í™•ì¸
            if conversation.is_in_content_creation():
                return await self._handle_content_creation_session(user_input, conversation)
            
            # # ğŸ†• 1. ì‹±ê¸€í„´ ì™„ë£Œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            # if await self.can_complete_as_singleton(user_input, conversation):
            #     # ì¦‰ì‹œ ì™„ë£Œ ê°€ëŠ¥í•œ ê²½ìš° ë°”ë¡œ ì‘ë‹µ ìƒì„±
            #     response = await self.generate_enhanced_response(user_input, conversation, is_singleton=True)
            #     conversation.add_message("assistant", response)
            #     return response
            
            # ğŸ†• 2. ë¶€ì •ì  ì‘ë‹µ ê°ì§€
            negative_analysis = await self.detect_negative_response(user_input, conversation)
            if negative_analysis.get("is_negative", False):
                print("ë¶€ì •ì  ì‘ë‹µ ê°ì§€")
                conversation.record_negative_response(user_input)
                
                # ì œì•ˆ ëª¨ë“œë¡œ ì „í™˜
                if conversation.should_switch_to_suggestion_mode():
                    conversation.switch_to_suggestion_mode()
                    
                    # ì œì•ˆ ëª¨ë“œ ì‘ë‹µ ìƒì„±
                    if conversation.has_sufficient_info_for_suggestions():
                        response = await self.generate_instant_recommendations(conversation)
                    else:
                        response = await self.generate_suggestion_response(user_input, conversation)
                    
                    conversation.add_message("assistant", response)
                    return response
            else:
                # ê¸ì •ì  ì‘ë‹µì´ë©´ ì¹´ìš´í„° ë¦¬ì…‹
                conversation.reset_negative_responses()
            
            # 3. ì‚¬ìš©ì ì˜ë„ ë¶„ì„
            intent_analysis = await self.analyze_user_intent_with_llm(user_input, conversation)
            logger.info(f"[{conversation.conversation_id}] ì˜ë„ ë¶„ì„: {intent_analysis.get('intent', {}).get('primary', 'unknown')}")

            # ì¶”ì¶œëœ ì •ë³´ ì €ì¥
            extracted_info = intent_analysis.get("extracted_info", {})
            for key, value in extracted_info.items():
                if value:
                    conversation.add_info(key, value, "llm_extracted")
                    if key == "business_type" and value != "ì¼ë°˜":
                        conversation.business_type = value
      
            primary_intent = intent_analysis.get('intent', {}).get('primary', '')
            topic = intent_analysis.get('intent', {}).get('topic', '')
            print ("primary_intent:"+primary_intent)
            print ("topic:"+topic)
            print(f"extracted_info:{extracted_info}")     
            
            # ğŸ†• 4. ì»¨í…ì¸  ìƒì„± ìš”ì²­ ê°ì§€
            content_intent = intent_analysis.get("content_intent", {})
            has_basic_info = (conversation.business_type and conversation.business_type != "ì¼ë°˜") or conversation.get_info('product') or conversation.get_info('business_type')
            has_keywords_or_trends = conversation.get_info('keywords') or conversation.get_info('trend_data')
            
            if content_intent.get("is_content_request") and (has_basic_info or has_keywords_or_trends):
                print("ì»¨í…ì¸ ìƒì„±ìš”ì²­")
                conversation.current_stage = MarketingStage.CONTENT_CREATION
                conversation.start_content_session(
                    content_intent.get("content_type", "general"),
                    user_input
                )
                return "TRIGGER_CONTENT_GENERATION"

            # # ğŸ†• 5. ì œì•ˆ ëª¨ë“œì¸ ê²½ìš° ì§ˆë¬¸ ëŒ€ì‹  ì œì•ˆ ìƒì„±
            # if conversation.current_mode == ConversationMode.SUGGESTING:
            #     response = await self.generate_instant_recommendations(conversation)
            #     conversation.add_message("assistant", response)
            #     return response
            
            # 6. ì¼ë°˜ì ì¸ ê°œì„ ëœ ì‘ë‹µ ìƒì„±
            # ğŸ†• êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
            if conversation.get_completion_rate() > 0.3:
                print("ì¦‰ì‹œì œì•ˆ")
                conversation.switch_to_suggestion_mode()
                response = await self.generate_instant_recommendations(conversation)
                conversation.add_message("assistant", response)
                return response
            else:
                print("ì¼ë°˜")
                # êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„± (ë©”ì¸ ì‘ë‹µ + í›„ì† ì§ˆë¬¸)
                structured_response = await self.generate_structured_response(user_input, conversation)
                conversation.add_message("assistant", structured_response)
                return f"STRUCTURED_RESPONSE:{structured_response}"

        except Exception as e:
            logger.error(f"[{conversation.conversation_id}] ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            # ì˜¤ë¥˜ ì‹œì—ë„ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±
            error_prompt = "ì‚¬ìš©ìì™€ì˜ ëŒ€í™” ì¤‘ ê¸°ìˆ ì  ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•Œ ì¹œê·¼í•˜ê²Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
            error_result = await self._call_llm(error_prompt, "", "")
            return error_result.get("raw_response", "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ ë¬¸ì œê°€ ë°œìƒí–ˆë„¤ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!")
    
    # ğŸ†• ê°œì„ ëœ ì‘ë‹µ ìƒì„± (ì¹œë°€ê° ê°•í™”)
    async def generate_enhanced_response(self, user_input: str, conversation: ConversationState, 
                                       topic: str = "", is_singleton: bool = False) -> str:
        """ì¹œë°€ê°ê³¼ ê°œì¸í™”ê°€ ê°•í™”ëœ ì‘ë‹µ ìƒì„±"""
        context = f"""
        ì—…ì¢…: {conversation.business_type}
        ì™„ë£Œìœ¨: {conversation.get_completion_rate():.1%}
        ì°¸ì—¬ë„: {conversation.user_engagement_level}
        ìˆ˜ì§‘ëœ ì •ë³´: {json.dumps(conversation.collected_info, ensure_ascii=False)}
        ì‹±ê¸€í„´ ì™„ë£Œ: {is_singleton}
        í† í”½: {topic}
        
        ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:
        {conversation.get_conversation_context()}
        """
        
        result = await self._call_llm(self.enhanced_response_prompt, user_input, context)
        return result.get("raw_response", result.get("response", ""))
    
    
    # í¬ìŠ¤íŒ… ë° ì»¨í…ì¸  ì„¸ì…˜ ê´€ë ¨ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€í•˜ë˜ LLM ê¸°ë°˜ìœ¼ë¡œ ê°œì„ )
    async def _handle_posting_response(self, user_input: str, conversation: ConversationState) -> str:
        """í¬ìŠ¤íŒ… ê´€ë ¨ ì‘ë‹µ ì²˜ë¦¬ - LLM ê¸°ë°˜"""
        user_input_lower = user_input.lower().strip()
        
        if conversation.awaiting_posting_confirmation:
            if any(word in user_input_lower for word in ["ë„¤", "ì˜ˆ", "í¬ìŠ¤íŒ…", "posting", "ì—…ë¡œë“œ", "ê²Œì‹œ"]):
                conversation.confirm_posting_and_request_schedule()
                
                # LLMìœ¼ë¡œ ìŠ¤ì¼€ì¤„ ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
                prompt = "ì‚¬ìš©ìê°€ í¬ìŠ¤íŒ…ì„ í™•ì¸í–ˆì„ ë•Œ, ì¹œê·¼í•˜ê²Œ ì–¸ì œ í¬ìŠ¤íŒ…í• ì§€ ì‹œê°„ì„ ë¬¼ì–´ë³´ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë‹¤ì–‘í•œ ì‹œê°„ ì…ë ¥ ì˜ˆì‹œë„ í¬í•¨í•´ì£¼ì„¸ìš”."
                result = await self._call_llm(prompt, "", "")
                return result.get("raw_response", "í¬ìŠ¤íŒ… ì¼ì •ì„ ì•Œë ¤ì£¼ì„¸ìš”!")
            else:
                conversation.cancel_posting_process()
                conversation.end_content_session()
                conversation.current_stage = MarketingStage.COMPLETED
                
                # LLMìœ¼ë¡œ ì™„ë£Œ ë©”ì‹œì§€ ìƒì„±
                prompt = "í¬ìŠ¤íŒ…ì„ ì·¨ì†Œí–ˆì„ ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ ì»¨í…ì¸  ì œì‘ ì™„ë£Œë¥¼ ì•Œë¦¬ê³  ì¶”ê°€ ë„ì›€ì„ ì œì•ˆí•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                result = await self._call_llm(prompt, "", "")
                return result.get("raw_response", "ì»¨í…ì¸  ì œì‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        elif conversation.awaiting_scheduling_time:
            try:
                scheduled_at = await self._parse_schedule_time(user_input)
                
                if scheduled_at:
                    return f"TRIGGER_AUTOMATION_TASK:{scheduled_at.isoformat()}|ìë™í™” ì˜ˆì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
                else:
                    # LLMìœ¼ë¡œ ì‹œê°„ ì¬ì…ë ¥ ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
                    prompt = "ì‹œê°„ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ì„ ë•Œ ì¹œê·¼í•˜ê²Œ ë‹¤ì‹œ ì…ë ¥ì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                    result = await self._call_llm(prompt, "", "")
                    return result.get("raw_response", "ì‹œê°„ í˜•ì‹ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                logger.error(f"ìŠ¤ì¼€ì¤„ íŒŒì‹± ì˜¤ë¥˜: {e}")
                prompt = "ì‹œê°„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì‚¬ê³¼í•˜ê³  ë‹¤ì‹œ ì‹œë„ë¥¼ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                result = await self._call_llm(prompt, "", "")
                return result.get("raw_response", "ì‹œê°„ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        return "ì˜ˆìƒì¹˜ ëª»í•œ í¬ìŠ¤íŒ… ìƒíƒœì…ë‹ˆë‹¤."
    
    async def _handle_content_creation_session(self, user_input: str, conversation: ConversationState, is_initial: bool = False) -> str:
        """ì»¨í…ì¸  ì œì‘ ì„¸ì…˜ ì²˜ë¦¬ - LLM ê¸°ë°˜"""
        if is_initial:
            # LLMìœ¼ë¡œ ì»¨í…ì¸  ì œì‘ ì‹œì‘ ë©”ì‹œì§€ ìƒì„±
            prompt = "ì»¨í…ì¸  ì œì‘ì„ ì‹œì‘í•œë‹¤ëŠ” ê²ƒì„ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì•Œë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
            result = await self._call_llm(prompt, "", "")
            return result.get("raw_response", "ì»¨í…ì¸  ì œì‘ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        else:
            # í”¼ë“œë°± ì²˜ë¦¬
            feedback_analysis = await self.handle_content_feedback_with_llm(user_input, conversation)
            
            request_type = feedback_analysis.get("request_type", "feedback")
            
            if request_type == "modify":
                # LLMìœ¼ë¡œ ìˆ˜ì • ë©”ì‹œì§€ ìƒì„±
                prompt = "ì‚¬ìš©ìê°€ ì»¨í…ì¸  ìˆ˜ì •ì„ ìš”ì²­í–ˆì„ ë•Œ ì¹œê·¼í•˜ê²Œ ìˆ˜ì •í•˜ê² ë‹¤ê³  ì•Œë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                result = await self._call_llm(prompt, "", "")
                conversation.update_content_session("ìˆ˜ì • ì¤‘...", user_input)
                return "TRIGGER_CONTENT_MODIFICATION:" + result.get("raw_response", "ì»¨í…ì¸ ë¥¼ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤!")
                
            elif request_type == "regenerate":
                prompt = "ìƒˆë¡œìš´ ì»¨í…ì¸ ë¥¼ ìƒì„±í•˜ê² ë‹¤ê³  ì¹œê·¼í•˜ê²Œ ì•Œë¦¬ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                result = await self._call_llm(prompt, "", "")
                conversation.update_content_session("ì¬ìƒì„± ì¤‘...", user_input)
                return "TRIGGER_CONTENT_REGENERATION:" + result.get("raw_response", "ìƒˆë¡œìš´ ì»¨í…ì¸ ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤!")
                
            elif request_type == "approval":
                if conversation.current_content_for_posting:
                    # LLMìœ¼ë¡œ í¬ìŠ¤íŒ… í™•ì¸ ë©”ì‹œì§€ ìƒì„±
                    prompt = "ì‚¬ìš©ìê°€ ì»¨í…ì¸ ë¥¼ ë§ˆìŒì— ë“¤ì–´í•  ë•Œ í¬ìŠ¤íŒ… ì—¬ë¶€ë¥¼ ì¹œê·¼í•˜ê²Œ ë¬»ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                    result = await self._call_llm(prompt, "", "")
                    conversation.start_posting_confirmation(conversation.current_content_for_posting)
                    return result.get("raw_response", "í¬ìŠ¤íŒ…í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                else:
                    # LLMìœ¼ë¡œ ì™„ë£Œ ë©”ì‹œì§€ ìƒì„±
                    prompt = "ì»¨í…ì¸  ì œì‘ì´ ì™„ë£Œë˜ì—ˆì„ ë•Œ ì¶”ê°€ ë„ì›€ì„ ì œì•ˆí•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                    result = await self._call_llm(prompt, "", "")
                    conversation.end_content_session()
                    conversation.current_stage = MarketingStage.COMPLETED
                    return result.get("raw_response", "ì»¨í…ì¸  ì œì‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                # LLMìœ¼ë¡œ í”¼ë“œë°± ìš”ì²­ ë©”ì‹œì§€ ìƒì„±
                prompt = "ì‚¬ìš©ìì˜ í”¼ë“œë°±ì— ê°ì‚¬ë¥¼ í‘œí•˜ê³  ë” êµ¬ì²´ì ì¸ ìˆ˜ì • ë°©í–¥ì„ ë¬»ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
                result = await self._call_llm(prompt, "", "")
                return result.get("raw_response", "í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤!")
    
    # ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€...
    async def analyze_user_intent_with_llm(self, user_input: str, conversation: ConversationState) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        context = f"""
        í˜„ì¬ ë‹¨ê³„: {conversation.current_stage.value}
        í˜„ì¬ ëª¨ë“œ: {conversation.current_mode.value}
        ì—…ì¢…: {conversation.business_type}
        ì™„ë£Œìœ¨: {conversation.get_completion_rate():.1%}
        ì‚¬ìš©ì ì°¸ì—¬ë„: {conversation.user_engagement_level}
        ì»¨í…ì¸  ì„¸ì…˜ í™œì„±: {conversation.is_in_content_creation()}
        ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:
        {conversation.get_conversation_context()}
        """
        
        result = await self._call_llm(self.intent_analysis_prompt, user_input, context)
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if "error" in result:
            return {
                "intent": {"primary": "ì¼ë°˜_ì§ˆë¬¸", "confidence": 0.5},
                "extracted_info": {},
                "stage_assessment": {"current_stage_complete": False, "ready_for_next": False},
                "content_intent": {"is_content_request": False, "content_type": ""},
                "user_sentiment": {"engagement_level": "medium", "frustration_level": "none", "needs_encouragement": False}
            }
        
        return result

    async def handle_content_feedback_with_llm(self, user_input: str, conversation: ConversationState) -> Dict[str, Any]:
        """ì»¨í…ì¸  í”¼ë“œë°± ì²˜ë¦¬"""
        context = f"""
        í˜„ì¬ ì»¨í…ì¸  ì„¸ì…˜: {conversation.current_content_session}
        ì´ì „ ì»¨í…ì¸ : {conversation.current_content_session.get('last_content', '') if conversation.current_content_session else ''}
        ë°˜ë³µ íšŸìˆ˜: {conversation.current_content_session.get('iteration_count', 0) if conversation.current_content_session else 0}
        """
        
        result = await self._call_llm(self.content_feedback_prompt, user_input, context)
        
        if "error" in result:
            return {
                "request_type": "feedback",
                "specific_changes": [],
                "content_direction": {},
                "action_needed": {"type": "provide_feedback", "priority": "medium"}
            }
        
        return result

    async def _parse_schedule_time(self, user_input: str) -> Optional[datetime]:
        """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì‹œê°„ íŒŒì‹± - LLM ê¸°ë°˜"""
        user_input_lower = user_input.lower().strip()
        
        # ì§€ê¸ˆ ë°”ë¡œ
        if any(word in user_input_lower for word in ["ì§€ê¸ˆ", "ë°”ë¡œ", "now", "immediately"]):
            return datetime.now()
        
        # LLMì„ ì‚¬ìš©í•œ ì‹œê°„ íŒŒì‹±
        try:
            time_parsing_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë‚ ì§œì™€ ì‹œê°„ì„ ì¶”ì¶œí•˜ì—¬ ISO 8601 í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
            
ì‚¬ìš©ì ì…ë ¥: "{user_input}"
í˜„ì¬ ì‹œê°„: {datetime.now().isoformat()}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
- ì„±ê³µ: "2024-01-15T14:30:00" (ì •í™•í•œ ISO 8601 í˜•ì‹)
- ì‹¤íŒ¨: "INVALID"

ì¶”ê°€ ì„¤ëª… ì—†ì´ ì˜¤ì§ ë‚ ì§œ/ì‹œê°„ ë˜ëŠ” "INVALID"ë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
            
            result = await self._call_llm("ë‹¹ì‹ ì€ ì‹œê°„ íŒŒì‹± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.", time_parsing_prompt)
            
            if isinstance(result, dict) and "raw_response" in result:
                time_str = result["raw_response"].strip()
            else:
                time_str = str(result).strip()
            
            if time_str != "INVALID" and "T" in time_str:
                return datetime.fromisoformat(time_str.replace("Z", "+00:00"))
                
        except Exception as e:
            logger.warning(f"ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return None
    
    # ëŒ€í™” ê´€ë¦¬ ê´€ë ¨ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€)
    def get_or_create_conversation(self, user_id: int, conversation_id: Optional[int] = None) -> Tuple[ConversationState, bool]:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ ë˜ëŠ” ìƒì„±"""
        if conversation_id is None:
            conversation_id = self._generate_conversation_id(user_id)
        
        # ê¸°ì¡´ ëŒ€í™” í™•ì¸
        if conversation_id in self.conversations:
            conversation = self.conversations[conversation_id]
            # ë§Œë£Œëœ ëŒ€í™”ëŠ” ìƒˆë¡œ ì‹œì‘
            if conversation.is_expired():
                logger.info(f"ë§Œë£Œëœ ëŒ€í™” ì¬ì‹œì‘: {conversation_id}")
                conversation = ConversationState(user_id, conversation_id)
                self.conversations[conversation_id] = conversation
                return conversation, True
            return conversation, False
        
        # ìƒˆ ëŒ€í™” ìƒì„±
        conversation = ConversationState(user_id, conversation_id)
        self.conversations[conversation_id] = conversation
        logger.info(f"ìƒˆ ëŒ€í™” ì‹œì‘: user_id={user_id}, conversation_id={conversation_id}")
        return conversation, True
    
    def _generate_conversation_id(self, user_id: int) -> int:
        """ëŒ€í™” ID ìƒì„±"""
        import time
        return int(f"{user_id}{int(time.time())}")
    
    def get_conversation_summary(self, conversation_id: int) -> Dict[str, Any]:
        """ëŒ€í™” ìš”ì•½ ì •ë³´"""
        if conversation_id not in self.conversations:
            return {"error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        conversation = self.conversations[conversation_id]
        
        return {
            "conversation_id": conversation_id,
            "user_id": conversation.user_id,
            "current_stage": conversation.current_stage.value,
            "current_mode": conversation.current_mode.value,
            "business_type": conversation.business_type,
            "completion_rate": conversation.get_completion_rate(),
            "collected_info_count": len(conversation.collected_info),
            "message_count": len(conversation.conversation_history),
            "created_at": conversation.created_at.isoformat(),
            "last_activity": conversation.last_activity.isoformat(),
            "user_engagement_level": conversation.user_engagement_level,
            "negative_response_count": conversation.negative_response_count,
            "in_content_creation": conversation.is_in_content_creation(),
            # "features": ["improved_context_understanding", "negative_response_handling", "suggestion_mode", "singleton_completion", "no_hardcoding"]
            "features": ["improved_context_understanding", "negative_response_handling", "suggestion_mode", "no_hardcoding"]
        }
    
    def cleanup_expired_conversations(self):
        """ë§Œë£Œëœ ëŒ€í™” ì •ë¦¬"""
        expired_ids = []
        for conv_id, conv in self.conversations.items():
            if conv.is_expired():
                expired_ids.append(conv_id)
        
        for conv_id in expired_ids:
            del self.conversations[conv_id]
            logger.info(f"ë§Œë£Œëœ ëŒ€í™” ì •ë¦¬: {conv_id}")
        
        return len(expired_ids)
    
    def should_use_structured_response(self, conversation: ConversationState) -> bool:
        """ğŸ†• êµ¬ì¡°í™”ëœ ì‘ë‹µ ì‚¬ìš© ì—¬ë¶€ íŒë‹¨"""
        # ì»¨í…ì¸  ì œì‘ ë‹¨ê³„ì´ê±°ë‚˜ ì œì•ˆ ëª¨ë“œì—ì„œëŠ” êµ¬ì¡°í™”ëœ ì‘ë‹µ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        if (conversation.current_stage == MarketingStage.CONTENT_CREATION or 
            conversation.current_mode == ConversationMode.SUGGESTING or
            conversation.is_awaiting_posting_response()):
            return False
        
        # ì™„ë£Œìœ¨ì´ ë†’ìœ¼ë©´ êµ¬ì¡°í™”ëœ ì‘ë‹µ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        if conversation.get_completion_rate() > 0.7:
            return False
        
        # ì •ë³´ ìˆ˜ì§‘ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ êµ¬ì¡°í™”ëœ ì‘ë‹µ ì‚¬ìš©
        return conversation.current_mode == ConversationMode.QUESTIONING
    
    async def get_welcome_message_with_llm(self, conversation: ConversationState) -> Dict[str, Any]:
        """ğŸ†• LLM ê¸°ë°˜ êµ¬ì¡°í™”ëœ í™˜ì˜ ë©”ì‹œì§€ ìƒì„±"""
        welcome_prompt = """ì‚¬ìš©ìê°€ ë§ˆì¼€íŒ… ìƒë‹´ì„ ì‹œì‘í•  ë•Œ ì‚¬ìš©í•  í™˜ì˜ ë©”ì‹œì§€ë¥¼ ë‹¤ìŒ JSON í˜•íƒœë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

{
  "main_response": "ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í™˜ì˜ ë©”ì‹œì§€ (ì´ëª¨ì§€ì™€ ë§ˆí¬ë‹¤ìš´ í™œìš©)",
  "follow_up_questions": [
    "ìì—°ìŠ¤ëŸ¬ìš´ ì‹œì‘ ì§ˆë¬¸ 1 (ì—…ì¢… ê´€ë ¨)",
    "ìì—°ìŠ¤ëŸ¬ìš´ ì‹œì‘ ì§ˆë¬¸ 2 (ëª©í‘œ ê´€ë ¨)",
    "ìì—°ìŠ¤ëŸ¬ìš´ ì‹œì‘ ì§ˆë¬¸ 3 (í˜„ì¬ ìƒí™© ê´€ë ¨)"
  ],
  "suggested_actions": [
    "ë°”ë¡œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ì²« ë²ˆì§¸ ì•¡ì…˜",
    "ë°”ë¡œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ë‘ ë²ˆì§¸ ì•¡ì…˜"
  ],
  "conversation_direction": "continue_info_gathering"
}

ìš”êµ¬ì‚¬í•­:
1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤
2. ë§ˆì¼€íŒ… ì „ë¬¸ê°€ë¡œì„œì˜ ì‹ ë¢°ì„± ì „ë‹¬
3. ê°œì„ ëœ ê¸°ëŠ¥ë“¤ ì†Œê°œ (ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€, ë§ì¶¤í˜• ì œì•ˆ, ì¹œë°€í•œ ëŒ€í™”)
4. ì‚¬ìš©ìì˜ ì°¸ì—¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„
5. ì´ëª¨ì§€ì™€ ë§ˆí¬ë‹¤ìš´ í™œìš©

ìƒˆë¡œìš´ íŠ¹ì§•:
- ì‚¬ìš©ìê°€ ëª¨ë¥¼ ë•Œ ì§ì ‘ ì œì•ˆ ë° ì¶”ì²œ
- ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€
- ì¹œë°€í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
- ì¦‰ì‹œ ë‹µë³€ ê°€ëŠ¥í•œ ê²ƒì€ ë°”ë¡œ ì™„ë£Œ
- í›„ì† ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™” íë¦„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ê¸°

ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
        
        result = await self._call_llm(welcome_prompt, "í™˜ì˜ ë©”ì‹œì§€ ìƒì„± ìš”ì²­", "")
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
        if "error" in result or "main_response" not in result:
            return {
                "main_response": "ğŸ¯ **ì•ˆë…•í•˜ì„¸ìš”! ë§ˆì¼€íŒ… ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤** ğŸ¯\n\në¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì„ ìœ„í•œ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ í•¨ê»˜ ë§Œë“¤ì–´ë³´ì•„ìš”! ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
                "follow_up_questions": [
                    "ì–´ë–¤ ì—…ì¢…ì—ì„œ ì‚¬ì—…ì„ í•˜ê³  ê³„ì‹ ê°€ìš”?",
                    "í˜„ì¬ ê°€ì¥ í° ë§ˆì¼€íŒ… ê³ ë¯¼ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "ì–´ë–¤ ê²°ê³¼ë¥¼ ê°€ì¥ ë¹ ë¥´ê²Œ ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
                ],
                "suggested_actions": [
                    "ë¹„ì¦ˆë‹ˆìŠ¤ í˜„í™© ì§„ë‹¨ë°›ê¸°",
                    "ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµ ìƒë‹´ë°›ê¸°"
                ],
                "conversation_direction": "continue_info_gathering"
            }
        
        return result