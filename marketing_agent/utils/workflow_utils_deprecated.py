"""
ë§ˆì¼€íŒ… ì›Œí¬í”Œë¡œìš° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í—¬í¼ í•¨ìˆ˜ì™€ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
"""

import re
import json
import hashlib
import logging
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
import yaml


# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class ContentValidator:
    """ì½˜í…ì¸  ìœ íš¨ì„± ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def validate_instagram_content(content: str, hashtags: List[str] = None) -> Dict[str, Any]:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ì½˜í…ì¸  ìœ íš¨ì„± ê²€ì¦"""
        errors = []
        warnings = []
        
        # ê¸€ì ìˆ˜ ì²´í¬ (2200ì ì œí•œ)
        if len(content) > 2200:
            errors.append(f"ì½˜í…ì¸ ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ({len(content)}/2200ì)")
        
        # í•´ì‹œíƒœê·¸ ìˆ˜ ì²´í¬ (30ê°œ ì œí•œ)
        if hashtags and len(hashtags) > 30:
            warnings.append(f"í•´ì‹œíƒœê·¸ê°€ ë§ìŠµë‹ˆë‹¤. ({len(hashtags)}/30ê°œ)")
        
        # í•„ìˆ˜ ìš”ì†Œ ì²´í¬
        if not content.strip():
            errors.append("ì½˜í…ì¸ ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # ì²« ë¬¸ì¥ ê¸¸ì´ ì²´í¬ (í›… íš¨ê³¼)
        first_sentence = content.split('.')[0] if '.' in content else content.split('\n')[0]
        if len(first_sentence) > 100:
            warnings.append("ì²« ë¬¸ì¥ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. í›… íš¨ê³¼ë¥¼ ìœ„í•´ ì§§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings,
            "character_count": len(content),
            "hashtag_count": len(hashtags) if hashtags else 0
        }
    
    @staticmethod
    def validate_blog_content(content: str, keywords: List[str] = None) -> Dict[str, Any]:
        """ë¸”ë¡œê·¸ ì½˜í…ì¸  ìœ íš¨ì„± ê²€ì¦"""
        errors = []
        warnings = []
        
        # ìµœì†Œ ê¸€ì ìˆ˜ ì²´í¬ (1000ì ê¶Œì¥)
        if len(content) < 1000:
            warnings.append(f"ì½˜í…ì¸ ê°€ ì§§ìŠµë‹ˆë‹¤. SEOë¥¼ ìœ„í•´ 1000ì ì´ìƒ ê¶Œì¥ ({len(content)}ì)")
        
        # í‚¤ì›Œë“œ ë°€ë„ ì²´í¬
        if keywords:
            total_words = len(content.split())
            for keyword in keywords:
                keyword_count = content.lower().count(keyword.lower())
                density = (keyword_count / total_words) * 100 if total_words > 0 else 0
                
                if density > 5:
                    warnings.append(f"'{keyword}' í‚¤ì›Œë“œ ë°€ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ({density:.1f}%)")
                elif density < 1:
                    warnings.append(f"'{keyword}' í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ({density:.1f}%)")
        
        # HTML íƒœê·¸ ì²´í¬
        if '<h1>' not in content and '<h2>' not in content:
            warnings.append("ì†Œì œëª©(H2, H3 íƒœê·¸)ì„ ì¶”ê°€í•˜ì—¬ êµ¬ì¡°í™”í•˜ì„¸ìš”.")
        
        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings,
            "character_count": len(content),
            "word_count": len(content.split()),
            "keyword_density": ContentValidator._calculate_keyword_density(content, keywords)
        }
    
    @staticmethod
    def _calculate_keyword_density(content: str, keywords: List[str]) -> Dict[str, float]:
        """í‚¤ì›Œë“œ ë°€ë„ ê³„ì‚°"""
        if not keywords:
            return {}
        
        total_words = len(content.split())
        density_map = {}
        
        for keyword in keywords:
            keyword_count = content.lower().count(keyword.lower())
            density = (keyword_count / total_words) * 100 if total_words > 0 else 0
            density_map[keyword] = round(density, 2)
        
        return density_map


class TextProcessor:
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def extract_hashtags(text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•´ì‹œíƒœê·¸ ì¶”ì¶œ"""
        hashtag_pattern = r'#[\wê°€-í£]+'
        hashtags = re.findall(hashtag_pattern, text)
        return [tag.replace('#', '') for tag in hashtags]
    
    @staticmethod
    def extract_keywords(text: str, max_keywords: int = 10) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë¹ˆë„ ê¸°ë°˜)"""
        # ë¶ˆìš©ì–´ ì œê±° (ê°„ë‹¨í•œ ë²„ì „)
        stopwords = {'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì—', 'ì˜', 'ëŠ”', 'ì€', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ', 
                    'ì—ì„œ', 'ë¶€í„°', 'ê¹Œì§€', 'í•˜ê³ ', 'ê·¸ë¦¬ê³ ', 'ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜'}
        
        # ë‹¨ì–´ ë¶„ë¦¬ ë° ì •ì œ
        words = re.findall(r'[\wê°€-í£]+', text.lower())
        words = [word for word in words if len(word) > 1 and word not in stopwords]
        
        # ë¹ˆë„ ê³„ì‚°
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        
        return [word for word, freq in sorted_words[:max_keywords]]
    
    @staticmethod
    def truncate_text(text: str, max_length: int, suffix: str = "...") -> str:
        """í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ"""
        if len(text) <= max_length:
            return text
        
        truncated = text[:max_length - len(suffix)]
        return truncated + suffix
    
    @staticmethod
    def clean_html(text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        html_pattern = r'<[^>]+>'
        return re.sub(html_pattern, '', text)
    
    @staticmethod
    def format_for_platform(text: str, platform: str) -> str:
        """í”Œë«í¼ë³„ í…ìŠ¤íŠ¸ í¬ë§·íŒ…"""
        if platform.lower() == 'instagram':
            # ì¸ìŠ¤íƒ€ê·¸ë¨: ì´ëª¨ì§€ ê°•í™”, ì¤„ë°”ê¿ˆ ìµœì í™”
            text = TextProcessor._add_line_breaks(text)
            text = TextProcessor._enhance_emojis(text)
        
        elif platform.lower() == 'naver-blog':
            # ë„¤ì´ë²„ ë¸”ë¡œê·¸: HTML íƒœê·¸ ì¶”ê°€, ë‹¨ë½ êµ¬ì¡°í™”
            text = TextProcessor._add_html_structure(text)
        
        return text
    
    @staticmethod
    def _add_line_breaks(text: str) -> str:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ìš© ì¤„ë°”ê¿ˆ ì¶”ê°€"""
        sentences = text.split('. ')
        formatted_sentences = []
        
        for i, sentence in enumerate(sentences):
            formatted_sentences.append(sentence.strip())
            
            # 2-3ë¬¸ì¥ë§ˆë‹¤ ì¤„ë°”ê¿ˆ ì¶”ê°€
            if (i + 1) % 2 == 0 and i < len(sentences) - 1:
                formatted_sentences.append('\n')
        
        return '. '.join(formatted_sentences)
    
    @staticmethod
    def _enhance_emojis(text: str) -> str:
        """ì´ëª¨ì§€ ê°•í™” (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        emoji_map = {
            'ì¢‹ì€': 'ğŸ‘',
            'ìµœê³ ': 'ğŸ”',
            'ì¶”ì²œ': 'ğŸ’¡',
            'ìƒˆë¡œìš´': 'âœ¨',
            'íŠ¹ë³„í•œ': 'â­',
            'ì™„ë²½í•œ': 'ğŸ’¯'
        }
        
        for keyword, emoji in emoji_map.items():
            if keyword in text and emoji not in text:
                text = text.replace(keyword, f"{keyword} {emoji}")
        
        return text
    
    @staticmethod
    def _add_html_structure(text: str) -> str:
        """HTML êµ¬ì¡° ì¶”ê°€"""
        lines = text.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # ì œëª©ì²˜ëŸ¼ ë³´ì´ëŠ” ë¼ì¸ì„ H2ë¡œ ë³€í™˜
            if len(line) < 50 and (line.endswith('?') or line.endswith(':')):
                formatted_lines.append(f"<h2>{line}</h2>")
            else:
                formatted_lines.append(f"<p>{line}</p>")
        
        return '\n'.join(formatted_lines)


class PerformanceTracker:
    """ì„±ê³¼ ì¶”ì  ìœ í‹¸ë¦¬í‹°"""
    
    def __init__(self):
        self.metrics = {}
        self.start_time = datetime.now(timezone.utc)
    
    def start_timer(self, operation: str):
        """ì‘ì—… ì‹œê°„ ì¸¡ì • ì‹œì‘"""
        self.metrics[f"{operation}_start"] = datetime.now(timezone.utc)
    
    def end_timer(self, operation: str):
        """ì‘ì—… ì‹œê°„ ì¸¡ì • ì¢…ë£Œ"""
        if f"{operation}_start" in self.metrics:
            start_time = self.metrics[f"{operation}_start"]
            duration = datetime.now(timezone.utc) - start_time
            self.metrics[f"{operation}_duration"] = duration.total_seconds()
    
    def increment_counter(self, metric: str, value: int = 1):
        """ì¹´ìš´í„° ì¦ê°€"""
        self.metrics[metric] = self.metrics.get(metric, 0) + value
    
    def set_metric(self, metric: str, value: Any):
        """ë©”íŠ¸ë¦­ ì„¤ì •"""
        self.metrics[metric] = value
    
    def get_summary(self) -> Dict[str, Any]:
        """ì„±ê³¼ ìš”ì•½ ë°˜í™˜"""
        total_duration = datetime.now(timezone.utc) - self.start_time
        
        return {
            "total_duration_seconds": total_duration.total_seconds(),
            "start_time": self.start_time.isoformat(),
            "end_time": datetime.now(timezone.utc).isoformat(),
            "metrics": self.metrics
        }


class CacheManager:
    """ê°„ë‹¨í•œ ìºì‹œ ê´€ë¦¬ì"""
    
    def __init__(self, max_size: int = 100):
        self.cache = {}
        self.max_size = max_size
        self.access_times = {}
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        if key in self.cache:
            self.access_times[key] = datetime.now()
            return self.cache[key]
        return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """ìºì‹œì— ê°’ ì €ì¥"""
        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.cache) >= self.max_size:
            self._evict_oldest()
        
        self.cache[key] = {
            "value": value,
            "created_at": datetime.now(),
            "ttl": ttl
        }
        self.access_times[key] = datetime.now()
    
    def _evict_oldest(self):
        """ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°"""
        if self.access_times:
            oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
            del self.cache[oldest_key]
            del self.access_times[oldest_key]
    
    def clear_expired(self):
        """ë§Œë£Œëœ í•­ëª© ì •ë¦¬"""
        now = datetime.now()
        expired_keys = []
        
        for key, data in self.cache.items():
            if isinstance(data, dict) and "created_at" in data and "ttl" in data:
                age = (now - data["created_at"]).total_seconds()
                if age > data["ttl"]:
                    expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
            if key in self.access_times:
                del self.access_times[key]
    
    def generate_cache_key(self, *args, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = str(args) + str(sorted(kwargs.items()))
        return hashlib.md5(key_data.encode()).hexdigest()


class ConfigValidator:
    """ì„¤ì • ìœ íš¨ì„± ê²€ì¦"""
    
    @staticmethod
    def validate_workflow_config(config_path: str) -> Tuple[bool, List[str]]:
        """ì›Œí¬í”Œë¡œìš° ì„¤ì • ìœ íš¨ì„± ê²€ì¦"""
        errors = []
        
        try:
            config_file = Path(config_path)
            if not config_file.exists():
                errors.append(f"ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {config_path}")
                return False, errors
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
            required_sections = ['workflow', 'mcp_servers', 'platform_configs']
            for section in required_sections:
                if section not in config:
                    errors.append(f"í•„ìˆ˜ ì„¹ì…˜ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {section}")
            
            # MCP ì„œë²„ URL í™•ì¸
            if 'mcp_servers' in config:
                for server_name, server_config in config['mcp_servers'].items():
                    if 'url' not in server_config:
                        errors.append(f"MCP ì„œë²„ URLì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {server_name}")
                    
                    if 'tools' not in server_config or not server_config['tools']:
                        errors.append(f"MCP ì„œë²„ ë„êµ¬ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {server_name}")
            
            # í”Œë«í¼ ì„¤ì • í™•ì¸
            if 'platform_configs' in config:
                required_platforms = ['instagram', 'naver_blog']
                for platform in required_platforms:
                    if platform not in config['platform_configs']:
                        errors.append(f"í”Œë«í¼ ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {platform}")
            
        except yaml.YAMLError as e:
            errors.append(f"YAML íŒŒì‹± ì˜¤ë¥˜: {e}")
        except Exception as e:
            errors.append(f"ì„¤ì • ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return len(errors) == 0, errors


class Logger:
    """ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ìš© ë¡œê±°"""
    
    @staticmethod
    def setup_logging(log_dir: str = "logs", log_level: str = "INFO"):
        """ë¡œê¹… ì„¤ì •"""
        log_path = Path(log_dir)
        log_path.mkdir(exist_ok=True)
        
        # ë¡œê·¸ í¬ë§· ì„¤ì •
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(log_path / "marketing_agent.log")
        file_handler.setFormatter(formatter)
        
        # ì—ëŸ¬ íŒŒì¼ í•¸ë“¤ëŸ¬
        error_handler = logging.FileHandler(log_path / "error.log")
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(formatter)
        
        # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_level.upper()))
        root_logger.addHandler(file_handler)
        root_logger.addHandler(error_handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬ (ê°œë°œ ì‹œ)
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        root_logger.addHandler(console_handler)


# ì „ì—­ ìºì‹œ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
_cache_manager = CacheManager()

def get_cache_manager() -> CacheManager:
    """ì „ì—­ ìºì‹œ ë§¤ë‹ˆì € ë°˜í™˜"""
    return _cache_manager
