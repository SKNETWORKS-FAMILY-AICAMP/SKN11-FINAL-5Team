"""
Business Planning Agent Utilities
"""

import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime

# OpenAI ì±—ë´‡ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)

# ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íš í† í”½ ì •ì˜
BUSINESS_TOPICS = {
    "startup_preparation": "ì°½ì—… ì¤€ë¹„ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸",
    "idea_validation": "ì•„ì´ë””ì–´ ê²€ì¦ ë° ì‹œì¥ì„± ë¶„ì„",
    "business_model": "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë° ë¦°ìº”ë²„ìŠ¤",
    "market_research": "ì‹œì¥ ì¡°ì‚¬ ë° ê²½ìŸ ë¶„ì„",
    "mvp_development": "MVP ê°œë°œ ë° ì´ˆê¸° ì œí’ˆ ì„¤ê³„",
    "funding_strategy": "ìê¸ˆ ì¡°ë‹¬ ë° íˆ¬ì ìœ ì¹˜",
    "business_registration": "ì‚¬ì—…ì ë“±ë¡ ë° ë²•ì  ì ˆì°¨",
    "financial_planning": "ì¬ë¬´ ê³„íš ë° ì˜ˆì‚° ê´€ë¦¬",
    "growth_strategy": "ì„±ì¥ ì „ëµ ë° í™•ì¥ ê³„íš",
    "risk_management": "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ìœ„ê¸° ëŒ€ì‘"
}

# ë‹¨ê³„ë³„ ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸ í…œí”Œë¦¿
INFO_GATHERING_QUESTIONS = {
    "business_idea": "ì–´ë–¤ ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ë¥¼ ê°€ì§€ê³  ê³„ì‹ ê°€ìš”?",
    "industry": "ì–´ë–¤ ì—…ì¢…/ì‚°ì—… ë¶„ì•¼ì¸ê°€ìš”?",
    "target_customers": "ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì€ ëˆ„êµ¬ì¸ê°€ìš”?",
    "unique_value": "ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ì°¨ë³„ì ì´ë‚˜ ê³ ìœ  ê°€ì¹˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "business_stage": "í˜„ì¬ ì–´ëŠ ë‹¨ê³„ì— ìˆë‚˜ìš”? (ì•„ì´ë””ì–´/ì¤€ë¹„/ìš´ì˜ ë“±)",
    "budget": "ì´ˆê¸° íˆ¬ì ê°€ëŠ¥í•œ ì˜ˆì‚°ì€ ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
    "timeline": "ì–¸ì œê¹Œì§€ ì‚¬ì—…ì„ ì‹œì‘í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
    "location": "ì‚¬ì—… ì§€ì—­ì´ë‚˜ ìœ„ì¹˜ê°€ ì •í•´ì ¸ ìˆë‚˜ìš”?",
    "team_size": "í˜¼ì ì‹œì‘í•˜ì‹œë‚˜ìš”? íŒ€ì´ ìˆë‚˜ìš”?",
    "experience": "ê´€ë ¨ ì—…ê³„ ê²½í—˜ì´ë‚˜ ì „ë¬¸ì„±ì´ ìˆìœ¼ì‹ ê°€ìš”?",
    "goals": "1-2ë…„ ë‚´ ë‹¬ì„±í•˜ê³  ì‹¶ì€ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "concerns": "ê°€ì¥ ê±±ì •ë˜ê±°ë‚˜ ì–´ë ¤ìš´ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€ìš”?"
}

def get_business_topics() -> Dict[str, str]:
    """ë¹„ì¦ˆë‹ˆìŠ¤ í† í”½ ë°˜í™˜"""
    return BUSINESS_TOPICS

def get_info_gathering_questions() -> Dict[str, str]:
    """ì •ë³´ ìˆ˜ì§‘ ì§ˆë¬¸ ë°˜í™˜"""
    return INFO_GATHERING_QUESTIONS

def format_topic_prompts(topic_prompts: Dict[str, str], business_topics: Dict[str, str]) -> str:
    """í† í”½ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
    if not topic_prompts:
        return "ê¸°ë³¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ìˆ˜í–‰"
    
    formatted = []
    for topic, prompt_content in topic_prompts.items():
        topic_name = business_topics.get(topic, topic)
        formatted.append(f"[{topic_name}]\n{prompt_content}\n")
    
    return "\n".join(formatted)

def format_business_summary(business_info: Dict[str, Any], questions: Dict[str, str]) -> str:
    """ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ ìš”ì•½ í¬ë§·íŒ…"""
    try:
        summary_parts = []
        
        key_mappings = {
            "business_idea": "ğŸ’¡ ì•„ì´ë””ì–´",
            "industry": "ğŸ¢ ì—…ì¢…",
            "target_customers": "ğŸ‘¥ íƒ€ê²Ÿ",
            "unique_value": "â­ ì°¨ë³„ì ",
            "business_stage": "ğŸ“ í˜„ì¬ ë‹¨ê³„",
            "budget": "ğŸ’° ì˜ˆì‚°",
            "timeline": "â° íƒ€ì„ë¼ì¸",
            "goals": "ğŸ¯ ëª©í‘œ"
        }
        
        for field, value in business_info.items():
            if value and field in key_mappings:
                summary_parts.append(f"{key_mappings[field]}: {value}")
        
        return "\n".join(summary_parts) if summary_parts else "ìˆ˜ì§‘ëœ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
    except Exception as e:
        logger.error(f"ë¹„ì¦ˆë‹ˆìŠ¤ ìš”ì•½ í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
        return "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def extract_business_info_with_llm(
    llm_manager, 
    user_input: str, 
    current_info: Dict[str, Any], 
    questions: Dict[str, str]
) -> Dict[str, Any]:
    """LLMì„ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ ì¶”ì¶œ"""
    try:
        extraction_prompt = f"""ì‚¬ìš©ìì˜ ë‹µë³€ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë‹µë³€: "{user_input}"

í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´:
{json.dumps(current_info, ensure_ascii=False, indent=2)}

ì¶”ì¶œ ê°€ëŠ¥í•œ ì •ë³´ í•­ëª©ë“¤:
{chr(10).join([f"- {key}: {value}" for key, value in questions.items()])}

ì‚¬ìš©ì ë‹µë³€ì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ë‹¤ìŒ JSON í˜•íƒœë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "field_name": "ì¶”ì¶œëœ ì •ë³´ ê°’"
}}

ì •ë³´ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ê°ì²´ {{}}ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ì¶”ì¶œ ê²°ê³¼:"""

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ë‹µë³€ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": extraction_prompt}
        ]
        
        response = llm_manager.generate_response_sync(convert_messages_to_dict(messages), output_format="json")
        
        if isinstance(response, dict):
            return response
        elif isinstance(response, str):
            try:
                return json.loads(response)
            except json.JSONDecodeError:
                pass
        
        return {}
        
    except Exception as e:
        logger.error(f"LLM ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return {}

def validate_conversation_completeness(business_info: Dict[str, Any], questions: Dict[str, str]) -> Dict[str, Any]:
    """ëŒ€í™” ì™„ë£Œë„ ê²€ì¦"""
    try:
        result = {
            "is_complete": False,
            "completion_rate": 0.0,
            "missing_fields": [],
            "completed_fields": [],
            "critical_missing": []
        }
        
        # í•„ìˆ˜ í•„ë“œ ì •ì˜
        critical_fields = ["business_idea", "industry", "target_customers", "goals"]
        
        for field, question in questions.items():
            if business_info.get(field):
                result["completed_fields"].append(field)
            else:
                result["missing_fields"].append(field)
                if field in critical_fields:
                    result["critical_missing"].append(field)
        
        # ì™„ë£Œìœ¨ ê³„ì‚°
        total_fields = len(questions)
        completed_fields = len(result["completed_fields"])
        result["completion_rate"] = completed_fields / total_fields if total_fields > 0 else 0.0
        
        # ì™„ë£Œ ì—¬ë¶€ íŒë‹¨ (í•„ìˆ˜ í•„ë“œ ëª¨ë‘ ì™„ë£Œ ë˜ëŠ” ì „ì²´ 70% ì´ìƒ ì™„ë£Œ)
        result["is_complete"] = (
            len(result["critical_missing"]) == 0 or 
            result["completion_rate"] >= 0.7
        )
        
        return result
        
    except Exception as e:
        logger.error(f"ëŒ€í™” ì™„ë£Œë„ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return {
            "is_complete": False,
            "completion_rate": 0.0,
            "missing_fields": list(questions.keys()),
            "completed_fields": [],
            "critical_missing": ["business_idea", "industry", "target_customers", "goals"]
        }

def generate_single_turn_response(
    llm_manager,
    user_input: str,
    business_topics: Dict[str, str],
    classify_func,
    load_prompt_func,
    get_knowledge_func
) -> str:
    """ì‹±ê¸€í†¤ ì‘ë‹µ ìƒì„±"""
    try:
        # í† í”½ ë¶„ë¥˜
        topics = classify_func(user_input)
        
        # í† í”½ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        topic_prompts = {}
        for topic in topics:
            prompt_content = load_prompt_func(topic)
            if prompt_content:
                topic_prompts[topic] = prompt_content
        
        # ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
        relevant_knowledge = get_knowledge_func(user_input, topics)
        
        # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸
        response_prompt = f"""ì‚¬ìš©ìì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì— ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ê´€ë ¨ ë¹„ì¦ˆë‹ˆìŠ¤ í† í”½: {', '.join(topics)}

í† í”½ë³„ ì „ë¬¸ ì§€ì¹¨:
{format_topic_prompts(topic_prompts, business_topics)}

ê´€ë ¨ ì „ë¬¸ ì§€ì‹:
{chr(10).join(relevant_knowledge) if relevant_knowledge else "ê¸°ë³¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì§€ì‹ í™œìš©"}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•œ ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:
1. ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
2. ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸
3. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ê³ ë ¤ì‚¬í•­
4. í•„ìš”ì‹œ ì¶”ê°€ ì •ë³´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íš ì „ë¬¸ê°€ë¡œì„œ ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
            {"role": "user", "content": response_prompt}
        ]
        # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ì‚¬ìš©
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)
        raw_response = llm.invoke(messages)
        response = str(raw_response.content) if hasattr(raw_response, 'content') else str(raw_response)
        
        if isinstance(response, dict):
            return response
        elif isinstance(response, str):
            try:
                return json.loads(response)
            except json.JSONDecodeError:
                pass
        
        return response if response else "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
    except Exception as e:
        logger.error(f"ì‹±ê¸€í†¤ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        return "ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

def create_conversation_state_summary(state) -> Dict[str, Any]:
    """ëŒ€í™” ìƒíƒœ ìš”ì•½ ìƒì„±"""
    try:
        return {
            "conversation_id": state.conversation_id,
            "current_stage": state.stage.value,
            "completion_rate": state.get_completion_rate(),
            "collected_info_count": len([v for v in state.collected_info.values() if v]),
            "total_info_fields": len(state.collected_info),
            "analysis_completed": bool(state.analysis_results.get("analysis_content")),
            "last_updated": state.updated_at.isoformat() if state.updated_at else None,
            "feedback_count": len(state.feedback_history),
            "primary_topics": state.analysis_results.get("primary_topics", [])
        }
        
    except Exception as e:
        logger.error(f"ëŒ€í™” ìƒíƒœ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return {
            "conversation_id": getattr(state, 'conversation_id', None),
            "current_stage": "unknown",
            "completion_rate": 0.0,
            "error": "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
        }

def get_next_action_recommendations(business_info: Dict[str, Any], stage: str) -> List[str]:
    """í˜„ì¬ ë‹¨ê³„ì— ë”°ë¥¸ ë‹¤ìŒ ì•¡ì…˜ ì¶”ì²œ"""
    try:
        recommendations = []
        
        if stage == "initial" or stage == "info_gathering":
            if not business_info.get("business_idea"):
                recommendations.append("ë¹„ì¦ˆë‹ˆìŠ¤ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•´ë³´ì„¸ìš”")
            if not business_info.get("target_customers"):
                recommendations.append("íƒ€ê²Ÿ ê³ ê°ì„ ëª…í™•íˆ ì •ì˜í•´ë³´ì„¸ìš”")
            if not business_info.get("unique_value"):
                recommendations.append("ê²½ìŸ ìš°ìœ„ë‚˜ ì°¨ë³„ì ì„ ì°¾ì•„ë³´ì„¸ìš”")
                
        elif stage == "analysis":
            recommendations.extend([
                "ì‹œì¥ ì¡°ì‚¬ë¥¼ í†µí•´ ê²½ìŸ í˜„í™©ì„ íŒŒì•…í•´ë³´ì„¸ìš”",
                "MVP(ìµœì†Œ ì‹¤í–‰ ê°€ëŠ¥ ì œí’ˆ) ê°œë…ì„ ì„¤ê³„í•´ë³´ì„¸ìš”",
                "ì´ˆê¸° ë¹„ìš©ê³¼ ìˆ˜ìµ ëª¨ë¸ì„ ê³„íší•´ë³´ì„¸ìš”"
            ])
            
        elif stage == "planning":
            recommendations.extend([
                "êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ íƒ€ì„ë¼ì¸ì„ ìˆ˜ë¦½í•´ë³´ì„¸ìš”",
                "í•„ìš”í•œ ìì›ê³¼ íŒ€ êµ¬ì„±ì„ ê³„íší•´ë³´ì„¸ìš”",
                "ë§ˆì¼€íŒ… ì „ëµì„ êµ¬ì²´í™”í•´ë³´ì„¸ìš”"
            ])
        
        return recommendations[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€
        
    except Exception as e:
        logger.error(f"ë‹¤ìŒ ì•¡ì…˜ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        return ["í˜„ì¬ ìƒí™©ì„ ì ê²€í•˜ê³  ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•´ë³´ì„¸ìš”"]

def calculate_business_readiness_score(business_info: Dict[str, Any]) -> float:
    """ë¹„ì¦ˆë‹ˆìŠ¤ ì¤€ë¹„ë„ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)"""
    try:
        score = 0.0
        total_weight = 0.0
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        field_weights = {
            "business_idea": 0.2,      # 20%
            "industry": 0.1,           # 10%
            "target_customers": 0.15,  # 15%
            "unique_value": 0.15,      # 15%
            "business_stage": 0.1,     # 10%
            "budget": 0.1,             # 10%
            "timeline": 0.05,          # 5%
            "experience": 0.1,         # 10%
            "goals": 0.05              # 5%
        }
        
        for field, weight in field_weights.items():
            total_weight += weight
            if business_info.get(field):
                score += weight
        
        return min(score / total_weight, 1.0) if total_weight > 0 else 0.0
        
    except Exception as e:
        logger.error(f"ì¤€ë¹„ë„ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

def analyze_business_complexity_with_llm(llm_manager, user_input: str) -> Dict[str, Any]:
    """LLM ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë³µì¡ë„ ë¶„ì„"""
    try:
        complexity_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë³µì¡ë„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{user_input}"

ë‹¤ìŒ JSON í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
    "complexity_level": "simple|moderate|complex",
    "requires_consultation": true/false,
    "estimated_time": "quick|medium|extensive",
    "key_topics": ["ê´€ë ¨ ì£¼ìš” í† í”½ë“¤"],
    "immediate_answerable": true/false,
    "reasoning": "íŒë‹¨ ê·¼ê±°"
}}

ë¶„ì„ ê¸°ì¤€:
- simple: ì¼ë°˜ì ì¸ ì •ë³´ ë¬¸ì˜, ì¦‰ì‹œ ë‹µë³€ ê°€ëŠ¥
- moderate: ì•½ê°„ì˜ ë¶„ì„ì´ í•„ìš”í•˜ì§€ë§Œ ë‹¨ì¼ ì‘ë‹µìœ¼ë¡œ í•´ê²° ê°€ëŠ¥
- complex: ì²´ê³„ì ì¸ ìƒë‹´ê³¼ ì •ë³´ ìˆ˜ì§‘ì´ í•„ìš”

ë¶„ì„ ê²°ê³¼:"""

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ì •í™•íˆ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": complexity_prompt}
        ]
        
        response = llm_manager.generate_response_sync(convert_messages_to_dict(messages), output_format="json")
        
        if isinstance(response, dict):
            return response
        elif isinstance(response, str):
            try:
                return json.loads(response)
            except json.JSONDecodeError:
                pass
        
        return {
            "complexity_level": "moderate",
            "requires_consultation": True,
            "estimated_time": "medium",
            "key_topics": [],
            "immediate_answerable": False,
            "reasoning": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ê°’"
        }
        
    except Exception as e:
        logger.error(f"LLM ë³µì¡ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            "complexity_level": "moderate",
            "requires_consultation": True,
            "estimated_time": "medium",
            "key_topics": [],
            "immediate_answerable": False,
            "reasoning": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }

def generate_adaptive_response_with_llm(
    llm_manager,
    user_input: str,
    business_info: Dict[str, Any],
    conversation_history: List[str] = None
) -> str:
    """LLM ê¸°ë°˜ ì ì‘í˜• ì‘ë‹µ ìƒì„±"""
    try:
        context = ""
        if conversation_history:
            context = f"\nëŒ€í™” ê¸°ë¡:\n{chr(10).join(conversation_history[-3:])}"  # ìµœê·¼ 3ê°œë§Œ
        
        if business_info and any(business_info.values()):
            context += f"\n\nìˆ˜ì§‘ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´:\n{format_business_summary(business_info, INFO_GATHERING_QUESTIONS)}"
        
        adaptive_prompt = f"""ì‚¬ìš©ìì™€ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒë‹´ì—ì„œ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì…ë ¥: "{user_input}"
{context}

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ì‚¬ìš©ìì˜ í˜„ì¬ ìƒí™©ê³¼ ë‹ˆì¦ˆì— ë§ì¶° ê°œì¸í™”ëœ ë‹µë³€ ì œê³µ
2. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ í¬í•¨
3. í•„ìš”ì‹œ ë‹¤ìŒ ë‹¨ê³„ë‚˜ ì¶”ê°€ ì •ë³´ ìš”ì²­
4. ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•œ í†¤ ìœ ì§€
5. ë¹„ì¦ˆë‹ˆìŠ¤ ì‹¤ë¬´ì— ë„ì›€ì´ ë˜ëŠ” ì‹¤ìš©ì  ë‚´ìš© ì¤‘ì‹¬

ìœ„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë§ì¶¤í˜• ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ë¡œì„œ ê°œì¸ì˜ ìƒí™©ì— ë§ëŠ” ë§ì¶¤í˜• ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."},
            {"role": "user", "content": adaptive_prompt}
        ]
        
        response = llm_manager.generate_response_sync(convert_messages_to_dict(messages))
        return response if response else "ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
    except Exception as e:
        logger.error(f"ì ì‘í˜• ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        return "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
